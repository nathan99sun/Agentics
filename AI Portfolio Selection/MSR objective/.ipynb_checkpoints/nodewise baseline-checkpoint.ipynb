{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84482766-9f65-4cb5-9309-e8bd125501f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def naive_nodewise_regression(Y_star, lambda_grid=None):\n",
    "    \"\"\"\n",
    "    Implements Naive Nodewise Regression (Section 5.1.2).\n",
    "    Uses GIC (Generalized Information Criterion) as in the paper.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Y_star : np.ndarray, shape (n, p)\n",
    "        Demeaned returns matrix (time x assets)\n",
    "    lambda_grid : list or None\n",
    "        Grid of lambda values to try. If None, creates default grid.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Estimated precision matrix\n",
    "    \"\"\"\n",
    "    n, p = Y_star.shape\n",
    "\n",
    "    # Initialize matrices\n",
    "    Theta_hat = np.zeros((p, p))\n",
    "    tau_squared = np.zeros(p)\n",
    "    \n",
    "    # Create lambda grid if not provided\n",
    "    if lambda_grid is None:\n",
    "        lambda_grid = np.logspace(-3, 1, 50)\n",
    "    \n",
    "    # For each asset j\n",
    "    for j in range(p):\n",
    "        # Step 1: Get y_j (target) and Y_{-j} (predictors)\n",
    "        y_j = Y_star[:, j]\n",
    "        Y_minus_j = np.delete(Y_star, j, axis=1)\n",
    "        \n",
    "        # Step 2-3: Estimate gamma_j using Lasso with GIC\n",
    "        # GIC(λ) = log(σ²_λ) + |S_λ| * (log(p-1) / n) * log(log(n))\n",
    "        best_gic = np.inf\n",
    "        best_lambda = lambda_grid[0]\n",
    "        best_gamma = None\n",
    "        best_ssr = None\n",
    "        \n",
    "        for lam in lambda_grid:\n",
    "            lasso = Lasso(alpha=2*lam, fit_intercept=False, max_iter=10000)\n",
    "            lasso.fit(Y_minus_j, y_j)\n",
    "            gamma_j = lasso.coef_\n",
    "            \n",
    "            # Compute SSR and number of non-zero coefficients\n",
    "            residuals = y_j - Y_minus_j @ gamma_j\n",
    "            ssr = np.sum(residuals ** 2)\n",
    "            sigma_sq_lambda = ssr / n\n",
    "            q_lambda = np.sum(np.abs(gamma_j) > 1e-8)\n",
    "            \n",
    "            # Compute GIC\n",
    "            if sigma_sq_lambda > 1e-10: # Check for non-zero variance\n",
    "                # GIC formula from paper\n",
    "                gic = np.log(sigma_sq_lambda) + q_lambda * (np.log(p) / n) * np.log(np.log(n))\n",
    "            else:\n",
    "                gic = np.inf\n",
    "            \n",
    "            if gic < best_gic:\n",
    "                best_gic = gic\n",
    "                best_lambda = lam\n",
    "                best_gamma = gamma_j.copy()\n",
    "                best_ssr = ssr\n",
    "        \n",
    "        gamma_j_star = best_gamma\n",
    "        \n",
    "\n",
    "        tau_squared[j] = best_ssr / n + best_lambda * np.sum(np.abs(gamma_j_star))\n",
    "\n",
    "        # [cite_start]Step 5: Form the j-th row of Theta_hat [cite: 579, 543-547]\n",
    "        Theta_hat[j, j] = 1 / tau_squared[j]\n",
    "        off_diag = -gamma_j_star / tau_squared[j]\n",
    "        Theta_hat[j, :j] = off_diag[:j]\n",
    "        Theta_hat[j, j+1:] = off_diag[j:]\n",
    "    \n",
    "    # Step 6: Symmetrize\n",
    "    Theta_hat_sym = (Theta_hat + Theta_hat.T) / 2\n",
    "    \n",
    "    return Theta_hat_sym\n",
    "\n",
    "\n",
    "def msr_weights(Theta_hat, mu):\n",
    "    \"\"\"\n",
    "    Compute Maximum Sharpe Ratio portfolio weights.\n",
    "    \n",
    "    The maximum Sharpe ratio portfolio solves:\n",
    "    max (w' mu) / sqrt(w' Sigma w)\n",
    "    \n",
    "    Solution (when mu represents excess returns):\n",
    "    w ∝ Sigma^{-1} mu = Theta mu\n",
    "    \n",
    "    Then normalize so that sum(w) = 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix (Sigma^{-1})\n",
    "    mu : np.ndarray, shape (p,)\n",
    "        Expected excess returns\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights (sum to 1)\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # Compute unnormalized weights: w ∝ Theta mu\n",
    "    w_unnorm = Theta_hat @ mu\n",
    "    \n",
    "    # Normalize to sum to 1\n",
    "    weight_sum = np.sum(w_unnorm)\n",
    "    \n",
    "    if np.abs(weight_sum) < 1e-10:\n",
    "        print('WARNING: Weight sum near zero, returning equal weights')\n",
    "        return ones_p / p\n",
    "    \n",
    "    w_star = w_unnorm / weight_sum\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "\n",
    "def compute_portfolio_metrics(returns, weights):\n",
    "    \"\"\"\n",
    "    Compute portfolio return, variance, and Sharpe ratio.\n",
    "    \"\"\"\n",
    "    portfolio_returns = returns @ weights\n",
    "    mean_return = np.mean(portfolio_returns)\n",
    "    variance = np.var(portfolio_returns, ddof=1)\n",
    "    sharpe_ratio = mean_return / np.sqrt(variance) if variance > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'return': mean_return,\n",
    "        'variance': variance,\n",
    "        'sharpe_ratio': sharpe_ratio\n",
    "    }\n",
    "\n",
    "\n",
    "def backtest_nodewise_gmv(df, \n",
    "                          test_start_date='2000-01-31', \n",
    "                          test_end_date='2003-12-31',\n",
    "                          lookback_window=180,\n",
    "                          transaction_cost=0.005,\n",
    "                          verbose=True):\n",
    "    \"\"\"\n",
    "    Backtest Nodewise + MSR strategy with monthly rebalancing,\n",
    "    180-month rolling window, and NaN filtering as per the paper.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with columns: permno, datadate, ret_fwd_1\n",
    "    test_start_date : str\n",
    "        First date for out-of-sample returns (format: 'YYYY-MM-DD')\n",
    "    test_end_date : str\n",
    "        Last date for out-of-sample returns (format: 'YYYY-MM-DD')\n",
    "    lookback_window : int\n",
    "        Number of months in rolling training window (default: 180)\n",
    "    transaction_cost : float\n",
    "        Proportional transaction cost (default: 0.005 = 50 bps)\n",
    "    verbose : bool\n",
    "        If True, prints detailed log at each time step.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results_df : pd.DataFrame\n",
    "        DataFrame with columns: date, portfolio_return, cumulative_return\n",
    "    metrics : dict\n",
    "        Overall performance metrics\n",
    "    \"\"\"\n",
    "    # --- 1. Setup ---\n",
    "    df = df.copy()\n",
    "    if 'datadate' not in df.columns or 'permno' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have 'datadate' and 'permno' columns\")\n",
    "    df['datadate'] = pd.to_datetime(df['datadate'])\n",
    "    \n",
    "    # Get unique dates\n",
    "    all_dates = sorted(df['datadate'].unique())\n",
    "    \n",
    "    # Convert test dates to datetime\n",
    "    test_start_dt = pd.to_datetime(test_start_date)\n",
    "    test_end_dt = pd.to_datetime(test_end_date)\n",
    "    \n",
    "    # Find date indices\n",
    "    try:\n",
    "        test_start_idx = all_dates.index(test_start_dt)\n",
    "        test_end_idx = all_dates.index(test_end_dt)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Date not found in DataFrame: {e}\")\n",
    "    \n",
    "    if test_start_idx < lookback_window:\n",
    "        raise ValueError(f\"Not enough data for lookback. Test start date {test_start_date} \"\n",
    "                         f\"requires data back to {all_dates[test_start_idx - lookback_window]}, \"\n",
    "                         f\"but only {test_start_idx} periods are available.\")\n",
    "    \n",
    "    # Storage for results\n",
    "    portfolio_returns = []\n",
    "    portfolio_dates = []\n",
    "    portfolio_weights_list = []\n",
    "    portfolio_turnover_list = []\n",
    "    portfolio_gross_returns = []\n",
    "    \n",
    "    # Track weights by permno (handles entry/exit)\n",
    "    prev_weights_dict = {}\n",
    "    prev_oos_returns_dict = {}\n",
    "    prev_gross_return = 0.0\n",
    "    \n",
    "    # --- 2. Rolling Window Backtest ---\n",
    "    if verbose:\n",
    "        print(\"=\"*60)\n",
    "        print(\"STARTING BACKTEST\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "    for t in range(test_start_idx, test_end_idx + 1):\n",
    "        current_date = all_dates[t]\n",
    "        \n",
    "        # Define the lookback window\n",
    "        window_start_date = all_dates[t - lookback_window]\n",
    "        window_end_date = all_dates[t - 1]\n",
    "        \n",
    "        # Get training data for this window\n",
    "        train_data = df[(df['datadate'] >= window_start_date) & \n",
    "                        (df['datadate'] <= window_end_date)]\n",
    "        \n",
    "        # Pivot to get returns matrix (time x assets)\n",
    "        returns_pivot = train_data.pivot(index='datadate', columns='permno', values='ret_fwd_1')\n",
    "        \n",
    "        # Reindex to ensure all dates are present\n",
    "        window_dates = all_dates[t - lookback_window : t]\n",
    "        returns_pivot = returns_pivot.reindex(index=window_dates)\n",
    "        \n",
    "        # Filter assets with any NaNs in this window\n",
    "        nan_assets = returns_pivot.columns[returns_pivot.isna().any()]\n",
    "        filtered_pivot = returns_pivot.drop(columns=nan_assets)\n",
    "        \n",
    "        current_assets = filtered_pivot.columns.tolist()\n",
    "        Y = filtered_pivot.values\n",
    "        n_train, p_current = Y.shape\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                  f\"Date: {current_date.strftime('%Y-%m-%d')}\")\n",
    "            print(f\"  Window: {window_start_date.strftime('%Y-%m-%d')} to \"\n",
    "                  f\"{window_end_date.strftime('%Y-%m-%d')}\")\n",
    "            print(f\"  Assets: {p_current} with complete data\")\n",
    "\n",
    "        # Check for valid data\n",
    "        if n_train < lookback_window or p_current < 2:\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ Insufficient data (n={n_train}, p={p_current}), using prev weights\")\n",
    "            new_weights_dict = prev_weights_dict.copy()\n",
    "        else:\n",
    "            try:\n",
    "                # Demean the returns\n",
    "                Y_bar = Y.mean(axis=0)\n",
    "                Y_star = Y - Y_bar\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Running Nodewise Regression...\")\n",
    "                Theta_hat = naive_nodewise_regression(Y_star)\n",
    "\n",
    "                # Compute expected returns (sample mean)\n",
    "                mu = Y.mean(axis=0)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Computing MSR weights...\")\n",
    "                w_star = msr_weights(Theta_hat, mu)\n",
    "                \n",
    "                # Create weights dictionary\n",
    "                new_weights_dict = {asset: w_star[i] for i, asset in enumerate(current_assets)}\n",
    "                \n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"  ✗ Error: {e}\")\n",
    "                    print(f\"  Using previous weights\")\n",
    "                new_weights_dict = prev_weights_dict.copy()\n",
    "\n",
    "        # Normalize weights to sum to 1\n",
    "        weight_sum = sum(new_weights_dict.values())\n",
    "        if weight_sum > 1e-10:\n",
    "            new_weights_dict = {k: v/weight_sum for k, v in new_weights_dict.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ Zero weight sum, using previous weights\")\n",
    "            new_weights_dict = prev_weights_dict.copy()\n",
    "        \n",
    "        # --- 3. OOS Returns & Transaction Costs ---\n",
    "        \n",
    "        # Get out-of-sample returns for current month\n",
    "        oos_data = df[df['datadate'] == current_date]\n",
    "        oos_returns_series = oos_data.set_index('permno')['ret_fwd_1']\n",
    "        \n",
    "        # Filter out NaN returns\n",
    "        oos_returns_series = oos_returns_series.dropna()\n",
    "        oos_returns_dict = oos_returns_series.to_dict()\n",
    "        \n",
    "        # Find common assets between weights and returns\n",
    "        common_assets = set(new_weights_dict.keys()) & set(oos_returns_dict.keys())\n",
    "        \n",
    "        if len(common_assets) == 0:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ No common assets with valid returns, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Filter to common assets and renormalize\n",
    "        common_weights = {a: new_weights_dict[a] for a in common_assets}\n",
    "        common_weight_sum = sum(common_weights.values())\n",
    "        if common_weight_sum > 1e-10:\n",
    "            common_weights = {k: v/common_weight_sum for k, v in common_weights.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ Zero weight sum after filtering, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Compute gross portfolio return\n",
    "        gross_return = sum(common_weights[a] * oos_returns_dict[a] for a in common_assets)\n",
    "        \n",
    "        # Sanity check\n",
    "        if np.isnan(gross_return) or np.isinf(gross_return):\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ Invalid gross return: {gross_return}, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate transaction costs with proper weight adjustment\n",
    "        if len(prev_weights_dict) > 0:\n",
    "            # Step 1: Adjust ALL previous weights for returns\n",
    "            adjusted_prev = {}\n",
    "            \n",
    "            for asset, prev_w in prev_weights_dict.items():\n",
    "                if asset in prev_oos_returns_dict:\n",
    "                    prev_r = prev_oos_returns_dict[asset]\n",
    "                    if abs(1 + prev_gross_return) > 1e-6:\n",
    "                        adjusted_prev[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return)\n",
    "                    else:\n",
    "                        adjusted_prev[asset] = 0.0\n",
    "                else:\n",
    "                    print(\"SUSPICIOUS\")\n",
    "                    # Asset had weight but no return data\n",
    "                    if abs(1 + prev_gross_return) > 1e-6:\n",
    "                        adjusted_prev[asset] = prev_w / (1 + prev_gross_return)\n",
    "                    else:\n",
    "                        adjusted_prev[asset] = 0.0\n",
    "            \n",
    "            # Step 2: Calculate turnover\n",
    "            all_assets = set(adjusted_prev.keys()) | set(common_weights.keys())\n",
    "            \n",
    "            turnover = 0.0\n",
    "            for asset in all_assets:\n",
    "                old_w = adjusted_prev.get(asset, 0.0)\n",
    "                new_w = common_weights.get(asset, 0.0)\n",
    "                turnover += abs(new_w - old_w)\n",
    "            \n",
    "            # Transaction cost on end-of-period portfolio value\n",
    "            tc = transaction_cost * (1 + gross_return) * turnover\n",
    "        \n",
    "        else:\n",
    "            # First period: no previous positions, buying into everything\n",
    "            turnover = sum(abs(w) for w in common_weights.values())\n",
    "            tc = transaction_cost * (1 + gross_return) * turnover\n",
    "        \n",
    "        # Net return\n",
    "        net_return = gross_return - tc\n",
    "        \n",
    "        # Store results\n",
    "        portfolio_returns.append(net_return)\n",
    "        portfolio_dates.append(current_date)\n",
    "        portfolio_weights_list.append(common_weights.copy())\n",
    "        portfolio_turnover_list.append(turnover)\n",
    "        portfolio_gross_returns.append(gross_return)\n",
    "        \n",
    "        # Update previous values for next iteration\n",
    "        prev_weights_dict = common_weights.copy()\n",
    "        prev_oos_returns_dict = {a: oos_returns_dict[a] for a in common_assets}\n",
    "        prev_gross_return = gross_return\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Gross: {gross_return:>8.5f} | Turnover: {turnover:>6.4f} | \"\n",
    "                  f\"TC: {tc:>8.6f} | Net: {net_return:>8.5f}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BACKTEST COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    # --- 4. Compile Results ---\n",
    "    results_df = pd.DataFrame({\n",
    "        'date': portfolio_dates,\n",
    "        'portfolio_return': portfolio_returns,\n",
    "        'portfolio_gross_return': portfolio_gross_returns,\n",
    "        'portfolio_weights': portfolio_weights_list,\n",
    "        'portfolio_turnover': portfolio_turnover_list\n",
    "    })\n",
    "    results_df['cumulative_return'] = (1 + results_df['portfolio_return']).cumprod() - 1\n",
    "    \n",
    "    # Compute overall metrics\n",
    "    if len(portfolio_returns) > 0:\n",
    "        mean_return = np.mean(portfolio_returns)\n",
    "        variance = np.var(portfolio_returns, ddof=1)\n",
    "        sharpe_ratio = mean_return / np.sqrt(variance) if variance > 0 else 0\n",
    "        \n",
    "        # Annualized metrics (monthly data)\n",
    "        annual_return = mean_return * 12\n",
    "        annual_volatility = np.sqrt(variance * 12)\n",
    "        annual_sharpe = annual_return / annual_volatility if annual_volatility > 0 else 0\n",
    "        \n",
    "        metrics = {\n",
    "            'mean_return': mean_return,\n",
    "            'variance': variance,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'annual_return': annual_return,\n",
    "            'annual_volatility': annual_volatility,\n",
    "            'annual_sharpe_ratio': annual_sharpe,\n",
    "            'total_return': results_df['cumulative_return'].iloc[-1],\n",
    "            'avg_turnover': np.mean(portfolio_turnover_list),\n",
    "            'n_periods': len(portfolio_returns)\n",
    "        }\n",
    "    else:\n",
    "        metrics = {\n",
    "            'mean_return': 0,\n",
    "            'variance': 0,\n",
    "            'sharpe_ratio': 0,\n",
    "            'annual_return': 0,\n",
    "            'annual_volatility': 0,\n",
    "            'annual_sharpe_ratio': 0,\n",
    "            'total_return': 0,\n",
    "            'avg_turnover': 0,\n",
    "            'n_periods': 0\n",
    "        }\n",
    "    \n",
    "    return results_df, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f77cbae-5233-4cbe-8d95-7d8e0a1a7e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have loaded your dataframe as 'df'\n",
    "df = pd.read_csv('../../green cleaned.csv', dtype={'ncusip': 'string'})\n",
    "df['ret_fwd_1'] = (df.groupby('permno')['ret_excess'].shift(-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91c84132-baa0-40d4-8184-13b3c69b620e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING BACKTEST\n",
      "============================================================\n",
      "\n",
      "[1/52] Date: 2020-01-31\n",
      "  Window: 2005-01-31 to 2019-12-31\n",
      "  Assets: 252 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.08808 | Turnover: 1.1269 | TC: 0.001028 | Net: -0.08911\n",
      "\n",
      "[2/52] Date: 2020-02-29\n",
      "  Window: 2005-02-28 to 2020-01-31\n",
      "  Assets: 252 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.12050 | Turnover: 0.0571 | TC: 0.000050 | Net: -0.12055\n",
      "\n",
      "[3/52] Date: 2020-03-31\n",
      "  Window: 2005-03-31 to 2020-02-29\n",
      "  Assets: 253 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.09909 | Turnover: 0.1242 | TC: 0.000136 | Net:  0.09896\n",
      "\n",
      "[4/52] Date: 2020-04-30\n",
      "  Window: 2005-04-30 to 2020-03-31\n",
      "  Assets: 251 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.04097 | Turnover: 0.0868 | TC: 0.000090 | Net:  0.04088\n",
      "\n",
      "[5/52] Date: 2020-05-31\n",
      "  Window: 2005-05-31 to 2020-04-30\n",
      "  Assets: 250 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.00811 | Turnover: 0.0578 | TC: 0.000057 | Net: -0.00817\n",
      "\n",
      "[6/52] Date: 2020-06-30\n",
      "  Window: 2005-06-30 to 2020-05-31\n",
      "  Assets: 248 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.04936 | Turnover: 0.0606 | TC: 0.000064 | Net:  0.04930\n",
      "\n",
      "[7/52] Date: 2020-07-31\n",
      "  Window: 2005-07-31 to 2020-06-30\n",
      "  Assets: 250 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.04065 | Turnover: 0.0669 | TC: 0.000070 | Net:  0.04058\n",
      "\n",
      "[8/52] Date: 2020-08-31\n",
      "  Window: 2005-08-31 to 2020-07-31\n",
      "  Assets: 253 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.00164 | Turnover: 0.0713 | TC: 0.000071 | Net: -0.00171\n",
      "\n",
      "[9/52] Date: 2020-09-30\n",
      "  Window: 2005-09-30 to 2020-08-31\n",
      "  Assets: 251 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.01719 | Turnover: 0.0539 | TC: 0.000053 | Net: -0.01724\n",
      "\n",
      "[10/52] Date: 2020-10-31\n",
      "  Window: 2005-10-31 to 2020-09-30\n",
      "  Assets: 251 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.08594 | Turnover: 0.0705 | TC: 0.000077 | Net:  0.08587\n",
      "\n",
      "[11/52] Date: 2020-11-30\n",
      "  Window: 2005-11-30 to 2020-10-31\n",
      "  Assets: 252 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.01561 | Turnover: 0.0992 | TC: 0.000101 | Net:  0.01551\n",
      "\n",
      "[12/52] Date: 2020-12-31\n",
      "  Window: 2005-12-31 to 2020-11-30\n",
      "  Assets: 251 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.02033 | Turnover: 0.0546 | TC: 0.000054 | Net: -0.02039\n",
      "\n",
      "[13/52] Date: 2021-01-31\n",
      "  Window: 2006-01-31 to 2020-12-31\n",
      "  Assets: 251 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.01317 | Turnover: 0.0660 | TC: 0.000067 | Net:  0.01311\n",
      "\n",
      "[14/52] Date: 2021-02-28\n",
      "  Window: 2006-02-28 to 2021-01-31\n",
      "  Assets: 252 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.07194 | Turnover: 0.0703 | TC: 0.000075 | Net:  0.07187\n",
      "\n",
      "[15/52] Date: 2021-03-31\n",
      "  Window: 2006-03-31 to 2021-02-28\n",
      "  Assets: 251 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.04317 | Turnover: 0.0520 | TC: 0.000054 | Net:  0.04312\n",
      "\n",
      "[16/52] Date: 2021-04-30\n",
      "  Window: 2006-04-30 to 2021-03-31\n",
      "  Assets: 253 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.01092 | Turnover: 0.0614 | TC: 0.000062 | Net:  0.01086\n",
      "\n",
      "[17/52] Date: 2021-05-31\n",
      "  Window: 2006-05-31 to 2021-04-30\n",
      "  Assets: 253 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.00112 | Turnover: 0.0526 | TC: 0.000053 | Net: -0.00118\n",
      "\n",
      "[18/52] Date: 2021-06-30\n",
      "  Window: 2006-06-30 to 2021-05-31\n",
      "  Assets: 254 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.02562 | Turnover: 0.0517 | TC: 0.000053 | Net:  0.02557\n",
      "\n",
      "[19/52] Date: 2021-07-31\n",
      "  Window: 2006-07-31 to 2021-06-30\n",
      "  Assets: 254 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.01856 | Turnover: 0.0643 | TC: 0.000066 | Net:  0.01850\n",
      "\n",
      "[20/52] Date: 2021-08-31\n",
      "  Window: 2006-08-31 to 2021-07-31\n",
      "  Assets: 255 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.05062 | Turnover: 0.0535 | TC: 0.000051 | Net: -0.05067\n",
      "\n",
      "[21/52] Date: 2021-09-30\n",
      "  Window: 2006-09-30 to 2021-08-31\n",
      "  Assets: 253 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.05579 | Turnover: 0.0576 | TC: 0.000061 | Net:  0.05573\n",
      "\n",
      "[22/52] Date: 2021-10-31\n",
      "  Window: 2006-10-31 to 2021-09-30\n",
      "  Assets: 253 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.01262 | Turnover: 0.0601 | TC: 0.000059 | Net: -0.01268\n",
      "\n",
      "[23/52] Date: 2021-11-30\n",
      "  Window: 2006-11-30 to 2021-10-31\n",
      "  Assets: 257 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.07070 | Turnover: 0.0750 | TC: 0.000080 | Net:  0.07062\n",
      "\n",
      "[24/52] Date: 2021-12-31\n",
      "  Window: 2006-12-31 to 2021-11-30\n",
      "  Assets: 255 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.04137 | Turnover: 0.0457 | TC: 0.000044 | Net: -0.04141\n",
      "\n",
      "[25/52] Date: 2022-01-31\n",
      "  Window: 2007-01-31 to 2021-12-31\n",
      "  Assets: 256 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.02282 | Turnover: 0.0739 | TC: 0.000072 | Net: -0.02289\n",
      "\n",
      "[26/52] Date: 2022-02-28\n",
      "  Window: 2007-02-28 to 2022-01-31\n",
      "  Assets: 255 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.03745 | Turnover: 0.0613 | TC: 0.000064 | Net:  0.03739\n",
      "\n",
      "[27/52] Date: 2022-03-31\n",
      "  Window: 2007-03-31 to 2022-02-28\n",
      "  Assets: 257 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.04460 | Turnover: 0.0647 | TC: 0.000062 | Net: -0.04466\n",
      "\n",
      "[28/52] Date: 2022-04-30\n",
      "  Window: 2007-04-30 to 2022-03-31\n",
      "  Assets: 259 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.00735 | Turnover: 0.0727 | TC: 0.000073 | Net:  0.00727\n",
      "\n",
      "[29/52] Date: 2022-05-31\n",
      "  Window: 2007-05-31 to 2022-04-30\n",
      "  Assets: 259 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.05866 | Turnover: 0.0517 | TC: 0.000049 | Net: -0.05870\n",
      "\n",
      "[30/52] Date: 2022-06-30\n",
      "  Window: 2007-06-30 to 2022-05-31\n",
      "  Assets: 259 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.06369 | Turnover: 0.0630 | TC: 0.000067 | Net:  0.06362\n",
      "\n",
      "[31/52] Date: 2022-07-31\n",
      "  Window: 2007-07-31 to 2022-06-30\n",
      "  Assets: 260 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.02902 | Turnover: 0.0782 | TC: 0.000076 | Net: -0.02909\n",
      "\n",
      "[32/52] Date: 2022-08-31\n",
      "  Window: 2007-08-31 to 2022-07-31\n",
      "  Assets: 261 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.08647 | Turnover: 0.0573 | TC: 0.000052 | Net: -0.08652\n",
      "\n",
      "[33/52] Date: 2022-09-30\n",
      "  Window: 2007-09-30 to 2022-08-31\n",
      "  Assets: 262 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.08023 | Turnover: 0.0798 | TC: 0.000086 | Net:  0.08014\n",
      "\n",
      "[34/52] Date: 2022-10-31\n",
      "  Window: 2007-10-31 to 2022-09-30\n",
      "  Assets: 265 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.06715 | Turnover: 0.0836 | TC: 0.000089 | Net:  0.06706\n",
      "\n",
      "[35/52] Date: 2022-11-30\n",
      "  Window: 2007-11-30 to 2022-10-31\n",
      "  Assets: 266 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.03533 | Turnover: 0.0812 | TC: 0.000078 | Net: -0.03541\n",
      "\n",
      "[36/52] Date: 2022-12-31\n",
      "  Window: 2007-12-31 to 2022-11-30\n",
      "  Assets: 266 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.01909 | Turnover: 0.0569 | TC: 0.000058 | Net:  0.01903\n",
      "\n",
      "[37/52] Date: 2023-01-31\n",
      "  Window: 2008-01-31 to 2022-12-31\n",
      "  Assets: 265 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.03588 | Turnover: 0.0968 | TC: 0.000093 | Net: -0.03598\n",
      "\n",
      "[38/52] Date: 2023-02-28\n",
      "  Window: 2008-02-29 to 2023-01-31\n",
      "  Assets: 265 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.01484 | Turnover: 0.0633 | TC: 0.000064 | Net:  0.01478\n",
      "\n",
      "[39/52] Date: 2023-03-31\n",
      "  Window: 2008-03-31 to 2023-02-28\n",
      "  Assets: 265 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.01641 | Turnover: 0.0796 | TC: 0.000081 | Net:  0.01633\n",
      "\n",
      "[40/52] Date: 2023-04-30\n",
      "  Window: 2008-04-30 to 2023-03-31\n",
      "  Assets: 266 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.05083 | Turnover: 0.0589 | TC: 0.000056 | Net: -0.05089\n",
      "\n",
      "[41/52] Date: 2023-05-31\n",
      "  Window: 2008-05-31 to 2023-04-30\n",
      "  Assets: 266 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.05528 | Turnover: 0.0668 | TC: 0.000071 | Net:  0.05521\n",
      "\n",
      "[42/52] Date: 2023-06-30\n",
      "  Window: 2008-06-30 to 2023-05-31\n",
      "  Assets: 268 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.01236 | Turnover: 0.0932 | TC: 0.000094 | Net:  0.01226\n",
      "\n",
      "[43/52] Date: 2023-07-31\n",
      "  Window: 2008-07-31 to 2023-06-30\n",
      "  Assets: 270 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.02956 | Turnover: 0.0860 | TC: 0.000083 | Net: -0.02964\n",
      "\n",
      "[44/52] Date: 2023-08-31\n",
      "  Window: 2008-08-31 to 2023-07-31\n",
      "  Assets: 272 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.04711 | Turnover: 0.0694 | TC: 0.000066 | Net: -0.04717\n",
      "\n",
      "[45/52] Date: 2023-09-30\n",
      "  Window: 2008-09-30 to 2023-08-31\n",
      "  Assets: 275 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.01839 | Turnover: 0.1337 | TC: 0.000131 | Net: -0.01852\n",
      "\n",
      "[46/52] Date: 2023-10-31\n",
      "  Window: 2008-10-31 to 2023-09-30\n",
      "  Assets: 277 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.07225 | Turnover: 0.1358 | TC: 0.000146 | Net:  0.07211\n",
      "\n",
      "[47/52] Date: 2023-11-30\n",
      "  Window: 2008-11-30 to 2023-10-31\n",
      "  Assets: 280 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.03765 | Turnover: 0.1147 | TC: 0.000119 | Net:  0.03753\n",
      "\n",
      "[48/52] Date: 2023-12-31\n",
      "  Window: 2008-12-31 to 2023-11-30\n",
      "  Assets: 280 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.00205 | Turnover: 0.0866 | TC: 0.000087 | Net:  0.00196\n",
      "\n",
      "[49/52] Date: 2024-01-31\n",
      "  Window: 2009-01-31 to 2023-12-31\n",
      "  Assets: 282 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.03071 | Turnover: 0.1114 | TC: 0.000115 | Net:  0.03059\n",
      "\n",
      "[50/52] Date: 2024-02-29\n",
      "  Window: 2009-02-28 to 2024-01-31\n",
      "  Assets: 282 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.03425 | Turnover: 0.1162 | TC: 0.000120 | Net:  0.03413\n",
      "\n",
      "[51/52] Date: 2024-03-31\n",
      "  Window: 2009-03-31 to 2024-02-29\n",
      "  Assets: 284 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.04045 | Turnover: 0.0935 | TC: 0.000090 | Net: -0.04054\n",
      "\n",
      "[52/52] Date: 2024-04-30\n",
      "  Window: 2009-04-30 to 2024-03-31\n",
      "  Assets: 282 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.01917 | Turnover: 0.1008 | TC: 0.000103 | Net:  0.01907\n",
      "\n",
      "============================================================\n",
      "BACKTEST COMPLETE\n",
      "============================================================\n",
      "Sharpe Ratio: 0.1377\n",
      "Annualized Sharpe Ratio: 0.4769\n"
     ]
    }
   ],
   "source": [
    "results_df, metrics = backtest_nodewise_gmv(\n",
    "    df,\n",
    "    test_start_date='2020-01-31',  # Last date of training period\n",
    "    test_end_date='2024-04-30',   # Last date of testing period\n",
    "    lookback_window=180,\n",
    "    transaction_cost=0.001\n",
    ")\n",
    "print(f\"Sharpe Ratio: {metrics['sharpe_ratio']:.4f}\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics['annual_sharpe_ratio']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb0ee69e-c4ba-4da2-b774-fb00a30784ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{34817: 0.00242249395553771, 20482: 0.006805074384082329, 49154: 0.003278833820521948, 52230: 0.0026929685513930827, 71175: 0.0036082967359080953, 48653: 0.0014864570824605881, 60943: 0.003418292246796153, 49680: 0.008441086495762135, 34833: 0.0037389081747815998, 59408: -0.003849968835480621, 87055: 0.006589806519631617, 72726: 0.002504080197924304, 60442: 0.005089846212758344, 23579: -0.006912055774039984, 13856: 0.010727714153810112, 43553: 0.004285533231924262, 76841: 0.0017716945499136768, 11308: 0.009798519000077924, 24109: 0.008377224229564613, 19502: 0.0029733566295818865, 66093: 0.007230487455301651, 57904: 0.0038917573025133373, 75825: 0.002124582489416908, 75828: 0.0015300394675521476, 86580: -0.0013756608637485795, 44601: 0.0036601648027149783, 60986: 0.0016762223132872065, 28222: 0.006279107597662725, 22592: 0.006825964457490043, 39490: 0.000922192264267681, 24643: 0.0007367122289558844, 59459: 0.00700499859404927, 21573: 0.0014031483106038628, 17478: 0.0037473504861341086, 78916: 0.0030139241928121645, 11850: 0.007805610457790376, 13901: 0.006267922620210153, 46674: 0.006376849739288306, 48725: 0.005451662364055509, 26710: 0.008102614583435603, 22103: 0.006385679480988413, 88661: 0.0017189215899459092, 60506: 0.0038509296030267335, 40539: 0.0061854120843679505, 89179: 0.0025104357066050714, 22111: 0.010844125286588152, 87137: -5.8791388962974907e-05, 44644: 0.007046550220992137, 13928: 0.004895084013616652, 19561: 0.003662126680654675, 89195: -0.0054439312605040445, 23660: 0.005777724456190151, 17005: 0.003985596443380031, 18542: 0.0019552232304481743, 66157: 0.0068557832037806875, 36468: 0.00529038073012822, 86136: 0.008390750747603705, 41080: -9.208173257904379e-05, 85631: -0.0006028287292785517, 78975: 0.004613623046971086, 59010: 0.001808471688264756, 81540: 0.00491675805230132, 66181: 0.00629408130976276, 11404: 0.009638514444471882, 24205: 0.007754741059510582, 62092: 0.004557906116060754, 77462: -0.00011956322049074084, 81055: 0.0027481393751982567, 23712: 0.006348687736555793, 84129: -0.0009654873184988295, 81061: 0.0030971604065337913, 82598: 0.001356382016072097, 55976: 0.00747998527412258, 89258: 0.002422823494931834, 11955: 0.009086519038446154, 27828: 0.002563325708957723, 61621: 0.006422245544412494, 45751: 0.0074797821911528435, 14008: 0.0033003212575427637, 25785: -0.003924777511935427, 21178: 0.006145475537848533, 60599: 0.0036830348402682195, 50876: 0.006324766160588075, 23229: 0.006698848278741548, 24766: 0.005878742825376851, 64186: 0.0022743539331904258, 79547: 0.0055167311385660184, 60097: 0.0057241416698822906, 21186: 0.0030225177944649124, 62148: 0.0032991721556313064, 26825: 0.008379905396770124, 12490: 0.005317641916870902, 14541: 0.007168360342575789, 37584: 0.004325870119585351, 80080: 0.0025267372629738513, 60628: 0.0035473100476799578, 21207: 0.001612662309064802, 16600: 0.006529406312673592, 42200: 0.003521667998577557, 39642: 0.006361196295711616, 15579: 0.004842046127329997, 82651: 0.0032321338700276275, 15069: -0.0008144574604435786, 49373: 0.002580248329420484, 22752: 0.004866961873672218, 57568: 0.004973479827160976, 35554: 0.005817320125511128, 35044: -0.00018793007407494184, 80100: 0.0046204010622607795, 25320: 0.005798616127022949, 27887: 0.005452144080842056, 34032: -0.0014296446850977627, 66800: -0.0031333491945764163, 52978: 0.003268480033091994, 18163: 0.009619909734060588, 75510: 0.0030435605272189996, 81655: 0.002663659579148748, 17144: 0.009110723892230081, 29946: 0.005833002757523654, 22779: 0.002809769945455679, 52476: 0.003941714491369741, 56573: 0.006447925406645992, 82686: 0.0021185940494080984, 14593: 0.0022113820227164086, 23819: 0.0003797941115638942, 38156: 0.002331997685547059, 21776: 0.006115650563133431, 10516: 0.0028493298228122878, 12052: 0.0064464144351198465, 22293: 0.0023913637649892456, 85269: 0.0013812463641753472, 47896: 0.004820736406392407, 64282: 0.001211025397788568, 75034: 0.0011568864107967328, 12060: 0.003241857416801548, 12062: 0.006669746024661181, 21792: 0.005646797794695604, 87842: 0.004784889278924082, 26403: 0.00598830427981231, 77605: 0.0022041812727343142, 16678: 0.0037229064094727727, 46886: 0.0010547148221175182, 59176: 0.003072565271427464, 18729: 0.00976819814366741, 61735: 0.005278937546455846, 77606: 0.0025511683222625933, 76076: 0.0040591158713417395, 60206: 0.004664456330199359, 38703: 0.00444436064959907, 27959: 0.010894135106622904, 64311: 0.0029242221810740366, 58683: 0.002478103354100519, 76605: 0.005007285641394193, 57665: 0.00436586437681025, 28484: 0.00031356215884465014, 52038: 0.007263982348121699, 80711: 0.0009089877596588251, 53065: 0.00044856466826220364, 25419: -0.0018142725559745433, 27983: 0.0021770892553231325, 40272: 0.005517191982293323, 65875: 0.007068600444381497, 86356: 0.0021178174071880035, 86868: 0.0029271953113015605, 17750: 0.009605236409009453, 27991: 0.007266115340647924, 43350: 0.004817196334392918, 75607: 0.002225751795468253, 82775: -0.005041946978393583, 75100: 0.0018771728601933175, 25953: 0.004802439697245042, 15202: 0.0024134431893058535, 62308: 0.006678169243597764, 85348: 0.005132780444532329, 15720: 0.00508343029054263, 38762: 0.006427669441313745, 53613: -6.535526682718345e-05, 14702: 0.002466309122946923, 24942: 0.005975266777892687, 59248: 0.0033352186555208403, 81774: -0.004450029112232268, 49015: -0.0064882648957655, 10104: 0.004832476774101592, 70519: -0.003980276518310736, 48506: 0.0019327726057283266, 21371: 0.00425807479003759, 23931: 0.009690345640749269, 10107: 0.0039881006937233605, 52090: 0.007811203732534549, 77178: 0.0020600715766753625, 54148: 0.0003510303707160084, 58246: 0.004869582185396234, 64390: 0.005319419210225126, 77702: 0.003342632456507011, 87432: 0.002649147041253321, 41355: 0.003708702435430757, 71563: 0.004372901144999939, 70033: -0.0005122099043372597, 75154: 0.003229929228470713, 84373: 0.005653387827265058, 19350: 0.003403546792918827, 83862: -0.0014166197461165956, 87447: 0.006047457174680284, 24985: 0.0069657831265884105, 11674: 0.008485340181756548, 10138: 0.004757118225659887, 42906: -0.00045481610840268324, 84381: -9.446922114070193e-05, 85913: 0.0033063366024207188, 85914: 0.0008842947407267014, 10145: 0.006951669758222859, 17830: 0.008289980709620922, 85926: 0.0034933867742790985, 64936: 0.009176897330789273, 69032: 0.0013871486884002113, 76201: 0.0032921406207244187, 76712: 0.003070085194541151, 69550: 0.002122923113493589, 21936: 0.006099393845482792, 23473: 0.006376137352075917, 70578: 0.007839845629621383, 73139: 0.004452177056603689, 75186: 0.0031961276343663737, 89525: 0.004471535284033071, 43449: 0.00919402479208594, 34746: -0.0023023009847248565, 59328: 0.004269459465898026, 19393: 0.003821310010870053, 76226: -2.3754904112572182e-05, 14277: 0.0025826698571871465, 60871: 0.004049077070343479, 10696: 0.005376507367008939, 24010: 0.00669408822527169, 56274: 0.004142946248173651, 52695: 0.003951449100410552, 61399: 0.0032210317331635937, 30681: 0.006867982419780582, 57817: 0.0007766779533779953, 77274: 0.003371722571465257, 79323: 0.0056696570206098895, 64995: 0.002773755920533207, 18411: 0.011731726690125297, 22509: 0.006349514984410166, 39917: 0.003330698400592668, 89070: 0.003378702042327517, 92655: 0.004027255940376549, 11762: 0.004185373237393728, 23026: 0.0052387750981751835, 46578: 0.0083513612007001, 22517: 0.007212700787354029, 49656: 0.005340531234573654, 25081: 0.004334989989824289}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with pd.option_context(\"display.max_rows\", None):\n",
    "    print(results_df['portfolio_weights'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03bf25e0-0334-4df8-886c-e976651a4fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3756070714683275"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['total_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0191badd-87f7-4aed-bf07-18a6ab10b8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0023410463166250403"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['variance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5f0763c1-0ad6-492b-bf8a-e68b3703e9e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09082020565331547"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['portfolio_turnover'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd632c-26c3-4192-add1-9370f816e73e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
