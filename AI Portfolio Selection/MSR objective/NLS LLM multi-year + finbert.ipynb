{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c813f69-a0eb-41a2-b3c2-4b9cabf13451",
   "metadata": {},
   "source": [
    "# INTERSECTON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76f4f73d-ffcf-4c03-a782-fc89a37050aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy.linalg import sqrtm, cholesky, cho_solve\n",
    "import nonlinshrink as nls\n",
    "\n",
    "def nlshrink_cov(Y, k=1):\n",
    "    \"\"\"\n",
    "    Nonlinear shrinkage covariance estimation.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Y : array-like, shape (n_samples, n_features)\n",
    "        Data matrix\n",
    "    k : int\n",
    "        Number of factors (parameter for compatibility, may not be used)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    theta : array, shape (n_features, n_features)\n",
    "        Shrinkage covariance estimate\n",
    "    \"\"\"\n",
    "    # Using the non-linear-shrinkage package\n",
    "    # This implements the Ledoit & Wolf nonlinear shrinkage method\n",
    "    return nls.shrink_cov(Y)\n",
    "\n",
    "\n",
    "def msr_weights(Theta_hat, mu):\n",
    "    \"\"\"\n",
    "    Compute Maximum Sharpe Ratio portfolio weights.\n",
    "    \n",
    "    The maximum Sharpe ratio portfolio solves:\n",
    "    max (w' mu) / sqrt(w' Sigma w)\n",
    "    \n",
    "    Solution (when mu represents excess returns):\n",
    "    w ∝ Sigma^{-1} mu = Theta mu\n",
    "    \n",
    "    Then normalize so that sum(w) = 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix (Sigma^{-1})\n",
    "    mu : np.ndarray, shape (p,)\n",
    "        Expected excess returns\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights (sum to 1)\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # Compute unnormalized weights: w ∝ Theta mu\n",
    "    w_unnorm = Theta_hat @ mu\n",
    "    \n",
    "    # Normalize to sum to 1\n",
    "    weight_sum = np.sum(w_unnorm)\n",
    "    \n",
    "    if np.abs(weight_sum) < 1e-10:\n",
    "        print('WARNING: Weight sum near zero, returning equal weights')\n",
    "        return ones_p / p\n",
    "    \n",
    "    w_star = w_unnorm / weight_sum\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "\n",
    "def load_yearly_signals(year, buys_path_template='buys_{}.csv', sells_path_template='sells_{}.csv'):\n",
    "    \"\"\"\n",
    "    Load buy and sell signals for a specific year.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    year : int\n",
    "        Year to load signals for\n",
    "    buys_path_template : str\n",
    "        Template for buys file path (use {} for year placeholder)\n",
    "    sells_path_template : str\n",
    "        Template for sells file path (use {} for year placeholder)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    permno_set : set\n",
    "        Set of permnos in the buy and sell signals for this year\n",
    "    \"\"\"\n",
    "    try:\n",
    "        buys = pd.read_csv(buys_path_template.format(year), index_col=1)\n",
    "        sells = pd.read_csv(sells_path_template.format(year), index_col=1)\n",
    "        \n",
    "        buys.index.name = 'permno'\n",
    "        sells.index.name = 'permno'\n",
    "        \n",
    "        buys_index = buys.index.astype(int)\n",
    "        sells_index = sells.index.astype(int)\n",
    "        \n",
    "        return set(buys_index.union(sells_index))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  ⚠ Warning: Could not load signals for year {year}: {e}\")\n",
    "        return set()\n",
    "\n",
    "\n",
    "def load_finbert_signals(signals_path):\n",
    "    \"\"\"\n",
    "    Load FinBERT monthly signals from CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signals_path : str\n",
    "        Path to monthly_signals.csv file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    signals_df : pd.DataFrame\n",
    "        DataFrame with columns: symbol, company, year_month, signal, avg_sentiment_score\n",
    "    \"\"\"\n",
    "    try:\n",
    "        signals_df = pd.read_csv(signals_path)\n",
    "        # Convert year_month to datetime (end of month)\n",
    "        signals_df['date'] = pd.to_datetime(signals_df['year_month']) + pd.offsets.MonthEnd(0)\n",
    "        return signals_df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  ⚠ Warning: Could not load FinBERT signals: {e}\")\n",
    "        return pd.DataFrame(columns=['symbol', 'company', 'year_month', 'signal', 'date'])\n",
    "\n",
    "\n",
    "def get_finbert_permnos_for_date(signals_df, ticker_to_permno, date):\n",
    "    \"\"\"\n",
    "    Get set of permnos with 'buy' or 'sell' signals for a specific date.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signals_df : pd.DataFrame\n",
    "        FinBERT signals dataframe\n",
    "    ticker_to_permno : dict\n",
    "        Mapping from ticker symbol to permno\n",
    "    date : pd.Timestamp\n",
    "        Date to get signals for\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    permno_set : set\n",
    "        Set of permnos with buy or sell signals on this date\n",
    "    \"\"\"\n",
    "    # Get signals for this date\n",
    "    date_signals = signals_df[signals_df['date'] == date]\n",
    "    \n",
    "    # Filter for buy and sell signals (exclude hold)\n",
    "    buy_signals = date_signals[date_signals['signal'] == 'buy']\n",
    "    sell_signals = date_signals[date_signals['signal'] == 'sell']\n",
    "    \n",
    "    # Convert tickers to permnos\n",
    "    permnos = set()\n",
    "    for ticker in buy_signals['symbol'].values:\n",
    "        if ticker in ticker_to_permno:\n",
    "            permnos.add(ticker_to_permno[ticker])\n",
    "    for ticker in sell_signals['symbol'].values:\n",
    "        if ticker in ticker_to_permno:\n",
    "            permnos.add(ticker_to_permno[ticker])\n",
    "    \n",
    "    return permnos\n",
    "\n",
    "\n",
    "def create_ticker_to_permno_mapping(df):\n",
    "    \"\"\"\n",
    "    Create a mapping from ticker to permno from the returns dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Returns dataframe with 'ticker' and 'permno' columns\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    ticker_to_permno : dict\n",
    "        Mapping from ticker to permno (uses most recent permno for each ticker)\n",
    "    \"\"\"\n",
    "    if 'ticker' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have 'ticker' column for mapping\")\n",
    "    \n",
    "    # Drop NaN tickers\n",
    "    valid_df = df[df['ticker'].notna()].copy()\n",
    "    \n",
    "    # Get the most recent permno for each ticker\n",
    "    ticker_to_permno = valid_df.groupby('ticker')['permno'].last().to_dict()\n",
    "    \n",
    "    return ticker_to_permno\n",
    "\n",
    "\n",
    "def calculate_exit_transaction_cost(prev_weights_dict, prev_oos_returns_dict, \n",
    "                                    prev_gross_return, transaction_cost, verbose=False):\n",
    "    \"\"\"\n",
    "    Calculate transaction cost when exiting the market (liquidating all positions).\n",
    "    Enforces Immediate Liquidation logic:\n",
    "    - Next period return is 0.0 (Cash)\n",
    "    - Cost is paid on current portfolio value\n",
    "    \"\"\"\n",
    "    if len(prev_weights_dict) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    \n",
    "    # Step 1: Adjust previous weights to current period's BEGINNING (drift from t-1 to t)\n",
    "    adjusted_prev = {}\n",
    "    for asset, prev_w in prev_weights_dict.items():\n",
    "        if asset in prev_oos_returns_dict:\n",
    "            prev_r = prev_oos_returns_dict[asset]\n",
    "            if abs(1 + prev_gross_return) > 1e-6:\n",
    "                adjusted_prev[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return)\n",
    "            else:\n",
    "                adjusted_prev[asset] = 0.0\n",
    "        else:\n",
    "            if abs(1 + prev_gross_return) > 1e-6:\n",
    "                adjusted_prev[asset] = prev_w / (1 + prev_gross_return)\n",
    "            else:\n",
    "                adjusted_prev[asset] = 0.0\n",
    "    \n",
    "    # Step 2: Turnover (Selling everything to Cash)\n",
    "    turnover = sum(abs(w) for w in adjusted_prev.values())\n",
    "    \n",
    "    # Step 3: Cost \n",
    "    # Paper Formula: c * (1 + R_next) * Turnover. \n",
    "    # Since R_next (Cash) is 0.0, this simplifies to c * 1.0 * Turnover.\n",
    "    tc = transaction_cost * 1.0 * turnover\n",
    "    \n",
    "    # Step 4: Net Return is 0.0 (Cash return) - Cost\n",
    "    net_return = -tc\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  Liquidating positions | Turnover: {turnover:>6.4f} | TC: {tc:>8.6f}\")\n",
    "    \n",
    "    return turnover, tc, net_return\n",
    "\n",
    "def backtest_nodewise_gmv_combined(df, \n",
    "                                    test_start_date='2020-01-31', \n",
    "                                    test_end_date='2024-11-30',\n",
    "                                    lookback_window=180,\n",
    "                                    transaction_cost=0.001,\n",
    "                                    buys_path_template='buys_{}.csv',\n",
    "                                    sells_path_template='sells_{}.csv',\n",
    "                                    finbert_signals_path=None,\n",
    "                                    verbose=True):\n",
    "    \"\"\"\n",
    "    Backtest Nodewise + GMV strategy with year-specific buy/sell signals \n",
    "    and FinBERT sentiment signals.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with columns: permno, datadate, ticker, ret_fwd_1\n",
    "    test_start_date : str\n",
    "        First date for out-of-sample returns (format: 'YYYY-MM-DD')\n",
    "    test_end_date : str\n",
    "        Last date for out-of-sample returns (format: 'YYYY-MM-DD')\n",
    "    lookback_window : int\n",
    "        Number of months in rolling training window (default: 180)\n",
    "    transaction_cost : float\n",
    "        Proportional transaction cost (default: 0.001 = 10 bps)\n",
    "    buys_path_template : str\n",
    "        Template for buys file path (use {} for year placeholder)\n",
    "    sells_path_template : str\n",
    "        Template for sells file path (use {} for year placeholder)\n",
    "    finbert_signals_path : str or None\n",
    "        Path to FinBERT signals CSV file. If None, only uses buy/sell signals.\n",
    "    verbose : bool\n",
    "        If True, prints detailed log at each time step.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results_df : pd.DataFrame\n",
    "        DataFrame with columns: date, portfolio_return, cumulative_return\n",
    "    metrics : dict\n",
    "        Overall performance metrics\n",
    "    \"\"\"\n",
    "    # --- 1. Setup ---\n",
    "    df = df.copy()\n",
    "    if 'datadate' not in df.columns or 'permno' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have 'datadate' and 'permno' columns\")\n",
    "    df['datadate'] = pd.to_datetime(df['datadate'])\n",
    "    \n",
    "    # Create ticker to permno mapping\n",
    "    if verbose:\n",
    "        print(\"Creating ticker to permno mapping...\")\n",
    "    ticker_to_permno = create_ticker_to_permno_mapping(df)\n",
    "    if verbose:\n",
    "        print(f\"Mapped {len(ticker_to_permno)} unique tickers to permnos\")\n",
    "    \n",
    "    # Load FinBERT signals if provided\n",
    "    finbert_df = None\n",
    "    if finbert_signals_path is not None:\n",
    "        finbert_df = load_finbert_signals(finbert_signals_path)\n",
    "        if verbose and len(finbert_df) > 0:\n",
    "            print(f\"Loaded FinBERT signals: {len(finbert_df)} monthly records\")\n",
    "            print(f\"FinBERT signal distribution:\")\n",
    "            print(finbert_df['signal'].value_counts())\n",
    "    \n",
    "    # Get unique dates\n",
    "    all_dates = sorted(df['datadate'].unique())\n",
    "    \n",
    "    # Convert test dates to datetime\n",
    "    test_start_dt = pd.to_datetime(test_start_date)\n",
    "    test_end_dt = pd.to_datetime(test_end_date)\n",
    "    \n",
    "    # Find date indices\n",
    "    try:\n",
    "        test_start_idx = all_dates.index(test_start_dt)\n",
    "        test_end_idx = all_dates.index(test_end_dt)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Date not found in DataFrame: {e}\")\n",
    "    \n",
    "    if test_start_idx < lookback_window:\n",
    "        raise ValueError(f\"Not enough data for lookback. Test start date {test_start_date} \"\n",
    "                         f\"requires data back to {all_dates[test_start_idx - lookback_window]}, \"\n",
    "                         f\"but only {test_start_idx} periods are available.\")\n",
    "    \n",
    "    # Storage for results\n",
    "    portfolio_returns = []\n",
    "    portfolio_dates = []\n",
    "    portfolio_weights_list = []\n",
    "    portfolio_turnover_list = []\n",
    "    portfolio_gross_returns = []\n",
    "    \n",
    "    # Track weights by permno\n",
    "    prev_weights_dict = {}\n",
    "    prev_oos_returns_dict = {}\n",
    "    prev_gross_return = 0.0\n",
    "    \n",
    "    # Cache for yearly signals\n",
    "    yearly_signals_cache = {}\n",
    "    \n",
    "    # --- 2. Rolling Window Backtest ---\n",
    "    if verbose:\n",
    "        print(\"=\"*60)\n",
    "        print(\"STARTING BACKTEST WITH YEARLY + FINBERT SIGNALS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "    for t in range(test_start_idx, test_end_idx + 1):\n",
    "        current_date = all_dates[t]\n",
    "        current_year = current_date.year\n",
    "        \n",
    "        # Load signals for current year if not cached\n",
    "        if current_year not in yearly_signals_cache:\n",
    "            yearly_signals_cache[current_year] = load_yearly_signals(\n",
    "                current_year, buys_path_template, sells_path_template\n",
    "            )\n",
    "        \n",
    "        yearly_permnos = yearly_signals_cache[current_year]\n",
    "        \n",
    "        # Get FinBERT signals for current date\n",
    "        finbert_permnos = set()\n",
    "        if finbert_df is not None and len(finbert_df) > 0:\n",
    "            finbert_permnos = get_finbert_permnos_for_date(finbert_df, ticker_to_permno, current_date)\n",
    "        \n",
    "        # UNION of yearly signals and FinBERT signals\n",
    "        allowed_permnos = yearly_permnos.intersection(finbert_permnos)\n",
    "        if len(allowed_permnos) <= 1:\n",
    "            allowed_permnos = yearly_permnos.union(finbert_permnos)\n",
    "        \n",
    "        # ========================================\n",
    "        # CRITICAL: Get OOS returns FIRST before any early exits\n",
    "        # ========================================\n",
    "        oos_data = df[(df['datadate'] == current_date) & (df['permno'].isin(allowed_permnos))]\n",
    "        oos_returns_series = oos_data.set_index('permno')['ret_fwd_1']\n",
    "        oos_returns_series = oos_returns_series.dropna()\n",
    "        oos_returns_dict = oos_returns_series.to_dict()\n",
    "        \n",
    "        # Now handle early exit cases\n",
    "        if len(allowed_permnos) == 0:\n",
    "            if verbose:\n",
    "                print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                      f\"Date: {current_date.strftime('%Y-%m-%d')}\")\n",
    "                print(f\"  ⚠ No signals for {current_date.strftime('%Y-%m-%d')}, recording zero return\")\n",
    "            \n",
    "            # Now oos_returns_dict is defined and can be passed\n",
    "            turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                prev_weights_dict, \n",
    "                prev_oos_returns_dict, \n",
    "                prev_gross_return, \n",
    "                transaction_cost,\n",
    "                verbose=verbose\n",
    "            )\n",
    "            \n",
    "            portfolio_returns.append(net_return)\n",
    "            portfolio_dates.append(current_date)\n",
    "            portfolio_weights_list.append({})\n",
    "            portfolio_turnover_list.append(turnover)\n",
    "            portfolio_gross_returns.append(0.0)\n",
    "            \n",
    "            prev_weights_dict = {}\n",
    "            prev_oos_returns_dict = {}\n",
    "            prev_gross_return = 0.0\n",
    "            continue\n",
    "        \n",
    "        # Define the lookback window\n",
    "        window_start_date = all_dates[t - lookback_window]\n",
    "        window_end_date = all_dates[t - 1]\n",
    "        \n",
    "        # Get training data for this window\n",
    "        train_data = df[(df['datadate'] >= window_start_date) & \n",
    "                        (df['datadate'] <= window_end_date) &\n",
    "                        (df['permno'].isin(allowed_permnos))]\n",
    "        \n",
    "        # Pivot to get returns matrix\n",
    "        returns_pivot = train_data.pivot(index='datadate', columns='permno', values='ret_fwd_1')\n",
    "        window_dates = all_dates[t - lookback_window : t]\n",
    "        returns_pivot = returns_pivot.reindex(index=window_dates)\n",
    "        \n",
    "        # Filter assets with any NaNs\n",
    "        nan_assets = returns_pivot.columns[returns_pivot.isna().any()]\n",
    "        filtered_pivot = returns_pivot.drop(columns=nan_assets)\n",
    "        \n",
    "        current_assets = filtered_pivot.columns.tolist()\n",
    "        Y = filtered_pivot.values\n",
    "        n_train, p_current = Y.shape\n",
    "    \n",
    "        if verbose:\n",
    "            print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                  f\"Date: {current_date.strftime('%Y-%m-%d')} | Year: {current_year}\")\n",
    "            print(f\"  Window: {window_start_date.strftime('%Y-%m-%d')} to \"\n",
    "                  f\"{window_end_date.strftime('%Y-%m-%d')}\")\n",
    "            print(f\"  Yearly: {len(yearly_permnos)} | FinBERT: {len(finbert_permnos)} | \"\n",
    "                  f\"Union/Intersection: {len(allowed_permnos)} | Assets w/ data: {p_current}\")\n",
    "    \n",
    "        # Check for valid data\n",
    "        if n_train < lookback_window or p_current < 2:\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ Insufficient data (n={n_train}, p={p_current}), recording zero return\")\n",
    "            \n",
    "            turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                prev_weights_dict, \n",
    "                prev_oos_returns_dict, \n",
    "                prev_gross_return, \n",
    "                transaction_cost,\n",
    "                verbose=verbose\n",
    "            )\n",
    "            \n",
    "            portfolio_returns.append(net_return)\n",
    "            portfolio_dates.append(current_date)\n",
    "            portfolio_weights_list.append({})\n",
    "            portfolio_turnover_list.append(turnover)\n",
    "            portfolio_gross_returns.append(0.0)\n",
    "            \n",
    "            prev_weights_dict = {}\n",
    "            prev_oos_returns_dict = {}\n",
    "            prev_gross_return = 0.0\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Demean the returns\n",
    "            Y_bar = Y.mean(axis=0)\n",
    "            Y_star = Y - Y_bar\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  Running NLS Regression...\")\n",
    "            Sigma_hat = nlshrink_cov(Y_star)\n",
    "            # Invert to get precision matrix\n",
    "            try:\n",
    "                Theta_hat = np.linalg.inv(Sigma_hat)\n",
    "            except np.linalg.LinAlgError:\n",
    "                # If inversion fails, use pseudo-inverse\n",
    "                if verbose:\n",
    "                    print(f\"  ⚠ Covariance matrix singular, using pseudo-inverse\")\n",
    "                Theta_hat = np.linalg.pinv(Sigma_hat)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  Computing MSR weights...\")\n",
    "\n",
    "            mu = Y.mean(axis=0)\n",
    "            \n",
    "            w_star = msr_weights(Theta_hat, mu)\n",
    "            \n",
    "            # Create weights dictionary\n",
    "            new_weights_dict = {asset: w_star[i] for i, asset in enumerate(current_assets)}\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"  ✗ Error: {e}\")\n",
    "                print(f\"  Recording zero return\")\n",
    "            \n",
    "            # Calculate transaction cost from liquidating previous positions\n",
    "            turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "            prev_weights_dict, \n",
    "            prev_oos_returns_dict, \n",
    "            prev_gross_return, \n",
    "            transaction_cost,\n",
    "            verbose=verbose\n",
    "        )\n",
    "            \n",
    "            # Record zero return with empty weights\n",
    "            portfolio_returns.append(net_return)\n",
    "            portfolio_dates.append(current_date)\n",
    "            portfolio_weights_list.append({})\n",
    "            portfolio_turnover_list.append(turnover)\n",
    "            portfolio_gross_returns.append(0.0)\n",
    "            \n",
    "            # Reset previous state\n",
    "            prev_weights_dict = {}\n",
    "            prev_oos_returns_dict = {}\n",
    "            prev_gross_return = 0.0\n",
    "            continue\n",
    "\n",
    "        # Normalize weights to sum to 1\n",
    "        weight_sum = sum(new_weights_dict.values())\n",
    "        if weight_sum > 1e-10:\n",
    "            new_weights_dict = {k: v/weight_sum for k, v in new_weights_dict.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ Zero weight sum, recording zero return\")\n",
    "            \n",
    "            # Calculate transaction cost from liquidating previous positions\n",
    "            turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "            prev_weights_dict, \n",
    "            prev_oos_returns_dict, \n",
    "            prev_gross_return, \n",
    "            transaction_cost,\n",
    "            verbose=verbose\n",
    "        )\n",
    "            \n",
    "            # Record zero return with empty weights\n",
    "            portfolio_returns.append(net_return)\n",
    "            portfolio_dates.append(current_date)\n",
    "            portfolio_weights_list.append({})\n",
    "            portfolio_turnover_list.append(turnover)\n",
    "            portfolio_gross_returns.append(0.0)\n",
    "            \n",
    "            # Reset previous state\n",
    "            prev_weights_dict = {}\n",
    "            prev_oos_returns_dict = {}\n",
    "            prev_gross_return = 0.0\n",
    "            continue\n",
    "        \n",
    "        # --- 3. OOS Returns & Transaction Costs ---\n",
    "        \n",
    "        # Find common assets between weights and returns\n",
    "        common_assets = set(new_weights_dict.keys()) & set(oos_returns_dict.keys())\n",
    "        \n",
    "        if len(common_assets) == 0:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ No common assets with valid returns, recording zero return\")\n",
    "            \n",
    "            # Calculate transaction cost from liquidating previous positions\n",
    "            turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "            prev_weights_dict, \n",
    "            prev_oos_returns_dict, \n",
    "            prev_gross_return, \n",
    "            transaction_cost,\n",
    "            verbose=verbose\n",
    "        )\n",
    "            \n",
    "            # Record zero return with empty weights\n",
    "            portfolio_returns.append(net_return)\n",
    "            portfolio_dates.append(current_date)\n",
    "            portfolio_weights_list.append({})\n",
    "            portfolio_turnover_list.append(turnover)\n",
    "            portfolio_gross_returns.append(0.0)\n",
    "            \n",
    "            # Reset previous state\n",
    "            prev_weights_dict = {}\n",
    "            prev_oos_returns_dict = {}\n",
    "            prev_gross_return = 0.0\n",
    "            continue\n",
    "        \n",
    "        # Filter to common assets and renormalize\n",
    "        common_weights = {a: new_weights_dict[a] for a in common_assets}\n",
    "        common_weight_sum = sum(common_weights.values())\n",
    "        if common_weight_sum > 1e-10:\n",
    "            common_weights = {k: v/common_weight_sum for k, v in common_weights.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ Zero weight sum after filtering, recording zero return\")\n",
    "            \n",
    "            # Calculate transaction cost from liquidating previous positions\n",
    "            turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "            prev_weights_dict, \n",
    "            prev_oos_returns_dict, \n",
    "            prev_gross_return, \n",
    "            transaction_cost,\n",
    "            verbose=verbose\n",
    "        )\n",
    "            \n",
    "            # Record zero return with empty weights\n",
    "            portfolio_returns.append(net_return)\n",
    "            portfolio_dates.append(current_date)\n",
    "            portfolio_weights_list.append({})\n",
    "            portfolio_turnover_list.append(turnover)\n",
    "            portfolio_gross_returns.append(0.0)\n",
    "            \n",
    "            # Reset previous state\n",
    "            prev_weights_dict = {}\n",
    "            prev_oos_returns_dict = {}\n",
    "            prev_gross_return = 0.0\n",
    "            continue\n",
    "        \n",
    "        # Compute gross portfolio return\n",
    "        gross_return = sum(common_weights[a] * oos_returns_dict[a] for a in common_assets)\n",
    "        \n",
    "        # Sanity check\n",
    "        if np.isnan(gross_return) or np.isinf(gross_return):\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ Invalid gross return: {gross_return}, recording zero return\")\n",
    "            \n",
    "            # Calculate transaction cost from liquidating previous positions\n",
    "            turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "            prev_weights_dict, \n",
    "            prev_oos_returns_dict, \n",
    "            prev_gross_return, \n",
    "            transaction_cost,\n",
    "            verbose=verbose\n",
    "        )\n",
    "            \n",
    "            # Record zero return with empty weights\n",
    "            portfolio_returns.append(net_return)\n",
    "            portfolio_dates.append(current_date)\n",
    "            portfolio_weights_list.append({})\n",
    "            portfolio_turnover_list.append(turnover)\n",
    "            portfolio_gross_returns.append(0.0)\n",
    "            \n",
    "            # Reset previous state\n",
    "            prev_weights_dict = {}\n",
    "            prev_oos_returns_dict = {}\n",
    "            prev_gross_return = 0.0\n",
    "            continue\n",
    "        \n",
    "        # Calculate transaction costs\n",
    "        if len(prev_weights_dict) > 0:\n",
    "            # Step 1: Adjust ALL previous weights for returns\n",
    "            # This gives us the portfolio composition after returns but before rebalancing\n",
    "            adjusted_prev = {}\n",
    "            \n",
    "            for asset, prev_w in prev_weights_dict.items():\n",
    "                if asset in prev_oos_returns_dict:\n",
    "                    prev_r = prev_oos_returns_dict[asset]\n",
    "                    # Safer division check\n",
    "                    if abs(1 + prev_gross_return) > 1e-6:\n",
    "                        adjusted_prev[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return)\n",
    "                    else:\n",
    "                        # Portfolio nearly went to zero - conservative approach\n",
    "                        adjusted_prev[asset] = 0.0\n",
    "                else:\n",
    "                    print('ASLKDJHAFLKJSDFH')\n",
    "                    # Asset had weight but no return data\n",
    "                    # Conservative: assume it returned 0% (stayed at same value)\n",
    "                    # So its weight adjusts by the inverse of portfolio growth\n",
    "                    if abs(1 + prev_gross_return) > 1e-6:\n",
    "                        adjusted_prev[asset] = prev_w / (1 + prev_gross_return)\n",
    "                    else:\n",
    "                        adjusted_prev[asset] = 0.0\n",
    "            \n",
    "            # Step 2: Calculate turnover\n",
    "            # Get all assets involved in trading (held before OR after)\n",
    "            all_assets = set(adjusted_prev.keys()) | set(common_weights.keys())\n",
    "            \n",
    "            # Turnover = sum of |new_weight - old_adjusted_weight| for all assets\n",
    "            turnover = 0.0\n",
    "            for asset in all_assets:\n",
    "                old_w = adjusted_prev.get(asset, 0.0)  # Weight after returns, before rebalancing\n",
    "                new_w = common_weights.get(asset, 0.0)  # Target weight after rebalancing\n",
    "                turnover += abs(new_w - old_w)\n",
    "            \n",
    "            # Transaction cost on end-of-period portfolio value\n",
    "            tc = transaction_cost * (1 + gross_return) * turnover\n",
    "        \n",
    "        else:\n",
    "            # First period: no previous positions, buying into everything\n",
    "            turnover = sum(abs(w) for w in common_weights.values())\n",
    "            tc = transaction_cost * (1 + gross_return) * turnover\n",
    "        \n",
    "        # Net return\n",
    "        net_return = gross_return - tc\n",
    "        \n",
    "        # Store results\n",
    "        portfolio_returns.append(net_return)\n",
    "        portfolio_dates.append(current_date)\n",
    "        portfolio_weights_list.append(common_weights.copy())\n",
    "        portfolio_turnover_list.append(turnover)\n",
    "        portfolio_gross_returns.append(gross_return)\n",
    "        \n",
    "        # Update previous values for next iteration\n",
    "        prev_weights_dict = common_weights.copy()\n",
    "        prev_oos_returns_dict = {a: oos_returns_dict[a] for a in common_assets}\n",
    "        prev_gross_return = gross_return\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Gross: {gross_return:>8.5f} | Turnover: {turnover:>6.4f} | \"\n",
    "                  f\"TC: {tc:>8.6f} | Net: {net_return:>8.5f}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BACKTEST COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    # --- 4. Compile Results ---\n",
    "    results_df = pd.DataFrame({\n",
    "        'date': portfolio_dates,\n",
    "        'portfolio_return': portfolio_returns,\n",
    "        'portfolio_gross_return': portfolio_gross_returns,\n",
    "        'portfolio_weights': portfolio_weights_list,\n",
    "        'portfolio_turnover': portfolio_turnover_list\n",
    "    })\n",
    "    results_df['cumulative_return'] = (1 + results_df['portfolio_return']).cumprod() - 1\n",
    "    \n",
    "    # Compute overall metrics\n",
    "    if len(portfolio_returns) > 0:\n",
    "        mean_return = np.mean(portfolio_returns)\n",
    "        variance = np.var(portfolio_returns, ddof=1)\n",
    "        sharpe_ratio = mean_return / np.sqrt(variance) if variance > 0 else 0\n",
    "        \n",
    "        # Annualized metrics (monthly data)\n",
    "        annual_return = mean_return * 12\n",
    "        annual_volatility = np.sqrt(variance * 12)\n",
    "        annual_sharpe = annual_return / annual_volatility if annual_volatility > 0 else 0\n",
    "        \n",
    "        metrics = {\n",
    "            'mean_return': mean_return,\n",
    "            'variance': variance,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'annual_return': annual_return,\n",
    "            'annual_volatility': annual_volatility,\n",
    "            'annual_sharpe_ratio': annual_sharpe,\n",
    "            'total_return': results_df['cumulative_return'].iloc[-1],\n",
    "            'avg_turnover': np.mean(portfolio_turnover_list),\n",
    "            'n_periods': len(portfolio_returns),\n",
    "            'n_zero_periods': sum(1 for r in portfolio_returns if r == 0)\n",
    "        }\n",
    "    else:\n",
    "        metrics = {\n",
    "            'mean_return': 0,\n",
    "            'variance': 0,\n",
    "            'sharpe_ratio': 0,\n",
    "            'annual_return': 0,\n",
    "            'annual_volatility': 0,\n",
    "            'annual_sharpe_ratio': 0,\n",
    "            'total_return': 0,\n",
    "            'avg_turnover': 0,\n",
    "            'n_periods': 0,\n",
    "            'n_zero_periods': 0\n",
    "        }\n",
    "    \n",
    "    return results_df, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010cc24c-b8b4-4168-8902-5db6fce7a582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../green cleaned.csv', dtype={'ncusip': 'string'})\n",
    "df['ret_fwd_1'] = df.groupby('permno')['ret_excess'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9d036f7-3ed6-4eaf-b1ac-da6c3a42d104",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ticker to permno mapping...\n",
      "Mapped 1664 unique tickers to permnos\n",
      "Loaded FinBERT signals: 24780 monthly records\n",
      "FinBERT signal distribution:\n",
      "signal\n",
      "hold    23840\n",
      "sell      529\n",
      "buy       411\n",
      "Name: count, dtype: int64\n",
      "============================================================\n",
      "STARTING BACKTEST WITH YEARLY + FINBERT SIGNALS\n",
      "============================================================\n",
      "\n",
      "[1/52] Date: 2020-01-31 | Year: 2020\n",
      "  Window: 2005-01-31 to 2019-12-31\n",
      "  Yearly: 40 | FinBERT: 8 | Union/Intersection: 47 | Assets w/ data: 34\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.09652 | Turnover: 3.2719 | TC: 0.002956 | Net: -0.09947\n",
      "\n",
      "[2/52] Date: 2020-02-29 | Year: 2020\n",
      "  Window: 2005-02-28 to 2020-01-31\n",
      "  Yearly: 40 | FinBERT: 10 | Union/Intersection: 50 | Assets w/ data: 33\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.05553 | Turnover: 2.9473 | TC: 0.002784 | Net: -0.05832\n",
      "\n",
      "[3/52] Date: 2020-03-31 | Year: 2020\n",
      "  Window: 2005-03-31 to 2020-02-29\n",
      "  Yearly: 40 | FinBERT: 14 | Union/Intersection: 54 | Assets w/ data: 34\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.06036 | Turnover: 2.5293 | TC: 0.002682 | Net:  0.05768\n",
      "\n",
      "[4/52] Date: 2020-04-30 | Year: 2020\n",
      "  Window: 2005-04-30 to 2020-03-31\n",
      "  Yearly: 40 | FinBERT: 10 | Union/Intersection: 50 | Assets w/ data: 34\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.05435 | Turnover: 2.2243 | TC: 0.002345 | Net:  0.05200\n",
      "\n",
      "[5/52] Date: 2020-05-31 | Year: 2020\n",
      "  Window: 2005-05-31 to 2020-04-30\n",
      "  Yearly: 40 | FinBERT: 8 | Union/Intersection: 48 | Assets w/ data: 30\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.06258 | Turnover: 2.3028 | TC: 0.002159 | Net: -0.06474\n",
      "\n",
      "[6/52] Date: 2020-06-30 | Year: 2020\n",
      "  Window: 2005-06-30 to 2020-05-31\n",
      "  Yearly: 40 | FinBERT: 7 | Union/Intersection: 46 | Assets w/ data: 30\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.05576 | Turnover: 2.8188 | TC: 0.002976 | Net:  0.05278\n",
      "\n",
      "[7/52] Date: 2020-07-31 | Year: 2020\n",
      "  Window: 2005-07-31 to 2020-06-30\n",
      "  Yearly: 40 | FinBERT: 4 | Union/Intersection: 44 | Assets w/ data: 28\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.03471 | Turnover: 2.1259 | TC: 0.002052 | Net: -0.03676\n",
      "\n",
      "[8/52] Date: 2020-08-31 | Year: 2020\n",
      "  Window: 2005-08-31 to 2020-07-31\n",
      "  Yearly: 40 | FinBERT: 12 | Union/Intersection: 51 | Assets w/ data: 33\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.02847 | Turnover: 2.3409 | TC: 0.002408 | Net:  0.02606\n",
      "\n",
      "[9/52] Date: 2020-09-30 | Year: 2020\n",
      "  Window: 2005-09-30 to 2020-08-31\n",
      "  Yearly: 40 | FinBERT: 17 | Union/Intersection: 2 | Assets w/ data: 0\n",
      "  ⚠ Insufficient data (n=180, p=0), recording zero return\n",
      "  Liquidating positions | Turnover: 2.7194 | TC: 0.002719\n",
      "\n",
      "[10/52] Date: 2020-10-31 | Year: 2020\n",
      "  Window: 2005-10-31 to 2020-09-30\n",
      "  Yearly: 40 | FinBERT: 7 | Union/Intersection: 47 | Assets w/ data: 29\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.00311 | Turnover: 2.8717 | TC: 0.002881 | Net:  0.00023\n",
      "\n",
      "[11/52] Date: 2020-11-30 | Year: 2020\n",
      "  Window: 2005-11-30 to 2020-10-31\n",
      "  Yearly: 40 | FinBERT: 7 | Union/Intersection: 46 | Assets w/ data: 32\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.00941 | Turnover: 2.0223 | TC: 0.002003 | Net: -0.01141\n",
      "\n",
      "[12/52] Date: 2020-12-31 | Year: 2020\n",
      "  Window: 2005-12-31 to 2020-11-30\n",
      "  Yearly: 40 | FinBERT: 7 | Union/Intersection: 46 | Assets w/ data: 26\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.03782 | Turnover: 1.3259 | TC: 0.001376 | Net:  0.03645\n",
      "\n",
      "[13/52] Date: 2021-01-31 | Year: 2021\n",
      "  Window: 2006-01-31 to 2020-12-31\n",
      "  Yearly: 123 | FinBERT: 8 | Union/Intersection: 130 | Assets w/ data: 74\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.04109 | Turnover: 5.6795 | TC: 0.005446 | Net: -0.04653\n",
      "\n",
      "[14/52] Date: 2021-02-28 | Year: 2021\n",
      "  Window: 2006-02-28 to 2021-01-31\n",
      "  Yearly: 123 | FinBERT: 15 | Union/Intersection: 3 | Assets w/ data: 2\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.08915 | Turnover: 5.1335 | TC: 0.005591 | Net:  0.08356\n",
      "\n",
      "[15/52] Date: 2021-03-31 | Year: 2021\n",
      "  Window: 2006-03-31 to 2021-02-28\n",
      "  Yearly: 123 | FinBERT: 11 | Union/Intersection: 2 | Assets w/ data: 1\n",
      "  ⚠ Insufficient data (n=180, p=1), recording zero return\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "\n",
      "[16/52] Date: 2021-04-30 | Year: 2021\n",
      "  Window: 2006-04-30 to 2021-03-31\n",
      "  Yearly: 123 | FinBERT: 15 | Union/Intersection: 137 | Assets w/ data: 80\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.03835 | Turnover: 3.8083 | TC: 0.003662 | Net: -0.04201\n",
      "\n",
      "[17/52] Date: 2021-05-31 | Year: 2021\n",
      "  Window: 2006-05-31 to 2021-04-30\n",
      "  Yearly: 123 | FinBERT: 9 | Union/Intersection: 131 | Assets w/ data: 72\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.05002 | Turnover: 1.5320 | TC: 0.001609 | Net:  0.04841\n",
      "\n",
      "[18/52] Date: 2021-06-30 | Year: 2021\n",
      "  Window: 2006-06-30 to 2021-05-31\n",
      "  Yearly: 123 | FinBERT: 13 | Union/Intersection: 3 | Assets w/ data: 1\n",
      "  ⚠ Insufficient data (n=180, p=1), recording zero return\n",
      "  Liquidating positions | Turnover: 3.5336 | TC: 0.003534\n",
      "\n",
      "[19/52] Date: 2021-07-31 | Year: 2021\n",
      "  Window: 2006-07-31 to 2021-06-30\n",
      "  Yearly: 123 | FinBERT: 11 | Union/Intersection: 134 | Assets w/ data: 77\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.01606 | Turnover: 3.8816 | TC: 0.003819 | Net: -0.01988\n",
      "\n",
      "[20/52] Date: 2021-08-31 | Year: 2021\n",
      "  Window: 2006-08-31 to 2021-07-31\n",
      "  Yearly: 123 | FinBERT: 11 | Union/Intersection: 3 | Assets w/ data: 2\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.01264 | Turnover: 4.8590 | TC: 0.004920 | Net:  0.00772\n",
      "\n",
      "[21/52] Date: 2021-09-30 | Year: 2021\n",
      "  Window: 2006-09-30 to 2021-08-31\n",
      "  Yearly: 123 | FinBERT: 12 | Union/Intersection: 3 | Assets w/ data: 2\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.02495 | Turnover: 0.0844 | TC: 0.000086 | Net:  0.02487\n",
      "\n",
      "[22/52] Date: 2021-10-31 | Year: 2021\n",
      "  Window: 2006-10-31 to 2021-09-30\n",
      "  Yearly: 123 | FinBERT: 12 | Union/Intersection: 134 | Assets w/ data: 76\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.01144 | Turnover: 4.7523 | TC: 0.004807 | Net:  0.00663\n",
      "\n",
      "[23/52] Date: 2021-11-30 | Year: 2021\n",
      "  Window: 2006-11-30 to 2021-10-31\n",
      "  Yearly: 123 | FinBERT: 9 | Union/Intersection: 131 | Assets w/ data: 73\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.07316 | Turnover: 0.9488 | TC: 0.001018 | Net:  0.07215\n",
      "\n",
      "[24/52] Date: 2021-12-31 | Year: 2021\n",
      "  Window: 2006-12-31 to 2021-11-30\n",
      "  Yearly: 123 | FinBERT: 8 | Union/Intersection: 2 | Assets w/ data: 1\n",
      "  ⚠ Insufficient data (n=180, p=1), recording zero return\n",
      "  Liquidating positions | Turnover: 3.6749 | TC: 0.003675\n",
      "\n",
      "[25/52] Date: 2022-01-31 | Year: 2022\n",
      "  Window: 2007-01-31 to 2021-12-31\n",
      "  Yearly: 34 | FinBERT: 29 | Union/Intersection: 63 | Assets w/ data: 33\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.03075 | Turnover: 2.5962 | TC: 0.002676 | Net:  0.02807\n",
      "\n",
      "[26/52] Date: 2022-02-28 | Year: 2022\n",
      "  Window: 2007-02-28 to 2022-01-31\n",
      "  Yearly: 34 | FinBERT: 15 | Union/Intersection: 48 | Assets w/ data: 28\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.12465 | Turnover: 2.4360 | TC: 0.002740 | Net:  0.12191\n",
      "\n",
      "[27/52] Date: 2022-03-31 | Year: 2022\n",
      "  Window: 2007-03-31 to 2022-02-28\n",
      "  Yearly: 34 | FinBERT: 16 | Union/Intersection: 50 | Assets w/ data: 30\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.14220 | Turnover: 1.6410 | TC: 0.001408 | Net: -0.14361\n",
      "\n",
      "[28/52] Date: 2022-04-30 | Year: 2022\n",
      "  Window: 2007-04-30 to 2022-03-31\n",
      "  Yearly: 34 | FinBERT: 19 | Union/Intersection: 52 | Assets w/ data: 31\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.03839 | Turnover: 2.2191 | TC: 0.002304 | Net:  0.03609\n",
      "\n",
      "[29/52] Date: 2022-05-31 | Year: 2022\n",
      "  Window: 2007-05-31 to 2022-04-30\n",
      "  Yearly: 34 | FinBERT: 10 | Union/Intersection: 43 | Assets w/ data: 23\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.01937 | Turnover: 1.5561 | TC: 0.001586 | Net:  0.01778\n",
      "\n",
      "[30/52] Date: 2022-06-30 | Year: 2022\n",
      "  Window: 2007-06-30 to 2022-05-31\n",
      "  Yearly: 34 | FinBERT: 11 | Union/Intersection: 45 | Assets w/ data: 24\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.04389 | Turnover: 1.3475 | TC: 0.001407 | Net:  0.04248\n",
      "\n",
      "[31/52] Date: 2022-07-31 | Year: 2022\n",
      "  Window: 2007-07-31 to 2022-06-30\n",
      "  Yearly: 34 | FinBERT: 24 | Union/Intersection: 57 | Assets w/ data: 33\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.06186 | Turnover: 2.1704 | TC: 0.002036 | Net: -0.06389\n",
      "\n",
      "[32/52] Date: 2022-08-31 | Year: 2022\n",
      "  Window: 2007-08-31 to 2022-07-31\n",
      "  Yearly: 34 | FinBERT: 12 | Union/Intersection: 2 | Assets w/ data: 2\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.05478 | Turnover: 4.4431 | TC: 0.004200 | Net: -0.05898\n",
      "\n",
      "[33/52] Date: 2022-09-30 | Year: 2022\n",
      "  Window: 2007-09-30 to 2022-08-31\n",
      "  Yearly: 34 | FinBERT: 19 | Union/Intersection: 53 | Assets w/ data: 30\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.00781 | Turnover: 4.3249 | TC: 0.004291 | Net: -0.01211\n",
      "\n",
      "[34/52] Date: 2022-10-31 | Year: 2022\n",
      "  Window: 2007-10-31 to 2022-09-30\n",
      "  Yearly: 34 | FinBERT: 25 | Union/Intersection: 2 | Assets w/ data: 2\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.08168 | Turnover: 4.7202 | TC: 0.005106 | Net:  0.07657\n",
      "\n",
      "[35/52] Date: 2022-11-30 | Year: 2022\n",
      "  Window: 2007-11-30 to 2022-10-31\n",
      "  Yearly: 34 | FinBERT: 25 | Union/Intersection: 59 | Assets w/ data: 34\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.02151 | Turnover: 4.0636 | TC: 0.003976 | Net: -0.02548\n",
      "\n",
      "[36/52] Date: 2022-12-31 | Year: 2022\n",
      "  Window: 2007-12-31 to 2022-11-30\n",
      "  Yearly: 34 | FinBERT: 9 | Union/Intersection: 2 | Assets w/ data: 2\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.22412 | Turnover: 4.0292 | TC: 0.004932 | Net:  0.21918\n",
      "\n",
      "[37/52] Date: 2023-01-31 | Year: 2023\n",
      "  Window: 2008-01-31 to 2022-12-31\n",
      "  Yearly: 137 | FinBERT: 23 | Union/Intersection: 4 | Assets w/ data: 1\n",
      "  ⚠ Insufficient data (n=180, p=1), recording zero return\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "\n",
      "[38/52] Date: 2023-02-28 | Year: 2023\n",
      "  Window: 2008-02-29 to 2023-01-31\n",
      "  Yearly: 137 | FinBERT: 23 | Union/Intersection: 4 | Assets w/ data: 2\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.00934 | Turnover: 1.0000 | TC: 0.000991 | Net: -0.01033\n",
      "\n",
      "[39/52] Date: 2023-03-31 | Year: 2023\n",
      "  Window: 2008-03-31 to 2023-02-28\n",
      "  Yearly: 137 | FinBERT: 20 | Union/Intersection: 6 | Assets w/ data: 4\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.02034 | Turnover: 0.7545 | TC: 0.000770 | Net:  0.01957\n",
      "\n",
      "[40/52] Date: 2023-04-30 | Year: 2023\n",
      "  Window: 2008-04-30 to 2023-03-31\n",
      "  Yearly: 137 | FinBERT: 23 | Union/Intersection: 2 | Assets w/ data: 1\n",
      "  ⚠ Insufficient data (n=180, p=1), recording zero return\n",
      "  Liquidating positions | Turnover: 1.3999 | TC: 0.001400\n",
      "\n",
      "[41/52] Date: 2023-05-31 | Year: 2023\n",
      "  Window: 2008-05-31 to 2023-04-30\n",
      "  Yearly: 137 | FinBERT: 20 | Union/Intersection: 7 | Assets w/ data: 4\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.06904 | Turnover: 1.6186 | TC: 0.001507 | Net: -0.07055\n",
      "\n",
      "[42/52] Date: 2023-06-30 | Year: 2023\n",
      "  Window: 2008-06-30 to 2023-05-31\n",
      "  Yearly: 137 | FinBERT: 25 | Union/Intersection: 8 | Assets w/ data: 6\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.13328 | Turnover: 3.4495 | TC: 0.003909 | Net:  0.12937\n",
      "\n",
      "[43/52] Date: 2023-07-31 | Year: 2023\n",
      "  Window: 2008-07-31 to 2023-06-30\n",
      "  Yearly: 137 | FinBERT: 32 | Union/Intersection: 8 | Assets w/ data: 4\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.01359 | Turnover: 1.7765 | TC: 0.001752 | Net: -0.01535\n",
      "\n",
      "[44/52] Date: 2023-08-31 | Year: 2023\n",
      "  Window: 2008-08-31 to 2023-07-31\n",
      "  Yearly: 137 | FinBERT: 29 | Union/Intersection: 6 | Assets w/ data: 2\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.08556 | Turnover: 0.8243 | TC: 0.000754 | Net: -0.08632\n",
      "\n",
      "[45/52] Date: 2023-09-30 | Year: 2023\n",
      "  Window: 2008-09-30 to 2023-08-31\n",
      "  Yearly: 137 | FinBERT: 27 | Union/Intersection: 7 | Assets w/ data: 4\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.01544 | Turnover: 0.6387 | TC: 0.000649 | Net:  0.01479\n",
      "\n",
      "[46/52] Date: 2023-10-31 | Year: 2023\n",
      "  Window: 2008-10-31 to 2023-09-30\n",
      "  Yearly: 137 | FinBERT: 31 | Union/Intersection: 6 | Assets w/ data: 3\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.12503 | Turnover: 1.6375 | TC: 0.001842 | Net:  0.12319\n",
      "\n",
      "[47/52] Date: 2023-11-30 | Year: 2023\n",
      "  Window: 2008-11-30 to 2023-10-31\n",
      "  Yearly: 137 | FinBERT: 35 | Union/Intersection: 12 | Assets w/ data: 7\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.00367 | Turnover: 0.7926 | TC: 0.000796 | Net:  0.00287\n",
      "\n",
      "[48/52] Date: 2023-12-31 | Year: 2023\n",
      "  Window: 2008-12-31 to 2023-11-30\n",
      "  Yearly: 137 | FinBERT: 36 | Union/Intersection: 6 | Assets w/ data: 5\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.01311 | Turnover: 2.1978 | TC: 0.002169 | Net: -0.01528\n",
      "\n",
      "[49/52] Date: 2024-01-31 | Year: 2024\n",
      "  Window: 2009-01-31 to 2023-12-31\n",
      "  Yearly: 281 | FinBERT: 49 | Union/Intersection: 25 | Assets w/ data: 15\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.01908 | Turnover: 2.9821 | TC: 0.003039 | Net:  0.01604\n",
      "\n",
      "[50/52] Date: 2024-02-29 | Year: 2024\n",
      "  Window: 2009-02-28 to 2024-01-31\n",
      "  Yearly: 281 | FinBERT: 28 | Union/Intersection: 17 | Assets w/ data: 13\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.08634 | Turnover: 4.0585 | TC: 0.004409 | Net:  0.08193\n",
      "\n",
      "[51/52] Date: 2024-03-31 | Year: 2024\n",
      "  Window: 2009-03-31 to 2024-02-29\n",
      "  Yearly: 281 | FinBERT: 32 | Union/Intersection: 14 | Assets w/ data: 7\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross: -0.00019 | Turnover: 3.6981 | TC: 0.003697 | Net: -0.00389\n",
      "\n",
      "[52/52] Date: 2024-04-30 | Year: 2024\n",
      "  Window: 2009-04-30 to 2024-03-31\n",
      "  Yearly: 281 | FinBERT: 42 | Union/Intersection: 19 | Assets w/ data: 11\n",
      "  Running NLS Regression...\n",
      "  Computing MSR weights...\n",
      "  Gross:  0.05752 | Turnover: 3.1409 | TC: 0.003322 | Net:  0.05420\n",
      "\n",
      "============================================================\n",
      "BACKTEST COMPLETE\n",
      "============================================================\n",
      "\n",
      "Sharpe Ratio: 0.1699\n",
      "Annualized Sharpe Ratio: 0.5884\n",
      "Total Return: 0.5753\n",
      "Average Turnover: 2.5943\n"
     ]
    }
   ],
   "source": [
    "results_df, metrics = backtest_nodewise_gmv_combined(\n",
    "    df,\n",
    "    test_start_date='2020-01-31',\n",
    "    test_end_date='2024-04-30',\n",
    "    lookback_window=180,\n",
    "    transaction_cost=0.001,\n",
    "    buys_path_template='../buys_{}.csv',\n",
    "    sells_path_template='../sells_{}.csv',\n",
    "    finbert_signals_path='../../examples/monthly_signals_decay.csv',  # Your FinBERT signals\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nSharpe Ratio: {metrics['sharpe_ratio']:.4f}\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Total Return: {metrics['total_return']:.4f}\")\n",
    "print(f\"Average Turnover: {metrics['avg_turnover']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f2cb5b6-0544-492b-87fa-b11a29c05d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1279290434996842"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['mean_return']*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a255b9d-f63d-4f03-ae09-1fda24f20db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04727259332390772"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['variance']*12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3ca5b17-4721-483c-a397-18ec60e8ba8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5943286490652184"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics['avg_turnover']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14602811-9711-4d99-b79a-d22f3e2197e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
