{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84482766-9f65-4cb5-9309-e8bd125501f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from multiprocessing import get_context\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "import scipy.linalg as sl\n",
    "def afm_est(Y, NF):\n",
    "\n",
    "    n = Y.shape[0]\n",
    "    p = Y.shape[1]\n",
    "    \n",
    "    # L'L normalization\n",
    "    ev_ = sl.eigh(np.cov(Y))\n",
    "\n",
    "    # Sort eigenvalues in descending order\n",
    "    indx_ev = ev_[0].argsort()[::-1]\n",
    "    # Get eigenvectors\n",
    "    evec = ev_[1][:, indx_ev]\n",
    "\n",
    "    # Determining Factors\n",
    "    F = np.sqrt(n) * evec[:, 0:NF]\n",
    "\n",
    "    # Factorloadings\n",
    "    L = Y.T @ F/n\n",
    "\n",
    "    \"\"\"\n",
    "    # F'F normalization\n",
    "    ev_ = sl.eigh(np.cov(Y.T))\n",
    "\n",
    "    # Sort eigenvalues in descending order\n",
    "    indx_ev = ev_[0].argsort()[::-1]\n",
    "    # Get eigenvectors\n",
    "    evec = ev_[1][:, indx_ev]\n",
    "\n",
    "    # Determining Factors\n",
    "    L = np.sqrt(p) * evec[:, 0:NF]\n",
    "    # Factorloadings\n",
    "    F = Y @ L/p\n",
    "    \"\"\"\n",
    "    resd = Y - F @ L.T\n",
    "\n",
    "    ret_ = {'F': F, 'L': L, 'resd': resd}\n",
    "\n",
    "    return ret_\n",
    "\n",
    "def nf_bn(Y, nf_max):\n",
    "\n",
    "    n = Y.shape[0]\n",
    "    p = Y.shape[1]\n",
    "\n",
    "    IC1 = np.empty((nf_max, 1))\n",
    "    IC1[:] = np.nan\n",
    "    IC2 = np.empty((nf_max, 1))\n",
    "    IC2[:] = np.nan\n",
    "    IC3 = np.empty((nf_max, 1))\n",
    "    IC3[:] = np.nan\n",
    "\n",
    "    for ii in range(1, nf_max+1):\n",
    "        ret_afm = afm_est(Y, ii)\n",
    "\n",
    "        V = np.mean(ret_afm['resd']**2)\n",
    "        \n",
    "        #Information criteria\n",
    "        #IC1\n",
    "        IC1[ii-1, 0] = np.log(V) + ii * ((p+n)/(p*n) * np.log((p*n)/(p+n)))\n",
    "        #IC2\n",
    "        IC2[ii-1, 0] = np.log(V) + ii * ((p+n)/(p*n) * np.log(min(n,p)))\n",
    "        #IC3\n",
    "        IC3[ii-1, 0] = np.log(V) + ii * (np.log(min(n,p)) / (min(n,p)))\n",
    "    \n",
    "    ICs = np.empty((3, 2))\n",
    "    ICs[:] = np.nan\n",
    "\n",
    "    ICs[0, 0] = IC1.argmin()\n",
    "    ICs[1, 0] = IC2.argmin()\n",
    "    ICs[2, 0] = IC3.argmin()\n",
    "\n",
    "    ICs[0, 1] = IC1[int(ICs[0, 0])]\n",
    "    ICs[1, 1] = IC2[int(ICs[1, 0])]\n",
    "    ICs[2, 1] = IC3[int(ICs[2, 0])]\n",
    "\n",
    "    ret_ = {'num_f': ICs[:,0], 'ICs': ICs[:,1]}\n",
    "\n",
    "    return ret_\n",
    "\n",
    "def soft_t(z, a):\n",
    "  t1 = np.sign(z)\n",
    "  b = np.abs(z) - a\n",
    "  t2 = b * (b >= 0)\n",
    "  z_t = t1 * t2\n",
    "  return z_t\n",
    "\n",
    "def cov_e_poet(resd, C, N, T):\n",
    "    rate_thres = 1/np.sqrt(N) + np.sqrt((np.log(N))/T)\n",
    "    # lam = rate_thres * C * np.ones(shape=(N,N))\n",
    "    \n",
    "    sig_e_samp = np.cov(resd.T)\n",
    "    \n",
    "    \n",
    "    thet_par = np.empty((N, N))\n",
    "    thet_par[:] = np.nan\n",
    "    \n",
    "    for ii in range(0, N):\n",
    "        for jj in range(0, N):\n",
    "            thet_par[ii, jj] = np.mean((resd[:, ii] * resd[:, jj] - sig_e_samp[ii, jj])**2)\n",
    "    \n",
    "    lam = rate_thres * C * np.sqrt(thet_par)\n",
    "    \n",
    "    \"\"\"\n",
    "    sig_e_diag=np.diag(np.sqrt(np.diag(sig_e_samp)))\n",
    "    R = np.linalg.inv(sig_e_diag) @ sig_e_samp @ np.linalg.inv(sig_e_diag); \n",
    "    M = soft_t(R, lam)\n",
    "    np.fill_diagonal(M, 1)\n",
    "    sig_e_hat = sig_e_diag @ M @ sig_e_diag\n",
    "    \"\"\"\n",
    "\n",
    "    sig_e_diag = np.diag(sig_e_samp)\n",
    "    sig_e_hat = soft_t(sig_e_samp, lam)\n",
    "    np.fill_diagonal(sig_e_hat, sig_e_diag)\n",
    "\n",
    "    return sig_e_hat\n",
    "\n",
    "def poet(Y_star,NF_max):\n",
    "    n = Y_star.shape[0]\n",
    "    p = Y_star.shape[1]\n",
    "    \n",
    "    num_f = nf_bn(Y_star, NF_max)['num_f']\n",
    "    num_f = int(num_f[0])\n",
    "    est_afm = afm_est(Y_star, num_f)\n",
    "\n",
    "    F = est_afm['F']\n",
    "    L = est_afm['L']\n",
    "    resd = est_afm['resd']\n",
    "    sigma_u_hat = cov_e_poet(resd, 2, p, n)\n",
    "    sigma_u_hat_inv = np.linalg.inv(sigma_u_hat)\n",
    "    \n",
    "    A=L.T @ sigma_u_hat_inv @ L\n",
    "    I=np.eye(A.shape[0])\n",
    "    \n",
    "    Theta_hat = sigma_u_hat_inv - sigma_u_hat_inv @ L @ np.linalg.inv(I+A) @ L.T @ sigma_u_hat_inv\n",
    "    return Theta_hat\n",
    "\n",
    "\n",
    "def gmv_weights(Theta_hat):\n",
    "    \"\"\"\n",
    "    Compute Global Minimum Variance (GMV) portfolio weights (Section 6.1).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # w* = (Θ 1_p) / (1_p' Θ 1_p)\n",
    "    numerator = Theta_hat @ ones_p\n",
    "    denominator = ones_p @ Theta_hat @ ones_p\n",
    "    \n",
    "    if np.abs(denominator) < 1e-10:\n",
    "        # Fallback to equal weights if precision matrix is near-singular\n",
    "        return ones_p / p\n",
    "    \n",
    "    w_star = numerator / denominator\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "def mv_weights(Theta_hat, mu, target_return=0.01):\n",
    "    \"\"\"\n",
    "    Compute Mean-Variance portfolio weights with target return.\n",
    "    \n",
    "    Solves the constrained optimization:\n",
    "    min w' Sigma w  subject to  w' mu = target_return  and  w' 1 = 1\n",
    "    \n",
    "    Solution uses Lagrange multipliers with two constraints.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix (Sigma^{-1})\n",
    "    mu : np.ndarray, shape (p,)\n",
    "        Expected returns\n",
    "    target_return : float\n",
    "        Target portfolio return (default: 0.01 = 1% monthly)\n",
    "    long_only : bool\n",
    "        If True, falls back to GMV if MV produces negative weights\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # Compute key quantities\n",
    "    A = ones_p @ Theta_hat @ ones_p  # 1' Theta 1\n",
    "    B = ones_p @ Theta_hat @ mu       # 1' Theta mu  \n",
    "    C = mu @ Theta_hat @ mu           # mu' Theta mu\n",
    "    D = A * C - B * B                  # Determinant\n",
    "    \n",
    "    # Check for singularity\n",
    "    if np.abs(D) < 1e-10:\n",
    "        print('SINGULARITY')\n",
    "        # System is singular, use GMV instead\n",
    "        if np.abs(A) > 1e-10:\n",
    "            w_star = (Theta_hat @ ones_p) / A\n",
    "            return w_star\n",
    "        else:\n",
    "            return ones_p / p\n",
    "    \n",
    "    \n",
    "    # Compute Lagrange multipliers\n",
    "    lambda1 = (C - B * target_return) / D\n",
    "    lambda2 = (A * target_return - B) / D\n",
    "    \n",
    "    # Compute weights: w = lambda1 * Theta^{-1} 1 + lambda2 * Theta^{-1} mu\n",
    "    w_star = lambda1 * (Theta_hat @ ones_p) + lambda2 * (Theta_hat @ mu)\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "def msr_weights(Theta_hat, mu):\n",
    "    \"\"\"\n",
    "    Compute Maximum Sharpe Ratio portfolio weights.\n",
    "    \n",
    "    The maximum Sharpe ratio portfolio solves:\n",
    "    max (w' mu) / sqrt(w' Sigma w)\n",
    "    \n",
    "    Solution (when mu represents excess returns):\n",
    "    w ∝ Sigma^{-1} mu = Theta mu\n",
    "    \n",
    "    Then normalize so that sum(w) = 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix (Sigma^{-1})\n",
    "    mu : np.ndarray, shape (p,)\n",
    "        Expected excess returns\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights (sum to 1)\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # Compute unnormalized weights: w ∝ Theta mu\n",
    "    w_unnorm = Theta_hat @ mu\n",
    "    \n",
    "    # Normalize to sum to 1\n",
    "    weight_sum = np.sum(w_unnorm)\n",
    "    \n",
    "    if np.abs(weight_sum) < 1e-10:\n",
    "        print('WARNING: Weight sum near zero, returning equal weights')\n",
    "        return ones_p / p\n",
    "    \n",
    "    w_star = w_unnorm / weight_sum\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "\n",
    "def load_yearly_signals(year, buys_path_template='buys_{}.csv', sells_path_template='sells_{}.csv'):\n",
    "    \"\"\"\n",
    "    Load buy and sell signals for a specific year.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    year : int\n",
    "        Year to load signals for\n",
    "    buys_path_template : str\n",
    "        Template for buys file path (use {} for year placeholder)\n",
    "    sells_path_template : str\n",
    "        Template for sells file path (use {} for year placeholder)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    permno_set : set\n",
    "        Set of permnos in the buy and sell signals for this year\n",
    "    \"\"\"\n",
    "    try:\n",
    "        buys = pd.read_csv(buys_path_template.format(year), index_col=1)\n",
    "        sells = pd.read_csv(sells_path_template.format(year), index_col=1)\n",
    "        \n",
    "        buys.index.name = 'permno'\n",
    "        sells.index.name = 'permno'\n",
    "        \n",
    "        buys_index = buys.index.astype(int)\n",
    "        sells_index = sells.index.astype(int)\n",
    "        \n",
    "        return set(buys_index.union(sells_index))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  ⚠ Warning: Could not load signals for year {year}: {e}\")\n",
    "        return set()\n",
    "\n",
    "def load_finbert_signals(signals_path):\n",
    "    \"\"\"\n",
    "    Load FinBERT monthly signals from CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signals_path : str\n",
    "        Path to monthly_signals.csv file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    signals_df : pd.DataFrame\n",
    "        DataFrame with columns: symbol, company, year_month, signal, avg_sentiment_score\n",
    "    \"\"\"\n",
    "    try:\n",
    "        signals_df = pd.read_csv(signals_path)\n",
    "        # Convert year_month to datetime (end of month)\n",
    "        signals_df['date'] = pd.to_datetime(signals_df['year_month']) + pd.offsets.MonthEnd(0)\n",
    "        return signals_df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  ⚠ Warning: Could not load FinBERT signals: {e}\")\n",
    "        return pd.DataFrame(columns=['symbol', 'company', 'year_month', 'signal', 'date'])\n",
    "\n",
    "def get_finbert_permnos_for_date(signals_df, ticker_to_permno, date):\n",
    "    \"\"\"\n",
    "    Get set of permnos with 'buy' or 'sell' signals for a specific date.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signals_df : pd.DataFrame\n",
    "        FinBERT signals dataframe\n",
    "    ticker_to_permno : dict\n",
    "        Mapping from ticker symbol to permno\n",
    "    date : pd.Timestamp\n",
    "        Date to get signals for\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    permno_set : set\n",
    "        Set of permnos with buy or sell signals on this date\n",
    "    \"\"\"\n",
    "    # Get signals for this date\n",
    "    date_signals = signals_df[signals_df['date'] == date]\n",
    "    \n",
    "    # Filter for buy and sell signals (exclude hold)\n",
    "    buy_signals = date_signals[date_signals['signal'] == 'buy']\n",
    "    sell_signals = date_signals[date_signals['signal'] == 'sell']\n",
    "    \n",
    "    # Convert tickers to permnos\n",
    "    permnos = set()\n",
    "    for ticker in buy_signals['symbol'].values:\n",
    "        if ticker in ticker_to_permno:\n",
    "            permnos.add(ticker_to_permno[ticker])\n",
    "    for ticker in sell_signals['symbol'].values:\n",
    "        if ticker in ticker_to_permno:\n",
    "            permnos.add(ticker_to_permno[ticker])\n",
    "    \n",
    "    return permnos\n",
    "\n",
    "\n",
    "def create_ticker_to_permno_mapping(df):\n",
    "    \"\"\"\n",
    "    Create a mapping from ticker to permno from the returns dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Returns dataframe with 'ticker' and 'permno' columns\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    ticker_to_permno : dict\n",
    "        Mapping from ticker to permno (uses most recent permno for each ticker)\n",
    "    \"\"\"\n",
    "    if 'ticker' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have 'ticker' column for mapping\")\n",
    "    \n",
    "    # Drop NaN tickers\n",
    "    valid_df = df[df['ticker'].notna()].copy()\n",
    "    \n",
    "    # Get the most recent permno for each ticker\n",
    "    ticker_to_permno = valid_df.groupby('ticker')['permno'].last().to_dict()\n",
    "    \n",
    "    return ticker_to_permno\n",
    "\n",
    "def load_analyst_recommendations(rec_changes_path):\n",
    "    \"\"\"\n",
    "    Load significant recommendation changes from CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rec_changes_path : str\n",
    "        Path to significant_recommendation_changes.csv file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    rec_changes_df : pd.DataFrame\n",
    "        DataFrame with columns: permno, date, ticker, mean_recommendation, \n",
    "        recommendation_change, num_recommendations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rec_changes_df = pd.read_csv(rec_changes_path)\n",
    "        rec_changes_df['date'] = pd.to_datetime(rec_changes_df['date'])\n",
    "        rec_changes_df['permno'] = rec_changes_df['permno'].astype(int)\n",
    "        return rec_changes_df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  ⚠ Warning: Could not load recommendation changes: {e}\")\n",
    "        return pd.DataFrame(columns=['permno', 'date', 'ticker', 'mean_recommendation', \n",
    "                                    'recommendation_change', 'num_recommendations'])\n",
    "\n",
    "\n",
    "def get_signal_permnos_for_date(rec_changes_df, date, buy_threshold=-0.5, sell_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Get sets of permnos with buy/sell signals based on recommendation changes.\n",
    "    \n",
    "    Note: Negative change = upgrade (moving toward Strong Buy) = BUY signal\n",
    "          Positive change = downgrade (moving toward Sell) = SELL signal\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rec_changes_df : pd.DataFrame\n",
    "        Recommendation changes dataframe\n",
    "    date : pd.Timestamp\n",
    "        Date to get signals for\n",
    "    buy_threshold : float\n",
    "        Threshold for buy signals (default: -0.5)\n",
    "    sell_threshold : float\n",
    "        Threshold for sell signals (default: 0.5)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    buy_permnos : set\n",
    "        Set of permnos with buy signals\n",
    "    sell_permnos : set\n",
    "        Set of permnos with sell signals\n",
    "    \"\"\"\n",
    "    date_changes = rec_changes_df[rec_changes_df['date'] == date]\n",
    "    \n",
    "    # Buy signals: negative changes (recommendations getting better)\n",
    "    buys = date_changes[date_changes['recommendation_change'] <= buy_threshold]\n",
    "    buy_permnos = set(buys['permno'].values)\n",
    "    \n",
    "    # Sell signals: positive changes (recommendations getting worse)\n",
    "    sells = date_changes[date_changes['recommendation_change'] >= sell_threshold]\n",
    "    sell_permnos = set(sells['permno'].values)\n",
    "    \n",
    "    return buy_permnos | sell_permnos\n",
    "\n",
    "\n",
    "def calculate_exit_transaction_cost(prev_weights_dict, prev_oos_returns_dict, \n",
    "                                    prev_gross_return, transaction_cost, verbose=False):\n",
    "    \"\"\"Calculate transaction cost when exiting the market (liquidating all positions).\"\"\"\n",
    "    if len(prev_weights_dict) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    \n",
    "    adjusted_prev = {}\n",
    "    for asset, prev_w in prev_weights_dict.items():\n",
    "        if asset in prev_oos_returns_dict:\n",
    "            prev_r = prev_oos_returns_dict[asset]\n",
    "            if abs(1 + prev_gross_return) > 1e-6:\n",
    "                adjusted_prev[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return)\n",
    "            else:\n",
    "                adjusted_prev[asset] = 0.0\n",
    "        else:\n",
    "            if abs(1 + prev_gross_return) > 1e-6:\n",
    "                adjusted_prev[asset] = prev_w / (1 + prev_gross_return)\n",
    "            else:\n",
    "                adjusted_prev[asset] = 0.0\n",
    "    \n",
    "    turnover = sum(abs(w) for w in adjusted_prev.values())\n",
    "    tc = transaction_cost * 1.0 * turnover\n",
    "    net_return = -tc\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  Liquidating positions | Turnover: {turnover:>6.4f} | TC: {tc:>8.6f}\")\n",
    "    \n",
    "    return turnover, tc, net_return\n",
    "\n",
    "\n",
    "\n",
    "def backtest_dnn_yearly(df, \n",
    "                          test_start_date='2020-01-31', \n",
    "                          test_end_date='2024-11-30',\n",
    "                          lookback_window=180,\n",
    "                          transaction_cost=0.001,\n",
    "                          buys_path_template='buys_{}.csv',\n",
    "                          sells_path_template='sells_{}.csv',\n",
    "                          analyst_rec_path=None,\n",
    "                          finbert_signals_path=None,\n",
    "                          data_factor=None,\n",
    "                          verbose=True):\n",
    "    \"\"\"\n",
    "    Backtest DNN-FM with FinBERT + LLM signals using GMV/MV/MSR strategies.\n",
    "    \n",
    "    KEY CHANGES:\n",
    "    1. Added finbert_signals_path parameter\n",
    "    2. Added ticker to permno mapping creation\n",
    "    3. Added FinBERT signal loading and processing\n",
    "    4. Combined yearly and FinBERT signals using union/intersection logic\n",
    "    5. Added calculate_exit_transaction_cost for proper liquidation handling\n",
    "    \"\"\"\n",
    "    \n",
    "    # [Keep all existing setup code]\n",
    "    df = df.copy()\n",
    "    if 'datadate' not in df.columns or 'permno' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have 'datadate' and 'permno' columns\")\n",
    "    df['datadate'] = pd.to_datetime(df['datadate'])\n",
    "\n",
    "    # Create ticker to permno mapping\n",
    "    if verbose:\n",
    "        print(\"Creating ticker to permno mapping...\")\n",
    "    ticker_to_permno = create_ticker_to_permno_mapping(df)\n",
    "    if verbose:\n",
    "        print(f\"Mapped {len(ticker_to_permno)} unique tickers to permnos\")\n",
    "    \n",
    "    # Load FinBERT signals if provided\n",
    "    finbert_df = None\n",
    "    if finbert_signals_path is not None:\n",
    "        finbert_df = load_finbert_signals(finbert_signals_path)\n",
    "        if verbose and len(finbert_df) > 0:\n",
    "            print(f\"Loaded FinBERT signals: {len(finbert_df)} monthly records\")\n",
    "            print(f\"FinBERT signal distribution:\")\n",
    "            print(finbert_df['signal'].value_counts())\n",
    "    \n",
    "    # Load analyst recommendations if provided\n",
    "    analyst_df = None\n",
    "    if analyst_rec_path is not None:\n",
    "        analyst_df = load_analyst_recommendations(analyst_rec_path)\n",
    "        if verbose and len(analyst_df) > 0:\n",
    "            print(f\"Loaded analyst recommendations: {len(analyst_df)} records\")\n",
    "    \n",
    "    \n",
    "    # [Keep all existing date and storage setup]\n",
    "    all_dates = sorted(df['datadate'].unique())\n",
    "    test_start_dt = pd.to_datetime(test_start_date)\n",
    "    test_end_dt = pd.to_datetime(test_end_date)\n",
    "    \n",
    "    try:\n",
    "        test_start_idx = all_dates.index(test_start_dt)\n",
    "        test_end_idx = all_dates.index(test_end_dt)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Date not found in DataFrame: {e}\")\n",
    "    \n",
    "    # Storage for results - GMV\n",
    "    portfolio_returns = []\n",
    "    portfolio_dates = []\n",
    "    portfolio_weights_list = []\n",
    "    portfolio_turnover_list = []\n",
    "    portfolio_gross_returns = []\n",
    "    \n",
    "    # Storage for results - MV\n",
    "    portfolio_returns_2 = []\n",
    "    portfolio_dates_2 = []\n",
    "    portfolio_weights_list_2 = []\n",
    "    portfolio_turnover_list_2 = []\n",
    "    portfolio_gross_returns_2 = []\n",
    "    \n",
    "    # Storage for results - MSR\n",
    "    portfolio_returns_3 = []\n",
    "    portfolio_dates_3 = []\n",
    "    portfolio_weights_list_3 = []\n",
    "    portfolio_turnover_list_3 = []\n",
    "    portfolio_gross_returns_3 = []\n",
    "    \n",
    "    # Track weights by permno - GMV\n",
    "    prev_weights_dict = {}\n",
    "    prev_oos_returns_dict = {}\n",
    "    prev_gross_return = 0.0\n",
    "    \n",
    "    # Track weights by permno - MV\n",
    "    prev_weights_dict_2 = {}\n",
    "    prev_oos_returns_dict_2 = {}\n",
    "    prev_gross_return_2 = 0.0\n",
    "    \n",
    "    # Track weights by permno - MSR\n",
    "    prev_weights_dict_3 = {}\n",
    "    prev_oos_returns_dict_3 = {}\n",
    "    prev_gross_return_3 = 0.0\n",
    "    \n",
    "    # Cache for yearly signals\n",
    "    yearly_signals_cache = {}\n",
    "    \n",
    "    # --- 2. Rolling Window Backtest ---\n",
    "    if verbose:\n",
    "        print(\"=\"*60)\n",
    "        print(\"STARTING BACKTEST WITH DNN-FM + YEARLY + ANALYST SIGNALS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "    for t in range(test_start_idx, test_end_idx + 1):\n",
    "        current_date = all_dates[t]\n",
    "        current_year = current_date.year\n",
    "        \n",
    "        # Load yearly signals\n",
    "        if current_year not in yearly_signals_cache:\n",
    "            yearly_signals_cache[current_year] = load_yearly_signals(\n",
    "                current_year, buys_path_template, sells_path_template\n",
    "            )\n",
    "        \n",
    "        yearly_permnos = yearly_signals_cache[current_year]\n",
    "        \n",
    "        # Get analyst recommendations for current date\n",
    "        analyst_permnos = set()\n",
    "        if analyst_df is not None and len(analyst_df) > 0:\n",
    "            analyst_permnos = get_signal_permnos_for_date(analyst_df, current_date)\n",
    "\n",
    "        # Get FinBERT signals for current date\n",
    "        finbert_permnos = set()\n",
    "        if finbert_df is not None and len(finbert_df) > 0:\n",
    "            finbert_permnos = get_finbert_permnos_for_date(finbert_df, ticker_to_permno, current_date)\n",
    "        \n",
    "        # keep only permnos that 2 strats agree on\n",
    "        allowed_permnos = (yearly_permnos & analyst_permnos) | \\\n",
    "                          (yearly_permnos & finbert_permnos) | \\\n",
    "                          (analyst_permnos & finbert_permnos)\n",
    "        \n",
    "        # NEW: Get OOS returns FIRST (critical for exit transaction cost calculation)\n",
    "        oos_data = df[(df['datadate'] == current_date) & (df['permno'].isin(allowed_permnos))]\n",
    "        oos_returns_series = oos_data.set_index('permno')['ret_fwd_1']\n",
    "        oos_returns_series = oos_returns_series.dropna()\n",
    "        oos_returns_dict = oos_returns_series.to_dict()\n",
    "        \n",
    "        # NEW: Handle no signals case with proper liquidation\n",
    "        if len(allowed_permnos) == 0:\n",
    "            if verbose:\n",
    "                print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                      f\"Date: {current_date.strftime('%Y-%m-%d')}\")\n",
    "                print(f\"  ⚠ No signals, recording zero return for all strategies\")\n",
    "            \n",
    "            # Liquidate all three strategies\n",
    "            for idx, (pw, po, pg) in enumerate([\n",
    "                (prev_weights_dict, prev_oos_returns_dict, prev_gross_return),\n",
    "                (prev_weights_dict_2, prev_oos_returns_dict_2, prev_gross_return_2),\n",
    "                (prev_weights_dict_3, prev_oos_returns_dict_3, prev_gross_return_3)\n",
    "            ]):\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    pw, po, pg, transaction_cost, verbose=verbose\n",
    "                )\n",
    "                \n",
    "                if idx == 0:  # GMV\n",
    "                    portfolio_returns.append(net_return)\n",
    "                    portfolio_dates.append(current_date)\n",
    "                    portfolio_weights_list.append({})\n",
    "                    portfolio_turnover_list.append(turnover)\n",
    "                    portfolio_gross_returns.append(0.0)\n",
    "                elif idx == 1:  # MV\n",
    "                    portfolio_returns_2.append(net_return)\n",
    "                    portfolio_dates_2.append(current_date)\n",
    "                    portfolio_weights_list_2.append({})\n",
    "                    portfolio_turnover_list_2.append(turnover)\n",
    "                    portfolio_gross_returns_2.append(0.0)\n",
    "                else:  # MSR\n",
    "                    portfolio_returns_3.append(net_return)\n",
    "                    portfolio_dates_3.append(current_date)\n",
    "                    portfolio_weights_list_3.append({})\n",
    "                    portfolio_turnover_list_3.append(turnover)\n",
    "                    portfolio_gross_returns_3.append(0.0)\n",
    "            \n",
    "            # Reset all state\n",
    "            prev_weights_dict = {}\n",
    "            prev_oos_returns_dict = {}\n",
    "            prev_gross_return = 0.0\n",
    "            prev_weights_dict_2 = {}\n",
    "            prev_oos_returns_dict_2 = {}\n",
    "            prev_gross_return_2 = 0.0\n",
    "            prev_weights_dict_3 = {}\n",
    "            prev_oos_returns_dict_3 = {}\n",
    "            prev_gross_return_3 = 0.0\n",
    "            continue\n",
    "        \n",
    "        # Define the lookback window\n",
    "        window_start_date = all_dates[t - lookback_window]\n",
    "        window_end_date = all_dates[t - 1]\n",
    "        \n",
    "        train_data = df[(df['datadate'] >= window_start_date) & \n",
    "                        (df['datadate'] <= window_end_date) &\n",
    "                        (df['permno'].isin(allowed_permnos))]\n",
    "        train_factor = data_factor.loc[window_start_date : window_end_date]\n",
    "        \n",
    "        returns_pivot = train_data.pivot(index='datadate', columns='permno', values='ret_fwd_1')\n",
    "        window_dates = all_dates[t - lookback_window : t]\n",
    "        returns_pivot = returns_pivot.reindex(index=window_dates)\n",
    "        \n",
    "        nan_assets = returns_pivot.columns[returns_pivot.isna().any()]\n",
    "        filtered_pivot = returns_pivot.drop(columns=nan_assets)\n",
    "        \n",
    "        current_assets = filtered_pivot.columns.tolist()\n",
    "        Y = filtered_pivot.values\n",
    "        n_train, p_current = Y.shape\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                  f\"Date: {current_date.strftime('%Y-%m-%d')} | Year: {current_year}\")\n",
    "            print(f\"  Window: {window_start_date.strftime('%Y-%m-%d')} to \"\n",
    "                  f\"{window_end_date.strftime('%Y-%m-%d')}\")\n",
    "            # NEW: Show both signal types\n",
    "            print(f\"  Yearly: {len(yearly_permnos)} | Analyst: {len(analyst_permnos)} | FinBERT: {len(finbert_permnos)} | \"\n",
    "                  f\"Union/Intersection: {len(allowed_permnos)} | Assets w/ data: {p_current}\")\n",
    "\n",
    "        # Check for valid data\n",
    "        if n_train < lookback_window or p_current < 2:\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ Insufficient data (n={n_train}, p={p_current}), recording 0 return\")\n",
    "            # Liquidate all three strategies\n",
    "            for idx, (pw, po, pg) in enumerate([\n",
    "                (prev_weights_dict, prev_oos_returns_dict, prev_gross_return),\n",
    "                (prev_weights_dict_2, prev_oos_returns_dict_2, prev_gross_return_2),\n",
    "                (prev_weights_dict_3, prev_oos_returns_dict_3, prev_gross_return_3)\n",
    "            ]):\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    pw, po, pg, transaction_cost, verbose=verbose\n",
    "                )\n",
    "                \n",
    "                if idx == 0:  # GMV\n",
    "                    portfolio_returns.append(net_return)\n",
    "                    portfolio_dates.append(current_date)\n",
    "                    portfolio_weights_list.append({})\n",
    "                    portfolio_turnover_list.append(turnover)\n",
    "                    portfolio_gross_returns.append(0.0)\n",
    "                elif idx == 1:  # MV\n",
    "                    portfolio_returns_2.append(net_return)\n",
    "                    portfolio_dates_2.append(current_date)\n",
    "                    portfolio_weights_list_2.append({})\n",
    "                    portfolio_turnover_list_2.append(turnover)\n",
    "                    portfolio_gross_returns_2.append(0.0)\n",
    "                else:  # MSR\n",
    "                    portfolio_returns_3.append(net_return)\n",
    "                    portfolio_dates_3.append(current_date)\n",
    "                    portfolio_weights_list_3.append({})\n",
    "                    portfolio_turnover_list_3.append(turnover)\n",
    "                    portfolio_gross_returns_3.append(0.0)\n",
    "            \n",
    "            # Reset all state\n",
    "            prev_weights_dict = {}\n",
    "            prev_oos_returns_dict = {}\n",
    "            prev_gross_return = 0.0\n",
    "            prev_weights_dict_2 = {}\n",
    "            prev_oos_returns_dict_2 = {}\n",
    "            prev_gross_return_2 = 0.0\n",
    "            prev_weights_dict_3 = {}\n",
    "            prev_oos_returns_dict_3 = {}\n",
    "            prev_gross_return_3 = 0.0\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                # Demean the returns\n",
    "                Y_bar = Y.mean(axis=0)\n",
    "                Y_star = Y - Y_bar\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Running Deep Learning Regression...\")\n",
    "                F = train_factor.values.astype(float)\n",
    "                Theta_hat = poet(Y_star, 8)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Computing GMV weights...\")\n",
    "                w_star = gmv_weights(Theta_hat)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Computing MV weights...\")\n",
    "                w_star_2 = mv_weights(Theta_hat, Y_bar, target_return=0.01)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Computing MSR weights...\")\n",
    "                w_star_3 = msr_weights(Theta_hat, Y_bar)\n",
    "                \n",
    "                # Create weights dictionaries\n",
    "                new_weights_dict = {asset: w_star[i] for i, asset in enumerate(current_assets)}\n",
    "                new_weights_dict_2 = {asset: w_star_2[i] for i, asset in enumerate(current_assets)}\n",
    "                new_weights_dict_3 = {asset: w_star_3[i] for i, asset in enumerate(current_assets)}\n",
    "                \n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"  ✗ Error: {e}\")\n",
    "                    print(f\"  Using previous weights\")\n",
    "                new_weights_dict = prev_weights_dict.copy()\n",
    "                new_weights_dict_2 = prev_weights_dict_2.copy()\n",
    "                new_weights_dict_3 = prev_weights_dict_3.copy()\n",
    "\n",
    "        # Normalize weights to sum to 1 - GMV\n",
    "        weight_sum = sum(new_weights_dict.values())\n",
    "        if weight_sum > 1e-10:\n",
    "            new_weights_dict = {k: v/weight_sum for k, v in new_weights_dict.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ GMV: Zero weight sum, using previous weights\")\n",
    "            new_weights_dict = prev_weights_dict.copy()\n",
    "            weight_sum = sum(new_weights_dict.values())\n",
    "            if weight_sum > 1e-10:\n",
    "                new_weights_dict = {k: v/weight_sum for k, v in new_weights_dict.items()}\n",
    "        \n",
    "        # Normalize weights to sum to 1 - MV\n",
    "        weight_sum_2 = sum(new_weights_dict_2.values())\n",
    "        if weight_sum_2 > 1e-10:\n",
    "            new_weights_dict_2 = {k: v/weight_sum_2 for k, v in new_weights_dict_2.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ MV: Zero weight sum, using previous weights\")\n",
    "            new_weights_dict_2 = prev_weights_dict_2.copy()\n",
    "            weight_sum_2 = sum(new_weights_dict_2.values())\n",
    "            if weight_sum_2 > 1e-10:\n",
    "                new_weights_dict_2 = {k: v/weight_sum_2 for k, v in new_weights_dict_2.items()}\n",
    "        \n",
    "        # Normalize weights to sum to 1 - MSR\n",
    "        weight_sum_3 = sum(new_weights_dict_3.values())\n",
    "        if weight_sum_3 > 1e-10:\n",
    "            new_weights_dict_3 = {k: v/weight_sum_3 for k, v in new_weights_dict_3.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ MSR: Zero weight sum, using previous weights\")\n",
    "            new_weights_dict_3 = prev_weights_dict_3.copy()\n",
    "            weight_sum_3 = sum(new_weights_dict_3.values())\n",
    "            if weight_sum_3 > 1e-10:\n",
    "                new_weights_dict_3 = {k: v/weight_sum_3 for k, v in new_weights_dict_3.items()}\n",
    "        \n",
    "        # --- 3. OOS Returns & Transaction Costs ---\n",
    "        \n",
    "        # Get out-of-sample returns for current month (only for allowed permnos)\n",
    "        oos_data = df[(df['datadate'] == current_date) & (df['permno'].isin(allowed_permnos))]\n",
    "        oos_returns_series = oos_data.set_index('permno')['ret_fwd_1']\n",
    "        \n",
    "        # Filter out NaN returns\n",
    "        oos_returns_series = oos_returns_series.dropna()\n",
    "        oos_returns_dict = oos_returns_series.to_dict()\n",
    "        \n",
    "        # Find common assets between weights and returns\n",
    "        common_assets = set(new_weights_dict.keys()) & set(oos_returns_dict.keys())\n",
    "        common_assets_2 = set(new_weights_dict_2.keys()) & set(oos_returns_dict.keys())\n",
    "        common_assets_3 = set(new_weights_dict_3.keys()) & set(oos_returns_dict.keys())\n",
    "        \n",
    "        if len(common_assets) == 0 or len(common_assets_2) == 0 or len(common_assets_3) == 0:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ No common assets with valid returns, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Filter to common assets and renormalize - GMV\n",
    "        common_weights = {a: new_weights_dict[a] for a in common_assets}\n",
    "        common_weight_sum = sum(common_weights.values())\n",
    "        if common_weight_sum > 1e-10:\n",
    "            common_weights = {k: v/common_weight_sum for k, v in common_weights.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ GMV: Zero weight sum after filtering, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Filter to common assets and renormalize - MV\n",
    "        common_weights_2 = {a: new_weights_dict_2[a] for a in common_assets_2}\n",
    "        common_weight_sum_2 = sum(common_weights_2.values())\n",
    "        if common_weight_sum_2 > 1e-10:\n",
    "            common_weights_2 = {k: v/common_weight_sum_2 for k, v in common_weights_2.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ MV: Zero weight sum after filtering, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Filter to common assets and renormalize - MSR\n",
    "        common_weights_3 = {a: new_weights_dict_3[a] for a in common_assets_3}\n",
    "        common_weight_sum_3 = sum(common_weights_3.values())\n",
    "        if common_weight_sum_3 > 1e-10:\n",
    "            common_weights_3 = {k: v/common_weight_sum_3 for k, v in common_weights_3.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ MSR: Zero weight sum after filtering, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Compute gross portfolio returns\n",
    "        gross_return = sum(common_weights[a] * oos_returns_dict[a] for a in common_assets)\n",
    "        gross_return_2 = sum(common_weights_2[a] * oos_returns_dict[a] for a in common_assets_2)\n",
    "        gross_return_3 = sum(common_weights_3[a] * oos_returns_dict[a] for a in common_assets_3)\n",
    "        \n",
    "        # Sanity checks\n",
    "        if np.isnan(gross_return) or np.isinf(gross_return):\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ GMV: Invalid gross return: {gross_return}, skipping period\")\n",
    "            continue\n",
    "        if np.isnan(gross_return_2) or np.isinf(gross_return_2):\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ MV: Invalid gross return: {gross_return_2}, skipping period\")\n",
    "            continue\n",
    "        if np.isnan(gross_return_3) or np.isinf(gross_return_3):\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ MSR: Invalid gross return: {gross_return_3}, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # === IMPROVED TRANSACTION COST CALCULATION - GMV ===\n",
    "        if len(prev_weights_dict) > 0:\n",
    "            # Step 1: Adjust ALL previous weights for their returns\n",
    "            adjusted_prev = {}\n",
    "            \n",
    "            for asset, prev_w in prev_weights_dict.items():\n",
    "                if asset in prev_oos_returns_dict:\n",
    "                    prev_r = prev_oos_returns_dict[asset]\n",
    "                    if abs(1 + prev_gross_return) > 1e-6:\n",
    "                        adjusted_prev[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return)\n",
    "                    else:\n",
    "                        adjusted_prev[asset] = 0.0\n",
    "                else:\n",
    "                    # Asset had weight but no return data (exited)\n",
    "                    if abs(1 + prev_gross_return) > 1e-6:\n",
    "                        adjusted_prev[asset] = prev_w / (1 + prev_gross_return)\n",
    "                    else:\n",
    "                        adjusted_prev[asset] = 0.0\n",
    "            \n",
    "            # Step 2: Calculate turnover across all assets (old and new)\n",
    "            all_assets = set(adjusted_prev.keys()) | set(common_weights.keys())\n",
    "            \n",
    "            turnover = 0.0\n",
    "            for asset in all_assets:\n",
    "                old_w = adjusted_prev.get(asset, 0.0)\n",
    "                new_w = common_weights.get(asset, 0.0)\n",
    "                turnover += abs(new_w - old_w)\n",
    "            \n",
    "            # Transaction cost on end-of-period portfolio value\n",
    "            tc = transaction_cost * (1 + gross_return) * turnover\n",
    "        else:\n",
    "            # First period: buying into everything\n",
    "            turnover = sum(abs(w) for w in common_weights.values())\n",
    "            tc = transaction_cost * (1 + gross_return) * turnover\n",
    "        \n",
    "        # === IMPROVED TRANSACTION COST CALCULATION - MV ===\n",
    "        if len(prev_weights_dict_2) > 0:\n",
    "            adjusted_prev_2 = {}\n",
    "            \n",
    "            for asset, prev_w in prev_weights_dict_2.items():\n",
    "                if asset in prev_oos_returns_dict_2:\n",
    "                    prev_r = prev_oos_returns_dict_2[asset]\n",
    "                    if abs(1 + prev_gross_return_2) > 1e-6:\n",
    "                        adjusted_prev_2[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return_2)\n",
    "                    else:\n",
    "                        adjusted_prev_2[asset] = 0.0\n",
    "                else:\n",
    "                    if abs(1 + prev_gross_return_2) > 1e-6:\n",
    "                        adjusted_prev_2[asset] = prev_w / (1 + prev_gross_return_2)\n",
    "                    else:\n",
    "                        adjusted_prev_2[asset] = 0.0\n",
    "            \n",
    "            all_assets_2 = set(adjusted_prev_2.keys()) | set(common_weights_2.keys())\n",
    "            \n",
    "            turnover_2 = 0.0\n",
    "            for asset in all_assets_2:\n",
    "                old_w = adjusted_prev_2.get(asset, 0.0)\n",
    "                new_w = common_weights_2.get(asset, 0.0)\n",
    "                turnover_2 += abs(new_w - old_w)\n",
    "            \n",
    "            tc_2 = transaction_cost * (1 + gross_return_2) * turnover_2\n",
    "        else:\n",
    "            turnover_2 = sum(abs(w) for w in common_weights_2.values())\n",
    "            tc_2 = transaction_cost * (1 + gross_return_2) * turnover_2\n",
    "        \n",
    "        # === IMPROVED TRANSACTION COST CALCULATION - MSR ===\n",
    "        if len(prev_weights_dict_3) > 0:\n",
    "            adjusted_prev_3 = {}\n",
    "            \n",
    "            for asset, prev_w in prev_weights_dict_3.items():\n",
    "                if asset in prev_oos_returns_dict_3:\n",
    "                    prev_r = prev_oos_returns_dict_3[asset]\n",
    "                    if abs(1 + prev_gross_return_3) > 1e-6:\n",
    "                        adjusted_prev_3[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return_3)\n",
    "                    else:\n",
    "                        adjusted_prev_3[asset] = 0.0\n",
    "                else:\n",
    "                    if abs(1 + prev_gross_return_3) > 1e-6:\n",
    "                        adjusted_prev_3[asset] = prev_w / (1 + prev_gross_return_3)\n",
    "                    else:\n",
    "                        adjusted_prev_3[asset] = 0.0\n",
    "            \n",
    "            all_assets_3 = set(adjusted_prev_3.keys()) | set(common_weights_3.keys())\n",
    "            \n",
    "            turnover_3 = 0.0\n",
    "            for asset in all_assets_3:\n",
    "                old_w = adjusted_prev_3.get(asset, 0.0)\n",
    "                new_w = common_weights_3.get(asset, 0.0)\n",
    "                turnover_3 += abs(new_w - old_w)\n",
    "            \n",
    "            tc_3 = transaction_cost * (1 + gross_return_3) * turnover_3\n",
    "        else:\n",
    "            turnover_3 = sum(abs(w) for w in common_weights_3.values())\n",
    "            tc_3 = transaction_cost * (1 + gross_return_3) * turnover_3\n",
    "        \n",
    "        # Net returns\n",
    "        net_return = gross_return - tc\n",
    "        net_return_2 = gross_return_2 - tc_2\n",
    "        net_return_3 = gross_return_3 - tc_3\n",
    "        \n",
    "        # Store results - GMV\n",
    "        portfolio_returns.append(net_return)\n",
    "        portfolio_dates.append(current_date)\n",
    "        portfolio_weights_list.append(common_weights.copy())\n",
    "        portfolio_turnover_list.append(turnover)\n",
    "        portfolio_gross_returns.append(gross_return)\n",
    "        \n",
    "        # Store results - MV\n",
    "        portfolio_returns_2.append(net_return_2)\n",
    "        portfolio_dates_2.append(current_date)\n",
    "        portfolio_weights_list_2.append(common_weights_2.copy())\n",
    "        portfolio_turnover_list_2.append(turnover_2)\n",
    "        portfolio_gross_returns_2.append(gross_return_2)\n",
    "        \n",
    "        # Store results - MSR\n",
    "        portfolio_returns_3.append(net_return_3)\n",
    "        portfolio_dates_3.append(current_date)\n",
    "        portfolio_weights_list_3.append(common_weights_3.copy())\n",
    "        portfolio_turnover_list_3.append(turnover_3)\n",
    "        portfolio_gross_returns_3.append(gross_return_3)\n",
    "        \n",
    "        # Update previous values for next iteration\n",
    "        prev_weights_dict = common_weights.copy()\n",
    "        prev_oos_returns_dict = {a: oos_returns_dict[a] for a in common_assets}\n",
    "        prev_gross_return = gross_return\n",
    "        \n",
    "        prev_weights_dict_2 = common_weights_2.copy()\n",
    "        prev_oos_returns_dict_2 = {a: oos_returns_dict[a] for a in common_assets_2}\n",
    "        prev_gross_return_2 = gross_return_2\n",
    "        \n",
    "        prev_weights_dict_3 = common_weights_3.copy()\n",
    "        prev_oos_returns_dict_3 = {a: oos_returns_dict[a] for a in common_assets_3}\n",
    "        prev_gross_return_3 = gross_return_3\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  GMV  - Gross: {gross_return:>8.5f} | Turnover: {turnover:>6.4f} | \"\n",
    "                  f\"TC: {tc:>8.6f} | Net: {net_return:>8.5f}\")\n",
    "            print(f\"  MV   - Gross: {gross_return_2:>8.5f} | Turnover: {turnover_2:>6.4f} | \"\n",
    "                  f\"TC: {tc_2:>8.6f} | Net: {net_return_2:>8.5f}\")\n",
    "            print(f\"  MSR  - Gross: {gross_return_3:>8.5f} | Turnover: {turnover_3:>6.4f} | \"\n",
    "                  f\"TC: {tc_3:>8.6f} | Net: {net_return_3:>8.5f}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BACKTEST COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    # --- 4. Compile Results ---\n",
    "    results_df = pd.DataFrame({\n",
    "        'date': portfolio_dates,\n",
    "        'portfolio_return': portfolio_returns,\n",
    "        'portfolio_gross_return': portfolio_gross_returns,\n",
    "        'portfolio_weights': portfolio_weights_list,\n",
    "        'portfolio_turnover': portfolio_turnover_list\n",
    "    })\n",
    "    results_df['cumulative_return'] = (1 + results_df['portfolio_return']).cumprod() - 1\n",
    "    \n",
    "    results_df_2 = pd.DataFrame({\n",
    "        'date': portfolio_dates_2,\n",
    "        'portfolio_return': portfolio_returns_2,\n",
    "        'portfolio_gross_return': portfolio_gross_returns_2,\n",
    "        'portfolio_weights': portfolio_weights_list_2,\n",
    "        'portfolio_turnover': portfolio_turnover_list_2\n",
    "    })\n",
    "    results_df_2['cumulative_return'] = (1 + results_df_2['portfolio_return']).cumprod() - 1\n",
    "    \n",
    "    results_df_3 = pd.DataFrame({\n",
    "        'date': portfolio_dates_3,\n",
    "        'portfolio_return': portfolio_returns_3,\n",
    "        'portfolio_gross_return': portfolio_gross_returns_3,\n",
    "        'portfolio_weights': portfolio_weights_list_3,\n",
    "        'portfolio_turnover': portfolio_turnover_list_3\n",
    "    })\n",
    "    results_df_3['cumulative_return'] = (1 + results_df_3['portfolio_return']).cumprod() - 1\n",
    "    \n",
    "    # Helper function to compute metrics\n",
    "    def compute_metrics(returns_list, turnover_list, results_df):\n",
    "        if len(returns_list) > 0:\n",
    "            mean_return = np.mean(returns_list)\n",
    "            variance = np.var(returns_list, ddof=1)\n",
    "            sharpe_ratio = mean_return / np.sqrt(variance) if variance > 0 else 0\n",
    "            \n",
    "            # Annualized metrics (monthly data)\n",
    "            annual_return = mean_return * 12\n",
    "            annual_volatility = np.sqrt(variance * 12)\n",
    "            annual_sharpe = annual_return / annual_volatility if annual_volatility > 0 else 0\n",
    "            \n",
    "            return {\n",
    "                'mean_return': mean_return,\n",
    "                'variance': variance,\n",
    "                'sharpe_ratio': sharpe_ratio,\n",
    "                'annual_return': annual_return,\n",
    "                'annual_volatility': annual_volatility,\n",
    "                'annual_sharpe_ratio': annual_sharpe,\n",
    "                'total_return': results_df['cumulative_return'].iloc[-1],\n",
    "                'avg_turnover': np.mean(turnover_list),\n",
    "                'n_periods': len(returns_list)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'mean_return': 0, 'variance': 0, 'sharpe_ratio': 0,\n",
    "                'annual_return': 0, 'annual_volatility': 0, 'annual_sharpe_ratio': 0,\n",
    "                'total_return': 0, 'avg_turnover': 0, 'n_periods': 0\n",
    "            }\n",
    "    \n",
    "    # Compute metrics for all three strategies\n",
    "    metrics = compute_metrics(portfolio_returns, portfolio_turnover_list, results_df)\n",
    "    metrics_2 = compute_metrics(portfolio_returns_2, portfolio_turnover_list_2, results_df_2)\n",
    "    metrics_3 = compute_metrics(portfolio_returns_3, portfolio_turnover_list_3, results_df_3)\n",
    "    \n",
    "    return results_df, metrics, results_df_2, metrics_2, results_df_3, metrics_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f77cbae-5233-4cbe-8d95-7d8e0a1a7e1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ticker to permno mapping...\n",
      "Mapped 1664 unique tickers to permnos\n",
      "Loaded FinBERT signals: 24780 monthly records\n",
      "FinBERT signal distribution:\n",
      "signal\n",
      "hold    23840\n",
      "sell      529\n",
      "buy       411\n",
      "Name: count, dtype: int64\n",
      "Loaded analyst recommendations: 16960 records\n",
      "============================================================\n",
      "STARTING BACKTEST WITH DNN-FM + YEARLY + ANALYST SIGNALS\n",
      "============================================================\n",
      "\n",
      "[1/52] Date: 2020-01-31 | Year: 2020\n",
      "  Window: 2005-01-31 to 2019-12-31\n",
      "  Yearly: 40 | Analyst: 71 | FinBERT: 8 | Union/Intersection: 10 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.08843 | Turnover: 1.0231 | TC: 0.000933 | Net: -0.08936\n",
      "  MV   - Gross: -0.08811 | Turnover: 1.2179 | TC: 0.001111 | Net: -0.08922\n",
      "  MSR  - Gross: -0.08825 | Turnover: 1.0739 | TC: 0.000979 | Net: -0.08923\n",
      "\n",
      "[2/52] Date: 2020-02-29 | Year: 2020\n",
      "  Window: 2005-02-28 to 2020-01-31\n",
      "  Yearly: 40 | Analyst: 73 | FinBERT: 10 | Union/Intersection: 5 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.21876 | Turnover: 1.6601 | TC: 0.001297 | Net: -0.22006\n",
      "  MV   - Gross: -0.25283 | Turnover: 2.0544 | TC: 0.001535 | Net: -0.25436\n",
      "  MSR  - Gross: -0.22183 | Turnover: 1.6666 | TC: 0.001297 | Net: -0.22312\n",
      "\n",
      "[3/52] Date: 2020-03-31 | Year: 2020\n",
      "  Window: 2005-03-31 to 2020-02-29\n",
      "  Yearly: 40 | Analyst: 174 | FinBERT: 14 | Union/Intersection: 21 | Assets w/ data: 14\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.09918 | Turnover: 1.2838 | TC: 0.001411 | Net:  0.09777\n",
      "  MV   - Gross: -0.01646 | Turnover: 2.2065 | TC: 0.002170 | Net: -0.01863\n",
      "  MSR  - Gross:  0.07274 | Turnover: 1.2535 | TC: 0.001345 | Net:  0.07139\n",
      "\n",
      "[4/52] Date: 2020-04-30 | Year: 2020\n",
      "  Window: 2005-04-30 to 2020-03-31\n",
      "  Yearly: 40 | Analyst: 203 | FinBERT: 10 | Union/Intersection: 22 | Assets w/ data: 17\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01545 | Turnover: 1.0911 | TC: 0.001108 | Net:  0.01434\n",
      "  MV   - Gross:  0.02779 | Turnover: 2.3522 | TC: 0.002418 | Net:  0.02538\n",
      "  MSR  - Gross:  0.02205 | Turnover: 1.2244 | TC: 0.001251 | Net:  0.02080\n",
      "\n",
      "[5/52] Date: 2020-05-31 | Year: 2020\n",
      "  Window: 2005-05-31 to 2020-04-30\n",
      "  Yearly: 40 | Analyst: 123 | FinBERT: 8 | Union/Intersection: 6 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00222 | Turnover: 1.9674 | TC: 0.001963 | Net: -0.00418\n",
      "  MV   - Gross: -0.02898 | Turnover: 2.2559 | TC: 0.002191 | Net: -0.03117\n",
      "  MSR  - Gross: -0.00833 | Turnover: 1.9178 | TC: 0.001902 | Net: -0.01023\n",
      "\n",
      "[6/52] Date: 2020-06-30 | Year: 2020\n",
      "  Window: 2005-06-30 to 2020-05-31\n",
      "  Yearly: 40 | Analyst: 110 | FinBERT: 7 | Union/Intersection: 9 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.05168 | Turnover: 2.0000 | TC: 0.002103 | Net:  0.04958\n",
      "  MV   - Gross:  0.06164 | Turnover: 2.5047 | TC: 0.002659 | Net:  0.05898\n",
      "  MSR  - Gross:  0.05863 | Turnover: 2.0502 | TC: 0.002170 | Net:  0.05646\n",
      "\n",
      "[7/52] Date: 2020-07-31 | Year: 2020\n",
      "  Window: 2005-07-31 to 2020-06-30\n",
      "  Yearly: 40 | Analyst: 138 | FinBERT: 4 | Union/Intersection: 13 | Assets w/ data: 10\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04891 | Turnover: 1.8574 | TC: 0.001948 | Net:  0.04696\n",
      "  MV   - Gross:  0.06225 | Turnover: 2.3019 | TC: 0.002445 | Net:  0.05980\n",
      "  MSR  - Gross:  0.05399 | Turnover: 2.0616 | TC: 0.002173 | Net:  0.05182\n",
      "\n",
      "[8/52] Date: 2020-08-31 | Year: 2020\n",
      "  Window: 2005-08-31 to 2020-07-31\n",
      "  Yearly: 40 | Analyst: 67 | FinBERT: 12 | Union/Intersection: 5 | Assets w/ data: 2\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07751 | Turnover: 2.0000 | TC: 0.002155 | Net:  0.07535\n",
      "  MV   - Gross:  0.03183 | Turnover: 2.6017 | TC: 0.002685 | Net:  0.02915\n",
      "  MSR  - Gross:  0.07288 | Turnover: 2.0000 | TC: 0.002146 | Net:  0.07074\n",
      "\n",
      "[9/52] Date: 2020-09-30 | Year: 2020\n",
      "  Window: 2005-09-30 to 2020-08-31\n",
      "  Yearly: 40 | Analyst: 111 | FinBERT: 17 | Union/Intersection: 18 | Assets w/ data: 8\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01587 | Turnover: 2.1703 | TC: 0.002205 | Net:  0.01366\n",
      "  MV   - Gross: -0.02531 | Turnover: 2.5700 | TC: 0.002505 | Net: -0.02781\n",
      "  MSR  - Gross: -0.01371 | Turnover: 2.1360 | TC: 0.002107 | Net: -0.01581\n",
      "\n",
      "[10/52] Date: 2020-10-31 | Year: 2020\n",
      "  Window: 2005-10-31 to 2020-09-30\n",
      "  Yearly: 40 | Analyst: 94 | FinBERT: 7 | Union/Intersection: 4 | Assets w/ data: 2\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00758 | Turnover: 2.1847 | TC: 0.002168 | Net: -0.00975\n",
      "  MV   - Gross: -0.01839 | Turnover: 2.2436 | TC: 0.002202 | Net: -0.02059\n",
      "  MSR  - Gross: -0.01131 | Turnover: 2.1558 | TC: 0.002131 | Net: -0.01344\n",
      "\n",
      "[11/52] Date: 2020-11-30 | Year: 2020\n",
      "  Window: 2005-11-30 to 2020-10-31\n",
      "  Yearly: 40 | Analyst: 110 | FinBERT: 7 | Union/Intersection: 14 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02905 | Turnover: 2.1532 | TC: 0.002216 | Net:  0.02683\n",
      "  MV   - Gross:  0.02041 | Turnover: 2.3419 | TC: 0.002390 | Net:  0.01802\n",
      "  MSR  - Gross:  0.00931 | Turnover: 2.5580 | TC: 0.002582 | Net:  0.00672\n",
      "\n",
      "[12/52] Date: 2020-12-31 | Year: 2020\n",
      "  Window: 2005-12-31 to 2020-11-30\n",
      "  Yearly: 40 | Analyst: 75 | FinBERT: 7 | Union/Intersection: 8 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.05002 | Turnover: 2.0469 | TC: 0.002149 | Net:  0.04787\n",
      "  MV   - Gross:  0.01219 | Turnover: 3.1969 | TC: 0.003236 | Net:  0.00895\n",
      "  MSR  - Gross:  0.04798 | Turnover: 2.5613 | TC: 0.002684 | Net:  0.04530\n",
      "\n",
      "[13/52] Date: 2021-01-31 | Year: 2021\n",
      "  Window: 2006-01-31 to 2020-12-31\n",
      "  Yearly: 123 | Analyst: 116 | FinBERT: 8 | Union/Intersection: 34 | Assets w/ data: 22\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07384 | Turnover: 2.2000 | TC: 0.002362 | Net:  0.07148\n",
      "  MV   - Gross:  0.00604 | Turnover: 3.2015 | TC: 0.003221 | Net:  0.00282\n",
      "  MSR  - Gross:  0.01085 | Turnover: 2.2739 | TC: 0.002299 | Net:  0.00855\n",
      "\n",
      "[14/52] Date: 2021-02-28 | Year: 2021\n",
      "  Window: 2006-02-28 to 2021-01-31\n",
      "  Yearly: 123 | Analyst: 87 | FinBERT: 15 | Union/Intersection: 34 | Assets w/ data: 21\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.08716 | Turnover: 1.6871 | TC: 0.001834 | Net:  0.08532\n",
      "  MV   - Gross:  0.08686 | Turnover: 1.8201 | TC: 0.001978 | Net:  0.08488\n",
      "  MSR  - Gross:  0.08505 | Turnover: 1.9260 | TC: 0.002090 | Net:  0.08296\n",
      "\n",
      "[15/52] Date: 2021-03-31 | Year: 2021\n",
      "  Window: 2006-03-31 to 2021-02-28\n",
      "  Yearly: 123 | Analyst: 103 | FinBERT: 11 | Union/Intersection: 22 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.06108 | Turnover: 1.3658 | TC: 0.001449 | Net:  0.05963\n",
      "  MV   - Gross:  0.05817 | Turnover: 1.3627 | TC: 0.001442 | Net:  0.05672\n",
      "  MSR  - Gross:  0.05774 | Turnover: 1.3680 | TC: 0.001447 | Net:  0.05630\n",
      "\n",
      "[16/52] Date: 2021-04-30 | Year: 2021\n",
      "  Window: 2006-04-30 to 2021-03-31\n",
      "  Yearly: 123 | Analyst: 104 | FinBERT: 15 | Union/Intersection: 28 | Assets w/ data: 18\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02452 | Turnover: 1.5647 | TC: 0.001603 | Net:  0.02292\n",
      "  MV   - Gross:  0.02891 | Turnover: 1.6418 | TC: 0.001689 | Net:  0.02722\n",
      "  MSR  - Gross:  0.01528 | Turnover: 1.7815 | TC: 0.001809 | Net:  0.01348\n",
      "\n",
      "[17/52] Date: 2021-05-31 | Year: 2021\n",
      "  Window: 2006-05-31 to 2021-04-30\n",
      "  Yearly: 123 | Analyst: 92 | FinBERT: 9 | Union/Intersection: 19 | Assets w/ data: 13\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00613 | Turnover: 1.9941 | TC: 0.001982 | Net: -0.00811\n",
      "  MV   - Gross: -0.00718 | Turnover: 2.0398 | TC: 0.002025 | Net: -0.00921\n",
      "  MSR  - Gross: -0.00724 | Turnover: 1.9316 | TC: 0.001918 | Net: -0.00916\n",
      "\n",
      "[18/52] Date: 2021-06-30 | Year: 2021\n",
      "  Window: 2006-06-30 to 2021-05-31\n",
      "  Yearly: 123 | Analyst: 100 | FinBERT: 13 | Union/Intersection: 28 | Assets w/ data: 14\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02543 | Turnover: 1.9844 | TC: 0.002035 | Net:  0.02339\n",
      "  MV   - Gross:  0.02642 | Turnover: 1.9639 | TC: 0.002016 | Net:  0.02440\n",
      "  MSR  - Gross:  0.03890 | Turnover: 2.0226 | TC: 0.002101 | Net:  0.03680\n",
      "\n",
      "[19/52] Date: 2021-07-31 | Year: 2021\n",
      "  Window: 2006-07-31 to 2021-06-30\n",
      "  Yearly: 123 | Analyst: 77 | FinBERT: 11 | Union/Intersection: 20 | Assets w/ data: 13\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01610 | Turnover: 1.6265 | TC: 0.001600 | Net: -0.01770\n",
      "  MV   - Gross: -0.00883 | Turnover: 1.8086 | TC: 0.001793 | Net: -0.01063\n",
      "  MSR  - Gross: -0.02271 | Turnover: 1.5410 | TC: 0.001506 | Net: -0.02421\n",
      "\n",
      "[20/52] Date: 2021-08-31 | Year: 2021\n",
      "  Window: 2006-08-31 to 2021-07-31\n",
      "  Yearly: 123 | Analyst: 65 | FinBERT: 11 | Union/Intersection: 19 | Assets w/ data: 16\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00577 | Turnover: 1.8786 | TC: 0.001868 | Net: -0.00764\n",
      "  MV   - Gross: -0.00860 | Turnover: 2.1101 | TC: 0.002092 | Net: -0.01070\n",
      "  MSR  - Gross: -0.00252 | Turnover: 1.7078 | TC: 0.001703 | Net: -0.00422\n",
      "\n",
      "[21/52] Date: 2021-09-30 | Year: 2021\n",
      "  Window: 2006-09-30 to 2021-08-31\n",
      "  Yearly: 123 | Analyst: 80 | FinBERT: 12 | Union/Intersection: 19 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04712 | Turnover: 1.2297 | TC: 0.001288 | Net:  0.04583\n",
      "  MV   - Gross:  0.05047 | Turnover: 1.1928 | TC: 0.001253 | Net:  0.04922\n",
      "  MSR  - Gross:  0.04345 | Turnover: 1.3884 | TC: 0.001449 | Net:  0.04200\n",
      "\n",
      "[22/52] Date: 2021-10-31 | Year: 2021\n",
      "  Window: 2006-10-31 to 2021-09-30\n",
      "  Yearly: 123 | Analyst: 141 | FinBERT: 12 | Union/Intersection: 35 | Assets w/ data: 22\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02956 | Turnover: 1.9626 | TC: 0.001905 | Net: -0.03146\n",
      "  MV   - Gross: -0.02883 | Turnover: 1.9566 | TC: 0.001900 | Net: -0.03073\n",
      "  MSR  - Gross: -0.02207 | Turnover: 2.0040 | TC: 0.001960 | Net: -0.02403\n",
      "\n",
      "[23/52] Date: 2021-11-30 | Year: 2021\n",
      "  Window: 2006-11-30 to 2021-10-31\n",
      "  Yearly: 123 | Analyst: 103 | FinBERT: 9 | Union/Intersection: 27 | Assets w/ data: 19\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.05804 | Turnover: 1.3495 | TC: 0.001428 | Net:  0.05662\n",
      "  MV   - Gross:  0.06759 | Turnover: 1.4918 | TC: 0.001593 | Net:  0.06600\n",
      "  MSR  - Gross:  0.07082 | Turnover: 1.6197 | TC: 0.001734 | Net:  0.06909\n",
      "\n",
      "[24/52] Date: 2021-12-31 | Year: 2021\n",
      "  Window: 2006-12-31 to 2021-11-30\n",
      "  Yearly: 123 | Analyst: 63 | FinBERT: 8 | Union/Intersection: 15 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02401 | Turnover: 2.0956 | TC: 0.002045 | Net: -0.02606\n",
      "  MV   - Gross:  0.01808 | Turnover: 2.0119 | TC: 0.002048 | Net:  0.01604\n",
      "  MSR  - Gross: -0.05187 | Turnover: 2.2057 | TC: 0.002091 | Net: -0.05396\n",
      "\n",
      "[25/52] Date: 2022-01-31 | Year: 2022\n",
      "  Window: 2007-01-31 to 2021-12-31\n",
      "  Yearly: 34 | Analyst: 114 | FinBERT: 29 | Union/Intersection: 18 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02281 | Turnover: 2.1577 | TC: 0.002109 | Net: -0.02492\n",
      "  MV   - Gross: -0.01813 | Turnover: 2.1066 | TC: 0.002068 | Net: -0.02020\n",
      "  MSR  - Gross: -0.03585 | Turnover: 2.2724 | TC: 0.002191 | Net: -0.03804\n",
      "\n",
      "[26/52] Date: 2022-02-28 | Year: 2022\n",
      "  Window: 2007-02-28 to 2022-01-31\n",
      "  Yearly: 34 | Analyst: 99 | FinBERT: 15 | Union/Intersection: 16 | Assets w/ data: 10\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.06803 | Turnover: 1.0663 | TC: 0.001139 | Net:  0.06690\n",
      "  MV   - Gross:  0.06839 | Turnover: 1.0737 | TC: 0.001147 | Net:  0.06725\n",
      "  MSR  - Gross:  0.05961 | Turnover: 1.2032 | TC: 0.001275 | Net:  0.05833\n",
      "\n",
      "[27/52] Date: 2022-03-31 | Year: 2022\n",
      "  Window: 2007-03-31 to 2022-02-28\n",
      "  Yearly: 34 | Analyst: 88 | FinBERT: 16 | Union/Intersection: 12 | Assets w/ data: 8\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.06427 | Turnover: 1.2579 | TC: 0.001177 | Net: -0.06544\n",
      "  MV   - Gross: -0.05073 | Turnover: 1.3485 | TC: 0.001280 | Net: -0.05201\n",
      "  MSR  - Gross: -0.07817 | Turnover: 1.3468 | TC: 0.001242 | Net: -0.07941\n",
      "\n",
      "[28/52] Date: 2022-04-30 | Year: 2022\n",
      "  Window: 2007-04-30 to 2022-03-31\n",
      "  Yearly: 34 | Analyst: 101 | FinBERT: 19 | Union/Intersection: 14 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07640 | Turnover: 1.3659 | TC: 0.001470 | Net:  0.07493\n",
      "  MV   - Gross:  0.06980 | Turnover: 1.4129 | TC: 0.001512 | Net:  0.06829\n",
      "  MSR  - Gross:  0.06191 | Turnover: 1.1721 | TC: 0.001245 | Net:  0.06067\n",
      "\n",
      "[29/52] Date: 2022-05-31 | Year: 2022\n",
      "  Window: 2007-05-31 to 2022-04-30\n",
      "  Yearly: 34 | Analyst: 78 | FinBERT: 10 | Union/Intersection: 8 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.04646 | Turnover: 1.3414 | TC: 0.001279 | Net: -0.04774\n",
      "  MV   - Gross: -0.03967 | Turnover: 1.3364 | TC: 0.001283 | Net: -0.04096\n",
      "  MSR  - Gross: -0.06736 | Turnover: 1.3303 | TC: 0.001241 | Net: -0.06860\n",
      "\n",
      "[30/52] Date: 2022-06-30 | Year: 2022\n",
      "  Window: 2007-06-30 to 2022-05-31\n",
      "  Yearly: 34 | Analyst: 96 | FinBERT: 11 | Union/Intersection: 12 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07010 | Turnover: 2.0000 | TC: 0.002140 | Net:  0.06796\n",
      "  MV   - Gross:  0.06960 | Turnover: 2.0000 | TC: 0.002139 | Net:  0.06746\n",
      "  MSR  - Gross:  0.07266 | Turnover: 2.0000 | TC: 0.002145 | Net:  0.07051\n",
      "\n",
      "[31/52] Date: 2022-07-31 | Year: 2022\n",
      "  Window: 2007-07-31 to 2022-06-30\n",
      "  Yearly: 34 | Analyst: 100 | FinBERT: 24 | Union/Intersection: 16 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.06660 | Turnover: 1.6886 | TC: 0.001576 | Net: -0.06817\n",
      "  MV   - Gross: -0.07057 | Turnover: 1.5956 | TC: 0.001483 | Net: -0.07205\n",
      "  MSR  - Gross: -0.07536 | Turnover: 1.4833 | TC: 0.001372 | Net: -0.07673\n",
      "\n",
      "[32/52] Date: 2022-08-31 | Year: 2022\n",
      "  Window: 2007-08-31 to 2022-07-31\n",
      "  Yearly: 34 | Analyst: 80 | FinBERT: 12 | Union/Intersection: 7 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02552 | Turnover: 1.7963 | TC: 0.001750 | Net: -0.02727\n",
      "  MV   - Gross:  0.07314 | Turnover: 2.6770 | TC: 0.002873 | Net:  0.07027\n",
      "  MSR  - Gross: -0.03681 | Turnover: 1.6180 | TC: 0.001558 | Net: -0.03837\n",
      "\n",
      "[33/52] Date: 2022-09-30 | Year: 2022\n",
      "  Window: 2007-09-30 to 2022-08-31\n",
      "  Yearly: 34 | Analyst: 79 | FinBERT: 19 | Union/Intersection: 10 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.06925 | Turnover: 1.4497 | TC: 0.001550 | Net:  0.06770\n",
      "  MV   - Gross:  0.07063 | Turnover: 2.5252 | TC: 0.002704 | Net:  0.06793\n",
      "  MSR  - Gross:  0.06891 | Turnover: 1.4396 | TC: 0.001539 | Net:  0.06737\n",
      "\n",
      "[34/52] Date: 2022-10-31 | Year: 2022\n",
      "  Window: 2007-10-31 to 2022-09-30\n",
      "  Yearly: 34 | Analyst: 88 | FinBERT: 25 | Union/Intersection: 17 | Assets w/ data: 10\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03991 | Turnover: 1.5796 | TC: 0.001643 | Net:  0.03827\n",
      "  MV   - Gross:  0.04143 | Turnover: 1.8445 | TC: 0.001921 | Net:  0.03951\n",
      "  MSR  - Gross:  0.03372 | Turnover: 1.3935 | TC: 0.001441 | Net:  0.03228\n",
      "\n",
      "[35/52] Date: 2022-11-30 | Year: 2022\n",
      "  Window: 2007-11-30 to 2022-10-31\n",
      "  Yearly: 34 | Analyst: 79 | FinBERT: 25 | Union/Intersection: 11 | Assets w/ data: 8\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.05508 | Turnover: 1.7839 | TC: 0.001686 | Net: -0.05677\n",
      "  MV   - Gross: -0.04741 | Turnover: 2.0405 | TC: 0.001944 | Net: -0.04936\n",
      "  MSR  - Gross: -0.05765 | Turnover: 1.6676 | TC: 0.001571 | Net: -0.05922\n",
      "\n",
      "[36/52] Date: 2022-12-31 | Year: 2022\n",
      "  Window: 2007-12-31 to 2022-11-30\n",
      "  Yearly: 34 | Analyst: 50 | FinBERT: 9 | Union/Intersection: 7 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.06384 | Turnover: 1.8129 | TC: 0.001929 | Net:  0.06191\n",
      "  MV   - Gross:  0.07577 | Turnover: 1.9230 | TC: 0.002069 | Net:  0.07370\n",
      "  MSR  - Gross:  0.04401 | Turnover: 1.7861 | TC: 0.001865 | Net:  0.04214\n",
      "\n",
      "[37/52] Date: 2023-01-31 | Year: 2023\n",
      "  Window: 2008-01-31 to 2022-12-31\n",
      "  Yearly: 137 | Analyst: 98 | FinBERT: 23 | Union/Intersection: 32 | Assets w/ data: 15\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02970 | Turnover: 2.1697 | TC: 0.002105 | Net: -0.03181\n",
      "  MV   - Gross: -0.03654 | Turnover: 2.1985 | TC: 0.002118 | Net: -0.03865\n",
      "  MSR  - Gross: -0.04393 | Turnover: 2.2520 | TC: 0.002153 | Net: -0.04608\n",
      "\n",
      "[38/52] Date: 2023-02-28 | Year: 2023\n",
      "  Window: 2008-02-29 to 2023-01-31\n",
      "  Yearly: 137 | Analyst: 99 | FinBERT: 23 | Union/Intersection: 30 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02313 | Turnover: 2.0482 | TC: 0.002001 | Net: -0.02514\n",
      "  MV   - Gross: -0.02328 | Turnover: 2.0882 | TC: 0.002040 | Net: -0.02532\n",
      "  MSR  - Gross: -0.01933 | Turnover: 2.1447 | TC: 0.002103 | Net: -0.02143\n",
      "\n",
      "[39/52] Date: 2023-03-31 | Year: 2023\n",
      "  Window: 2008-03-31 to 2023-02-28\n",
      "  Yearly: 137 | Analyst: 70 | FinBERT: 20 | Union/Intersection: 24 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00193 | Turnover: 1.7406 | TC: 0.001737 | Net: -0.00367\n",
      "  MV   - Gross: -0.00214 | Turnover: 1.7962 | TC: 0.001792 | Net: -0.00394\n",
      "  MSR  - Gross: -0.00113 | Turnover: 1.5138 | TC: 0.001512 | Net: -0.00264\n",
      "\n",
      "[40/52] Date: 2023-04-30 | Year: 2023\n",
      "  Window: 2008-04-30 to 2023-03-31\n",
      "  Yearly: 137 | Analyst: 88 | FinBERT: 23 | Union/Intersection: 25 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.05526 | Turnover: 2.1098 | TC: 0.001993 | Net: -0.05725\n",
      "  MV   - Gross: -0.03621 | Turnover: 2.1514 | TC: 0.002074 | Net: -0.03828\n",
      "  MSR  - Gross: -0.09320 | Turnover: 2.2166 | TC: 0.002010 | Net: -0.09521\n",
      "\n",
      "[41/52] Date: 2023-05-31 | Year: 2023\n",
      "  Window: 2008-05-31 to 2023-04-30\n",
      "  Yearly: 137 | Analyst: 67 | FinBERT: 20 | Union/Intersection: 22 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.11167 | Turnover: 1.9610 | TC: 0.002180 | Net:  0.10949\n",
      "  MV   - Gross:  0.12357 | Turnover: 1.9543 | TC: 0.002196 | Net:  0.12138\n",
      "  MSR  - Gross:  0.08864 | Turnover: 2.0630 | TC: 0.002246 | Net:  0.08639\n",
      "\n",
      "[42/52] Date: 2023-06-30 | Year: 2023\n",
      "  Window: 2008-06-30 to 2023-05-31\n",
      "  Yearly: 137 | Analyst: 68 | FinBERT: 25 | Union/Intersection: 28 | Assets w/ data: 16\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03169 | Turnover: 1.9716 | TC: 0.002034 | Net:  0.02965\n",
      "  MV   - Gross:  0.03323 | Turnover: 1.9723 | TC: 0.002038 | Net:  0.03119\n",
      "  MSR  - Gross:  0.02980 | Turnover: 1.9707 | TC: 0.002029 | Net:  0.02777\n",
      "\n",
      "[43/52] Date: 2023-07-31 | Year: 2023\n",
      "  Window: 2008-07-31 to 2023-06-30\n",
      "  Yearly: 137 | Analyst: 82 | FinBERT: 32 | Union/Intersection: 33 | Assets w/ data: 17\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.03551 | Turnover: 1.2089 | TC: 0.001166 | Net: -0.03668\n",
      "  MV   - Gross: -0.04809 | Turnover: 1.1102 | TC: 0.001057 | Net: -0.04915\n",
      "  MSR  - Gross: -0.02817 | Turnover: 1.2859 | TC: 0.001250 | Net: -0.02942\n",
      "\n",
      "[44/52] Date: 2023-08-31 | Year: 2023\n",
      "  Window: 2008-08-31 to 2023-07-31\n",
      "  Yearly: 137 | Analyst: 93 | FinBERT: 29 | Union/Intersection: 38 | Assets w/ data: 17\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.04647 | Turnover: 1.1583 | TC: 0.001104 | Net: -0.04757\n",
      "  MV   - Gross: -0.04010 | Turnover: 1.0436 | TC: 0.001002 | Net: -0.04110\n",
      "  MSR  - Gross: -0.05956 | Turnover: 1.1740 | TC: 0.001104 | Net: -0.06067\n",
      "\n",
      "[45/52] Date: 2023-09-30 | Year: 2023\n",
      "  Window: 2008-09-30 to 2023-08-31\n",
      "  Yearly: 137 | Analyst: 83 | FinBERT: 27 | Union/Intersection: 34 | Assets w/ data: 16\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01909 | Turnover: 1.8177 | TC: 0.001783 | Net: -0.02088\n",
      "  MV   - Gross: -0.01246 | Turnover: 2.0161 | TC: 0.001991 | Net: -0.01445\n",
      "  MSR  - Gross: -0.02482 | Turnover: 1.6354 | TC: 0.001595 | Net: -0.02642\n",
      "\n",
      "[46/52] Date: 2023-10-31 | Year: 2023\n",
      "  Window: 2008-10-31 to 2023-09-30\n",
      "  Yearly: 137 | Analyst: 112 | FinBERT: 31 | Union/Intersection: 41 | Assets w/ data: 21\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.08031 | Turnover: 1.5008 | TC: 0.001621 | Net:  0.07869\n",
      "  MV   - Gross:  0.06855 | Turnover: 1.7133 | TC: 0.001831 | Net:  0.06672\n",
      "  MSR  - Gross:  0.08952 | Turnover: 1.3958 | TC: 0.001521 | Net:  0.08800\n",
      "\n",
      "[47/52] Date: 2023-11-30 | Year: 2023\n",
      "  Window: 2008-11-30 to 2023-10-31\n",
      "  Yearly: 137 | Analyst: 91 | FinBERT: 35 | Union/Intersection: 39 | Assets w/ data: 20\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02532 | Turnover: 1.2507 | TC: 0.001282 | Net:  0.02404\n",
      "  MV   - Gross:  0.01965 | Turnover: 1.4705 | TC: 0.001499 | Net:  0.01815\n",
      "  MSR  - Gross:  0.02806 | Turnover: 1.2105 | TC: 0.001244 | Net:  0.02682\n",
      "\n",
      "[48/52] Date: 2023-12-31 | Year: 2023\n",
      "  Window: 2008-12-31 to 2023-11-30\n",
      "  Yearly: 137 | Analyst: 87 | FinBERT: 36 | Union/Intersection: 32 | Assets w/ data: 16\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00051 | Turnover: 1.6519 | TC: 0.001651 | Net: -0.00216\n",
      "  MV   - Gross: -0.02987 | Turnover: 2.0163 | TC: 0.001956 | Net: -0.03183\n",
      "  MSR  - Gross:  0.01605 | Turnover: 1.6325 | TC: 0.001659 | Net:  0.01439\n",
      "\n",
      "[49/52] Date: 2024-01-31 | Year: 2024\n",
      "  Window: 2009-01-31 to 2023-12-31\n",
      "  Yearly: 281 | Analyst: 106 | FinBERT: 49 | Union/Intersection: 71 | Assets w/ data: 46\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02336 | Turnover: 2.1389 | TC: 0.002189 | Net:  0.02118\n",
      "  MV   - Gross:  0.01733 | Turnover: 2.3608 | TC: 0.002402 | Net:  0.01493\n",
      "  MSR  - Gross:  0.04315 | Turnover: 2.3311 | TC: 0.002432 | Net:  0.04072\n",
      "\n",
      "[50/52] Date: 2024-02-29 | Year: 2024\n",
      "  Window: 2009-02-28 to 2024-01-31\n",
      "  Yearly: 281 | Analyst: 114 | FinBERT: 28 | Union/Intersection: 72 | Assets w/ data: 44\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04365 | Turnover: 1.5955 | TC: 0.001665 | Net:  0.04199\n",
      "  MV   - Gross:  0.04418 | Turnover: 1.5643 | TC: 0.001633 | Net:  0.04254\n",
      "  MSR  - Gross:  0.04277 | Turnover: 1.8434 | TC: 0.001922 | Net:  0.04085\n",
      "\n",
      "[51/52] Date: 2024-03-31 | Year: 2024\n",
      "  Window: 2009-03-31 to 2024-02-29\n",
      "  Yearly: 281 | Analyst: 71 | FinBERT: 32 | Union/Intersection: 54 | Assets w/ data: 38\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.03741 | Turnover: 1.4149 | TC: 0.001362 | Net: -0.03877\n",
      "  MV   - Gross: -0.03849 | Turnover: 1.4204 | TC: 0.001366 | Net: -0.03985\n",
      "  MSR  - Gross: -0.03507 | Turnover: 1.5805 | TC: 0.001525 | Net: -0.03659\n",
      "\n",
      "[52/52] Date: 2024-04-30 | Year: 2024\n",
      "  Window: 2009-04-30 to 2024-03-31\n",
      "  Yearly: 281 | Analyst: 94 | FinBERT: 42 | Union/Intersection: 64 | Assets w/ data: 36\n",
      "  Running Deep Learning Regression...\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04773 | Turnover: 1.7946 | TC: 0.001880 | Net:  0.04585\n",
      "  MV   - Gross:  0.04797 | Turnover: 1.9167 | TC: 0.002009 | Net:  0.04596\n",
      "  MSR  - Gross:  0.04760 | Turnover: 1.8629 | TC: 0.001952 | Net:  0.04565\n",
      "\n",
      "============================================================\n",
      "BACKTEST COMPLETE\n",
      "============================================================\n",
      "\n",
      " GMV\n",
      "\n",
      "Sharpe Ratio: 0.1637\n",
      "Annualized Sharpe Ratio: 0.5669\n",
      "Total Return: 0.4995\n",
      "Average Turnover: 1.7156\n",
      "\n",
      " MV\n",
      "\n",
      "Sharpe Ratio: 0.0979\n",
      "Annualized Sharpe Ratio: 0.3391\n",
      "Total Return: 0.2288\n",
      "Average Turnover: 1.9447\n",
      "\n",
      " MSR\n",
      "\n",
      "Sharpe Ratio: 0.0606\n",
      "Annualized Sharpe Ratio: 0.2098\n",
      "Total Return: 0.0970\n",
      "Average Turnover: 1.7549\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../green cleaned.csv', dtype={'ncusip': 'string'})\n",
    "df['ret_fwd_1'] = df.groupby('permno')['ret_excess'].shift(-1)\n",
    "\n",
    "data_f=pd.read_csv('F-F_Research_Data_Factors.csv',sep=',')\n",
    "data_f['Date']=pd.to_datetime(data_f['Date'], format=\"%Y%m\")\n",
    "data_f['Date']=data_f['Date']+pd.offsets.MonthEnd(0)\n",
    "data_f = data_f.set_index('Date')\n",
    "data_f = data_f[['Mkt-RF', 'SMB', 'HML', 'RF']].astype(float)\n",
    "\n",
    "# Run backtest with yearly signals\n",
    "results_df, metrics, results_df_2, metrics_2, results_df_3, metrics_3= backtest_dnn_yearly(\n",
    "    df,\n",
    "    test_start_date='2020-01-31',\n",
    "    test_end_date='2024-04-30',\n",
    "    lookback_window=180,\n",
    "    transaction_cost=0.001,\n",
    "    buys_path_template='buys_{}.csv',\n",
    "    sells_path_template='sells_{}.csv',\n",
    "    analyst_rec_path='../examples/monthly_mean_recommendations_decay.csv',\n",
    "    finbert_signals_path='../examples/monthly_signals_decay.csv',  # Your FinBERT signals\n",
    "    data_factor=data_f,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n GMV\")\n",
    "print(f\"\\nSharpe Ratio: {metrics['sharpe_ratio']:.4f}\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Total Return: {metrics['total_return']:.4f}\")\n",
    "print(f\"Average Turnover: {metrics['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MV\")\n",
    "print(f\"\\nSharpe Ratio: {metrics_2['sharpe_ratio']:.4f}\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics_2['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Total Return: {metrics_2['total_return']:.4f}\")\n",
    "print(f\"Average Turnover: {metrics_2['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MSR\")\n",
    "print(f\"\\nSharpe Ratio: {metrics_3['sharpe_ratio']:.4f}\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics_3['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Total Return: {metrics_3['total_return']:.4f}\")\n",
    "print(f\"Average Turnover: {metrics_3['avg_turnover']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df58028-b81e-4987-92a9-52cb828f89f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GMV\n",
      "Annualized Sharpe Ratio: 0.5669\n",
      "Mean Return: 0.1148\n",
      "Variance: 0.0410\n",
      "Avg Turnover: 1.7156\n",
      "\n",
      " MV\n",
      "Annualized Sharpe Ratio: 0.3391\n",
      "Mean Return: 0.0698\n",
      "Variance: 0.0424\n",
      "Avg Turnover: 1.9447\n",
      "\n",
      " MSR\n",
      "Annualized Sharpe Ratio: 0.2098\n",
      "Mean Return: 0.0434\n",
      "Variance: 0.0428\n",
      "Avg Turnover: 1.7549\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n GMV\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {metrics['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {metrics['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {metrics['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MV\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics_2['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {metrics_2['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {metrics_2['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {metrics_2['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MSR\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics_3['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {metrics_3['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {metrics_3['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {metrics_3['avg_turnover']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d5e5c8-e09e-4e7f-b06c-2500ef309e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cdcee9-7980-4c93-aaa8-c7f6a28b7ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
