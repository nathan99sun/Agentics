{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c813f69-a0eb-41a2-b3c2-4b9cabf13451",
   "metadata": {},
   "source": [
    "# INTERSECTON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76f4f73d-ffcf-4c03-a782-fc89a37050aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso, LassoCV, LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def est_ndwcov_factor(Y, factors, ic, lambda_min=True):\n",
    "    \"\"\"\n",
    "    Estimate nodewise covariance with factor models using LASSO.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Y : numpy.ndarray\n",
    "        n x p matrix of observations\n",
    "    factors : numpy.ndarray\n",
    "        n x k matrix of factors\n",
    "    ic : str\n",
    "        Information criterion: 'WIC', 'BIC', 'GIC', 'AIC', or 'cv'\n",
    "    lambda_min : bool\n",
    "        If True and ic='cv', use lambda.min; otherwise use lambda.1se\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    TAU : numpy.ndarray\n",
    "        p x p precision matrix estimate\n",
    "    \"\"\"\n",
    "    # Initialization\n",
    "    p = Y.shape[1]\n",
    "    n = Y.shape[0]\n",
    "    C = np.zeros((p, p))\n",
    "    np.fill_diagonal(C, 1)\n",
    "    tau = []\n",
    "    ns1 = np.ones((n, 1))\n",
    "    \n",
    "    # Fit factor model: Y = factors * beta + u\n",
    "    # Add intercept to factors\n",
    "    factors_with_intercept = np.column_stack([np.ones(n), factors])\n",
    "    \n",
    "    # Fit linear regression for each column of Y\n",
    "    factormodel = LinearRegression(fit_intercept=False)\n",
    "    factormodel.fit(factors_with_intercept, Y)\n",
    "    \n",
    "    # Get residuals and beta coefficients (excluding intercept)\n",
    "    u = Y - factormodel.predict(factors_with_intercept)\n",
    "    beta = factormodel.coef_[:, 1:]  # p x k matrix (excluding intercept)\n",
    "    \n",
    "    # Loop over the assets\n",
    "    for j in range(p):\n",
    "        # Create design matrix excluding column j\n",
    "        X_j = np.delete(u, j, axis=1)\n",
    "        y_j = u[:, j]\n",
    "        \n",
    "        if ic != 'cv':\n",
    "            # Fit LASSO path\n",
    "            alphas = np.logspace(-4, 1, 100)\n",
    "            df_list = []\n",
    "            sig_list = []\n",
    "            bic_list = []\n",
    "            coef_list = []\n",
    "            res_list = []\n",
    "            \n",
    "            for alpha in alphas:\n",
    "                model = Lasso(alpha=alpha, fit_intercept=False, max_iter=10000)\n",
    "                model.fit(X_j, y_j)\n",
    "                \n",
    "                y_pred = model.predict(X_j)\n",
    "                res = y_j - y_pred\n",
    "                df = np.sum(np.abs(model.coef_) > 1e-8)\n",
    "                sig = np.sum(res**2) / n\n",
    "                \n",
    "                if ic == 'WIC':\n",
    "                    bic_val = np.log(sig) + df * np.log(n) / n * np.log(np.log(p))\n",
    "                elif ic == 'BIC':\n",
    "                    bic_val = np.log(sig) + df * np.log(n) / n\n",
    "                elif ic == 'GIC':\n",
    "                    bic_val = np.log(sig) + df * np.log(p) * np.log(np.log(n)) / n\n",
    "                elif ic == 'AIC':\n",
    "                    bic_val = np.log(sig) + 2 * df\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown IC: {ic}\")\n",
    "                \n",
    "                df_list.append(df)\n",
    "                sig_list.append(sig)\n",
    "                bic_list.append(bic_val)\n",
    "                coef_list.append(model.coef_.copy())\n",
    "                res_list.append(res)\n",
    "            \n",
    "            jind = np.argmin(bic_list)\n",
    "            jpar = coef_list[jind]\n",
    "            jres = res_list[jind]\n",
    "            jtau = np.sum(y_j * jres) / n\n",
    "            \n",
    "        else:  # Cross-validation\n",
    "            lasso_cv = LassoCV(cv=5, fit_intercept=False, max_iter=10000, n_alphas=100)\n",
    "            lasso_cv.fit(X_j, y_j)\n",
    "            \n",
    "            if lambda_min:\n",
    "                jfit = lasso_cv.predict(X_j)\n",
    "                jpar = lasso_cv.coef_\n",
    "            else:\n",
    "                cv_scores = lasso_cv.mse_path_.mean(axis=1)\n",
    "                cv_std = lasso_cv.mse_path_.std(axis=1)\n",
    "                min_idx = np.argmin(cv_scores)\n",
    "                threshold = cv_scores[min_idx] + cv_std[min_idx]\n",
    "                valid_indices = np.where(cv_scores <= threshold)[0]\n",
    "                se_idx = valid_indices[0] if len(valid_indices) > 0 else min_idx\n",
    "                selected_alpha = lasso_cv.alphas_[se_idx]\n",
    "                model_1se = Lasso(alpha=selected_alpha, fit_intercept=False, max_iter=10000)\n",
    "                model_1se.fit(X_j, y_j)\n",
    "                jfit = model_1se.predict(X_j)\n",
    "                jpar = model_1se.coef_\n",
    "            \n",
    "            jres = y_j - jfit\n",
    "            jtau = np.sum(y_j * jres) / n\n",
    "        \n",
    "        C_row = np.insert(-jpar / jtau, j, 0)\n",
    "        C[j, :] = C_row\n",
    "        tau.append(jtau)\n",
    "    \n",
    "    np.fill_diagonal(C, 1 / np.array(tau))\n",
    "    omega = C.copy()\n",
    "    omegasym = (C + C.T) / 2\n",
    "    \n",
    "    covft = (1/n) * (factors.T @ factors) - (1/(n**2)) * (factors.T @ ns1 @ ns1.T @ factors)\n",
    "    covft = covft.astype(np.float64)\n",
    "    beta = beta.astype(np.float64)\n",
    "    omegasym = omegasym.astype(np.float64)\n",
    "    \n",
    "    covft_inv = np.linalg.inv(covft)\n",
    "    p1 = np.linalg.inv(covft_inv + beta.T @ omegasym @ beta)\n",
    "    TAU = omega - omega @ beta @ p1 @ beta.T @ omega\n",
    "    \n",
    "    return TAU\n",
    "\n",
    "\n",
    "def gmv_weights(Theta_hat):\n",
    "    \"\"\"Compute Global Minimum Variance portfolio weights.\"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    numerator = Theta_hat @ ones_p\n",
    "    denominator = ones_p @ Theta_hat @ ones_p\n",
    "    \n",
    "    if np.abs(denominator) < 1e-10:\n",
    "        return ones_p / p\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "\n",
    "def mv_weights(Theta_hat, mu, target_return=0.01):\n",
    "    \"\"\"Compute Mean-Variance portfolio weights with target return.\"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    A = ones_p @ Theta_hat @ ones_p\n",
    "    B = ones_p @ Theta_hat @ mu\n",
    "    C = mu @ Theta_hat @ mu\n",
    "    D = A * C - B * B\n",
    "    \n",
    "    if np.abs(D) < 1e-10:\n",
    "        if np.abs(A) > 1e-10:\n",
    "            return (Theta_hat @ ones_p) / A\n",
    "        else:\n",
    "            return ones_p / p\n",
    "    \n",
    "    lambda1 = (C - B * target_return) / D\n",
    "    lambda2 = (A * target_return - B) / D\n",
    "    w_star = lambda1 * (Theta_hat @ ones_p) + lambda2 * (Theta_hat @ mu)\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "\n",
    "def msr_weights(Theta_hat, mu):\n",
    "    \"\"\"Compute Maximum Sharpe Ratio portfolio weights.\"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    w_unnorm = Theta_hat @ mu\n",
    "    weight_sum = np.sum(w_unnorm)\n",
    "    \n",
    "    if np.abs(weight_sum) < 1e-10:\n",
    "        return ones_p / p\n",
    "    \n",
    "    return w_unnorm / weight_sum\n",
    "\n",
    "\n",
    "def load_yearly_signals(year, buys_path_template='buys_{}.csv', sells_path_template='sells_{}.csv'):\n",
    "    \"\"\"Load buy and sell signals for a specific year.\"\"\"\n",
    "    try:\n",
    "        buys = pd.read_csv(buys_path_template.format(year), index_col=1)\n",
    "        sells = pd.read_csv(sells_path_template.format(year), index_col=1)\n",
    "        buys.index.name = 'permno'\n",
    "        sells.index.name = 'permno'\n",
    "        buys_index = buys.index.astype(int)\n",
    "        sells_index = sells.index.astype(int)\n",
    "        return set(buys_index.union(sells_index))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  ⚠ Warning: Could not load signals for year {year}: {e}\")\n",
    "        return set()\n",
    "\n",
    "\n",
    "def load_ff_factors(factors_path='factors_ff_monthly_raw.csv'):\n",
    "    \"\"\"Load Fama-French factors from CSV file.\"\"\"\n",
    "    factors_df = pd.read_csv(factors_path)\n",
    "    factors_df['date'] = pd.to_datetime(factors_df.iloc[:, 0].astype(str), format='%Y%m')\n",
    "    factors_df['date'] = factors_df['date'] + pd.offsets.MonthEnd(0)\n",
    "    factors_df = factors_df.set_index('date')[['Mkt-RF', 'SMB', 'HML']]\n",
    "    factors_df = factors_df / 100\n",
    "    return factors_df\n",
    "\n",
    "\n",
    "def load_finbert_signals(signals_path):\n",
    "    \"\"\"Load FinBERT monthly signals from CSV file.\"\"\"\n",
    "    try:\n",
    "        signals_df = pd.read_csv(signals_path)\n",
    "        signals_df['date'] = pd.to_datetime(signals_df['year_month']) + pd.offsets.MonthEnd(0)\n",
    "        return signals_df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  ⚠ Warning: Could not load FinBERT signals: {e}\")\n",
    "        return pd.DataFrame(columns=['symbol', 'company', 'year_month', 'signal', 'date'])\n",
    "\n",
    "\n",
    "def get_finbert_permnos_for_date(signals_df, ticker_to_permno, date):\n",
    "    \"\"\"Get set of permnos with 'buy' or 'sell' signals for a specific date.\"\"\"\n",
    "    date_signals = signals_df[signals_df['date'] == date]\n",
    "    buy_signals = date_signals[date_signals['signal'] == 'buy']\n",
    "    sell_signals = date_signals[date_signals['signal'] == 'sell']\n",
    "    \n",
    "    permnos = set()\n",
    "    for ticker in buy_signals['symbol'].values:\n",
    "        if ticker in ticker_to_permno:\n",
    "            permnos.add(ticker_to_permno[ticker])\n",
    "    for ticker in sell_signals['symbol'].values:\n",
    "        if ticker in ticker_to_permno:\n",
    "            permnos.add(ticker_to_permno[ticker])\n",
    "    \n",
    "    return permnos\n",
    "\n",
    "\n",
    "def create_ticker_to_permno_mapping(df):\n",
    "    \"\"\"Create a mapping from ticker to permno.\"\"\"\n",
    "    if 'ticker' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have 'ticker' column for mapping\")\n",
    "    valid_df = df[df['ticker'].notna()].copy()\n",
    "    ticker_to_permno = valid_df.groupby('ticker')['permno'].last().to_dict()\n",
    "    return ticker_to_permno\n",
    "\n",
    "\n",
    "def calculate_exit_transaction_cost(prev_weights_dict, prev_oos_returns_dict, \n",
    "                                    prev_gross_return, transaction_cost, verbose=False):\n",
    "    \"\"\"Calculate transaction cost when exiting the market.\"\"\"\n",
    "    if len(prev_weights_dict) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    \n",
    "    adjusted_prev = {}\n",
    "    for asset, prev_w in prev_weights_dict.items():\n",
    "        if asset in prev_oos_returns_dict:\n",
    "            prev_r = prev_oos_returns_dict[asset]\n",
    "            if abs(1 + prev_gross_return) > 1e-6:\n",
    "                adjusted_prev[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return)\n",
    "            else:\n",
    "                adjusted_prev[asset] = 0.0\n",
    "        else:\n",
    "            if abs(1 + prev_gross_return) > 1e-6:\n",
    "                adjusted_prev[asset] = prev_w / (1 + prev_gross_return)\n",
    "            else:\n",
    "                adjusted_prev[asset] = 0.0\n",
    "    \n",
    "    turnover = sum(abs(w) for w in adjusted_prev.values())\n",
    "    tc = transaction_cost * 1.0 * turnover\n",
    "    net_return = -tc\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  Liquidating positions | Turnover: {turnover:>6.4f} | TC: {tc:>8.6f}\")\n",
    "    \n",
    "    return turnover, tc, net_return\n",
    "\n",
    "\n",
    "def backtest_nodewise_all_portfolios(df, \n",
    "                                     factors_path='factors_ff_monthly_raw.csv',\n",
    "                                     ic='GIC',\n",
    "                                     target_return=0.01,\n",
    "                                     test_start_date='2020-01-31', \n",
    "                                     test_end_date='2024-11-30',\n",
    "                                     lookback_window=180,\n",
    "                                     transaction_cost=0.001,\n",
    "                                     buys_path_template='buys_{}.csv',\n",
    "                                     sells_path_template='sells_{}.csv',\n",
    "                                     finbert_signals_path=None,\n",
    "                                     verbose=True):\n",
    "    \"\"\"\n",
    "    Backtest all three portfolio strategies (GMV, MV, MSR) simultaneously.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with columns: permno, datadate, ticker, ret_fwd_1\n",
    "    factors_path : str\n",
    "        Path to Fama-French factors CSV\n",
    "    ic : str\n",
    "        Information criterion: 'WIC', 'BIC', 'GIC', 'AIC', or 'cv'\n",
    "    target_return : float\n",
    "        Target return for MV portfolio (default: 0.01 = 1% monthly)\n",
    "    test_start_date : str\n",
    "        First date for out-of-sample returns\n",
    "    test_end_date : str\n",
    "        Last date for out-of-sample returns\n",
    "    lookback_window : int\n",
    "        Number of months in rolling training window\n",
    "    transaction_cost : float\n",
    "        Proportional transaction cost\n",
    "    buys_path_template : str\n",
    "        Template for buys file path\n",
    "    sells_path_template : str\n",
    "        Template for sells file path\n",
    "    finbert_signals_path : str or None\n",
    "        Path to FinBERT signals CSV file\n",
    "    verbose : bool\n",
    "        If True, prints detailed log\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results_dict : dict\n",
    "        Dictionary with keys 'GMV', 'MV', 'MSR', each containing (results_df, metrics)\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    if 'datadate' not in df.columns or 'permno' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have 'datadate' and 'permno' columns\")\n",
    "    df['datadate'] = pd.to_datetime(df['datadate'])\n",
    "\n",
    "    factors_df = load_ff_factors(factors_path)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Creating ticker to permno mapping...\")\n",
    "    ticker_to_permno = create_ticker_to_permno_mapping(df)\n",
    "    if verbose:\n",
    "        print(f\"Mapped {len(ticker_to_permno)} unique tickers to permnos\")\n",
    "    \n",
    "    finbert_df = None\n",
    "    if finbert_signals_path is not None:\n",
    "        finbert_df = load_finbert_signals(finbert_signals_path)\n",
    "        if verbose and len(finbert_df) > 0:\n",
    "            print(f\"Loaded FinBERT signals: {len(finbert_df)} monthly records\")\n",
    "            print(f\"FinBERT signal distribution:\")\n",
    "            print(finbert_df['signal'].value_counts())\n",
    "    \n",
    "    all_dates = sorted(df['datadate'].unique())\n",
    "    test_start_dt = pd.to_datetime(test_start_date)\n",
    "    test_end_dt = pd.to_datetime(test_end_date)\n",
    "    \n",
    "    try:\n",
    "        test_start_idx = all_dates.index(test_start_dt)\n",
    "        test_end_idx = all_dates.index(test_end_dt)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Date not found in DataFrame: {e}\")\n",
    "    \n",
    "    if test_start_idx < lookback_window:\n",
    "        raise ValueError(f\"Not enough data for lookback.\")\n",
    "    \n",
    "    # Storage for all three portfolios\n",
    "    portfolios = {\n",
    "        'GMV': {\n",
    "            'returns': [], 'dates': [], 'weights': [], 'turnover': [], 'gross_returns': [],\n",
    "            'prev_weights': {}, 'prev_oos_returns': {}, 'prev_gross_return': 0.0\n",
    "        },\n",
    "        'MV': {\n",
    "            'returns': [], 'dates': [], 'weights': [], 'turnover': [], 'gross_returns': [],\n",
    "            'prev_weights': {}, 'prev_oos_returns': {}, 'prev_gross_return': 0.0\n",
    "        },\n",
    "        'MSR': {\n",
    "            'returns': [], 'dates': [], 'weights': [], 'turnover': [], 'gross_returns': [],\n",
    "            'prev_weights': {}, 'prev_oos_returns': {}, 'prev_gross_return': 0.0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    yearly_signals_cache = {}\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\"*60)\n",
    "        print(\"STARTING BACKTEST: ALL PORTFOLIOS (GMV, MV, MSR)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "    for t in range(test_start_idx, test_end_idx + 1):\n",
    "        current_date = all_dates[t]\n",
    "        current_year = current_date.year\n",
    "        \n",
    "        if current_year not in yearly_signals_cache:\n",
    "            yearly_signals_cache[current_year] = load_yearly_signals(\n",
    "                current_year, buys_path_template, sells_path_template\n",
    "            )\n",
    "        \n",
    "        yearly_permnos = yearly_signals_cache[current_year]\n",
    "        \n",
    "        finbert_permnos = set()\n",
    "        if finbert_df is not None and len(finbert_df) > 0:\n",
    "            finbert_permnos = get_finbert_permnos_for_date(finbert_df, ticker_to_permno, current_date)\n",
    "        \n",
    "        allowed_permnos = yearly_permnos.intersection(finbert_permnos)\n",
    "        if len(allowed_permnos) <= 1:\n",
    "            allowed_permnos = yearly_permnos.union(finbert_permnos)\n",
    "        \n",
    "        oos_data = df[(df['datadate'] == current_date) & (df['permno'].isin(allowed_permnos))]\n",
    "        oos_returns_series = oos_data.set_index('permno')['ret_fwd_1']\n",
    "        oos_returns_series = oos_returns_series.dropna()\n",
    "        oos_returns_dict = oos_returns_series.to_dict()\n",
    "        \n",
    "        if len(allowed_permnos) == 0:\n",
    "            if verbose:\n",
    "                print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                      f\"Date: {current_date.strftime('%Y-%m-%d')}\")\n",
    "                print(f\"  ⚠ No signals, recording zero return for all portfolios\")\n",
    "            \n",
    "            # Handle exit for all three portfolios\n",
    "            for ptype in ['GMV', 'MV', 'MSR']:\n",
    "                p = portfolios[ptype]\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    p['prev_weights'], p['prev_oos_returns'], p['prev_gross_return'], \n",
    "                    transaction_cost, verbose=True\n",
    "                )\n",
    "                \n",
    "                p['returns'].append(net_return)\n",
    "                p['dates'].append(current_date)\n",
    "                p['weights'].append({})\n",
    "                p['turnover'].append(turnover)\n",
    "                p['gross_returns'].append(0.0)\n",
    "                p['prev_weights'] = {}\n",
    "                p['prev_oos_returns'] = {}\n",
    "                p['prev_gross_return'] = 0.0\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        window_start_date = all_dates[t - lookback_window]\n",
    "        window_end_date = all_dates[t - 1]\n",
    "        \n",
    "        train_data = df[(df['datadate'] >= window_start_date) & \n",
    "                        (df['datadate'] <= window_end_date) &\n",
    "                        (df['permno'].isin(allowed_permnos))]\n",
    "        \n",
    "        returns_pivot = train_data.pivot(index='datadate', columns='permno', values='ret_fwd_1')\n",
    "        window_dates = all_dates[t - lookback_window : t]\n",
    "        returns_pivot = returns_pivot.reindex(index=window_dates)\n",
    "        \n",
    "        factor_dates = [(d + pd.DateOffset(months=1) + pd.offsets.MonthEnd(0)) for d in window_dates]\n",
    "        \n",
    "        try:\n",
    "            factors_window = factors_df.loc[factor_dates]\n",
    "        except KeyError as e:\n",
    "            raise ValueError(f\"Factor dates not found: {e}\")\n",
    "        \n",
    "        if factors_window.isna().any().any():\n",
    "            if verbose:\n",
    "                print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                      f\"Date: {current_date.strftime('%Y-%m-%d')}\")\n",
    "                print(f\"  ⚠ Missing factor data, skipping\")\n",
    "            continue\n",
    "        \n",
    "        nan_assets = returns_pivot.columns[returns_pivot.isna().any()]\n",
    "        filtered_pivot = returns_pivot.drop(columns=nan_assets)\n",
    "        \n",
    "        current_assets = filtered_pivot.columns.tolist()\n",
    "        Y = filtered_pivot.values\n",
    "        factors = factors_window.values\n",
    "        n_train, p_current = Y.shape\n",
    "    \n",
    "        if verbose:\n",
    "            print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                  f\"Date: {current_date.strftime('%Y-%m-%d')} | Year: {current_year}\")\n",
    "            print(f\"  Window: {window_start_date.strftime('%Y-%m-%d')} to \"\n",
    "                  f\"{window_end_date.strftime('%Y-%m-%d')}\")\n",
    "            print(f\"  Yearly: {len(yearly_permnos)} | FinBERT: {len(finbert_permnos)} | \"\n",
    "                  f\"Union/Intersection: {len(allowed_permnos)} | Assets: {p_current}\")\n",
    "    \n",
    "        if n_train < lookback_window or p_current < 2:\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ Insufficient data (n={n_train}, p={p_current})\")\n",
    "            \n",
    "            # Handle exit for all three portfolios\n",
    "            for ptype in ['GMV', 'MV', 'MSR']:\n",
    "                p = portfolios[ptype]\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    p['prev_weights'], p['prev_oos_returns'], p['prev_gross_return'],\n",
    "                    transaction_cost, verbose=True\n",
    "                )\n",
    "                \n",
    "                p['returns'].append(net_return)\n",
    "                p['dates'].append(current_date)\n",
    "                p['weights'].append({})\n",
    "                p['turnover'].append(turnover)\n",
    "                p['gross_returns'].append(0.0)\n",
    "                p['prev_weights'] = {}\n",
    "                p['prev_oos_returns'] = {}\n",
    "                p['prev_gross_return'] = 0.0\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            if verbose:\n",
    "                print(f\"  Running Nodewise Regression...\")\n",
    "            Theta_hat = est_ndwcov_factor(Y, factors, ic=ic, lambda_min=True)\n",
    "            \n",
    "            mu = Y.mean(axis=0)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  Computing weights for all portfolios...\")\n",
    "            \n",
    "            # Compute weights for all three strategies\n",
    "            weights_dict = {\n",
    "                'GMV': gmv_weights(Theta_hat),\n",
    "                'MV': mv_weights(Theta_hat, mu, target_return=target_return),\n",
    "                'MSR': msr_weights(Theta_hat, mu)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"  ✗ Error: {e}\")\n",
    "            \n",
    "            # Handle error for all three portfolios\n",
    "            for ptype in ['GMV', 'MV', 'MSR']:\n",
    "                p = portfolios[ptype]\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    p['prev_weights'], p['prev_oos_returns'], p['prev_gross_return'],\n",
    "                    transaction_cost, verbose=True\n",
    "                )\n",
    "                \n",
    "                p['returns'].append(net_return)\n",
    "                p['dates'].append(current_date)\n",
    "                p['weights'].append({})\n",
    "                p['turnover'].append(turnover)\n",
    "                p['gross_returns'].append(0.0)\n",
    "                p['prev_weights'] = {}\n",
    "                p['prev_oos_returns'] = {}\n",
    "                p['prev_gross_return'] = 0.0\n",
    "            \n",
    "            continue\n",
    "\n",
    "        # Process each portfolio type\n",
    "        for ptype in ['GMV', 'MV', 'MSR']:\n",
    "            p = portfolios[ptype]\n",
    "            w_star = weights_dict[ptype]\n",
    "            new_weights_dict = {asset: w_star[i] for i, asset in enumerate(current_assets)}\n",
    "            \n",
    "            # Normalize weights\n",
    "            weight_sum = sum(new_weights_dict.values())\n",
    "            if weight_sum <= 1e-10:\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    p['prev_weights'], p['prev_oos_returns'], p['prev_gross_return'],\n",
    "                    transaction_cost, verbose=True\n",
    "                )\n",
    "                \n",
    "                p['returns'].append(net_return)\n",
    "                p['dates'].append(current_date)\n",
    "                p['weights'].append({})\n",
    "                p['turnover'].append(turnover)\n",
    "                p['gross_returns'].append(0.0)\n",
    "                p['prev_weights'] = {}\n",
    "                p['prev_oos_returns'] = {}\n",
    "                p['prev_gross_return'] = 0.0\n",
    "                continue\n",
    "            \n",
    "            new_weights_dict = {k: v/weight_sum for k, v in new_weights_dict.items()}\n",
    "            \n",
    "            # Find common assets with returns\n",
    "            common_assets = set(new_weights_dict.keys()) & set(oos_returns_dict.keys())\n",
    "            \n",
    "            if len(common_assets) == 0:\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    p['prev_weights'], p['prev_oos_returns'], p['prev_gross_return'],\n",
    "                    transaction_cost, verbose=True\n",
    "                )\n",
    "                \n",
    "                p['returns'].append(net_return)\n",
    "                p['dates'].append(current_date)\n",
    "                p['weights'].append({})\n",
    "                p['turnover'].append(turnover)\n",
    "                p['gross_returns'].append(0.0)\n",
    "                p['prev_weights'] = {}\n",
    "                p['prev_oos_returns'] = {}\n",
    "                p['prev_gross_return'] = 0.0\n",
    "                continue\n",
    "            \n",
    "            # Filter to common assets and renormalize\n",
    "            common_weights = {a: new_weights_dict[a] for a in common_assets}\n",
    "            common_weight_sum = sum(common_weights.values())\n",
    "            if common_weight_sum <= 1e-10:\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    p['prev_weights'], p['prev_oos_returns'], p['prev_gross_return'],\n",
    "                    transaction_cost, verbose=True\n",
    "                )\n",
    "                \n",
    "                p['returns'].append(net_return)\n",
    "                p['dates'].append(current_date)\n",
    "                p['weights'].append({})\n",
    "                p['turnover'].append(turnover)\n",
    "                p['gross_returns'].append(0.0)\n",
    "                p['prev_weights'] = {}\n",
    "                p['prev_oos_returns'] = {}\n",
    "                p['prev_gross_return'] = 0.0\n",
    "                continue\n",
    "            \n",
    "            common_weights = {k: v/common_weight_sum for k, v in common_weights.items()}\n",
    "            \n",
    "            # Compute gross return\n",
    "            gross_return = sum(common_weights[a] * oos_returns_dict[a] for a in common_assets)\n",
    "            \n",
    "            if np.isnan(gross_return) or np.isinf(gross_return):\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    p['prev_weights'], p['prev_oos_returns'], p['prev_gross_return'],\n",
    "                    transaction_cost, verbose=True\n",
    "                )\n",
    "                \n",
    "                p['returns'].append(net_return)\n",
    "                p['dates'].append(current_date)\n",
    "                p['weights'].append({})\n",
    "                p['turnover'].append(turnover)\n",
    "                p['gross_returns'].append(0.0)\n",
    "                p['prev_weights'] = {}\n",
    "                p['prev_oos_returns'] = {}\n",
    "                p['prev_gross_return'] = 0.0\n",
    "                continue\n",
    "            \n",
    "            # Calculate transaction costs\n",
    "            if len(p['prev_weights']) > 0:\n",
    "                adjusted_prev = {}\n",
    "                for asset, prev_w in p['prev_weights'].items():\n",
    "                    if asset in p['prev_oos_returns']:\n",
    "                        prev_r = p['prev_oos_returns'][asset]\n",
    "                        if abs(1 + p['prev_gross_return']) > 1e-6:\n",
    "                            adjusted_prev[asset] = prev_w * (1 + prev_r) / (1 + p['prev_gross_return'])\n",
    "                        else:\n",
    "                            adjusted_prev[asset] = 0.0\n",
    "                    else:\n",
    "                        if abs(1 + p['prev_gross_return']) > 1e-6:\n",
    "                            adjusted_prev[asset] = prev_w / (1 + p['prev_gross_return'])\n",
    "                        else:\n",
    "                            adjusted_prev[asset] = 0.0\n",
    "                \n",
    "                all_assets = set(adjusted_prev.keys()) | set(common_weights.keys())\n",
    "                turnover = 0.0\n",
    "                for asset in all_assets:\n",
    "                    old_w = adjusted_prev.get(asset, 0.0)\n",
    "                    new_w = common_weights.get(asset, 0.0)\n",
    "                    turnover += abs(new_w - old_w)\n",
    "                \n",
    "                tc = transaction_cost * (1 + gross_return) * turnover\n",
    "            else:\n",
    "                turnover = sum(abs(w) for w in common_weights.values())\n",
    "                tc = transaction_cost * (1 + gross_return) * turnover\n",
    "            \n",
    "            net_return = gross_return - tc\n",
    "            \n",
    "            # Store results\n",
    "            p['returns'].append(net_return)\n",
    "            p['dates'].append(current_date)\n",
    "            p['weights'].append(common_weights.copy())\n",
    "            p['turnover'].append(turnover)\n",
    "            p['gross_returns'].append(gross_return)\n",
    "            p['prev_weights'] = common_weights.copy()\n",
    "            p['prev_oos_returns'] = {a: oos_returns_dict[a] for a in common_assets}\n",
    "            p['prev_gross_return'] = gross_return\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  GMV Net: {portfolios['GMV']['returns'][-1]:>8.5f} | \"\n",
    "                  f\"MV Net: {portfolios['MV']['returns'][-1]:>8.5f} | \"\n",
    "                  f\"MSR Net: {portfolios['MSR']['returns'][-1]:>8.5f}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BACKTEST COMPLETE - ALL PORTFOLIOS\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    # Compile results for all portfolios\n",
    "    results_dict = {}\n",
    "    \n",
    "    for ptype in ['GMV', 'MV', 'MSR']:\n",
    "        p = portfolios[ptype]\n",
    "        \n",
    "        results_df = pd.DataFrame({\n",
    "            'date': p['dates'],\n",
    "            'portfolio_return': p['returns'],\n",
    "            'portfolio_gross_return': p['gross_returns'],\n",
    "            'portfolio_weights': p['weights'],\n",
    "            'portfolio_turnover': p['turnover']\n",
    "        })\n",
    "        results_df['cumulative_return'] = (1 + results_df['portfolio_return']).cumprod() - 1\n",
    "        \n",
    "        # Compute metrics\n",
    "        if len(p['returns']) > 0:\n",
    "            mean_return = np.mean(p['returns'])\n",
    "            variance = np.var(p['returns'], ddof=1)\n",
    "            sharpe_ratio = mean_return / np.sqrt(variance) if variance > 0 else 0\n",
    "            \n",
    "            annual_return = mean_return * 12\n",
    "            annual_volatility = np.sqrt(variance * 12)\n",
    "            annual_sharpe = annual_return / annual_volatility if annual_volatility > 0 else 0\n",
    "            \n",
    "            metrics = {\n",
    "                'portfolio_type': ptype,\n",
    "                'mean_return': mean_return,\n",
    "                'variance': variance,\n",
    "                'sharpe_ratio': sharpe_ratio,\n",
    "                'annual_return': annual_return,\n",
    "                'annual_volatility': annual_volatility,\n",
    "                'annual_sharpe_ratio': annual_sharpe,\n",
    "                'total_return': results_df['cumulative_return'].iloc[-1],\n",
    "                'avg_turnover': np.mean(p['turnover']),\n",
    "                'n_periods': len(p['returns']),\n",
    "                'n_zero_periods': sum(1 for r in p['returns'] if r == 0)\n",
    "            }\n",
    "        else:\n",
    "            metrics = {\n",
    "                'portfolio_type': ptype,\n",
    "                'mean_return': 0,\n",
    "                'variance': 0,\n",
    "                'sharpe_ratio': 0,\n",
    "                'annual_return': 0,\n",
    "                'annual_volatility': 0,\n",
    "                'annual_sharpe_ratio': 0,\n",
    "                'total_return': 0,\n",
    "                'avg_turnover': 0,\n",
    "                'n_periods': 0,\n",
    "                'n_zero_periods': 0\n",
    "            }\n",
    "        \n",
    "        results_dict[ptype] = (results_df, metrics)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{ptype} Portfolio:\")\n",
    "            print(f\"  Annual Return: {metrics['annual_return']*100:.2f}%\")\n",
    "            print(f\"  Annual Volatility: {metrics['annual_volatility']*100:.2f}%\")\n",
    "            print(f\"  Annual Sharpe Ratio: {metrics['annual_sharpe_ratio']:.3f}\")\n",
    "            print(f\"  Total Return: {metrics['total_return']*100:.2f}%\")\n",
    "            print(f\"  Avg Turnover: {metrics['avg_turnover']:.4f}\")\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "010cc24c-b8b4-4168-8902-5db6fce7a582",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../green cleaned.csv', dtype={'ncusip': 'string'})\n",
    "df['ret_fwd_1'] = df.groupby('permno')['ret_excess'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d036f7-3ed6-4eaf-b1ac-da6c3a42d104",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ticker to permno mapping...\n",
      "Mapped 1664 unique tickers to permnos\n",
      "Loaded FinBERT signals: 24780 monthly records\n",
      "FinBERT signal distribution:\n",
      "signal\n",
      "hold    23840\n",
      "sell      529\n",
      "buy       411\n",
      "Name: count, dtype: int64\n",
      "============================================================\n",
      "STARTING BACKTEST: ALL PORTFOLIOS (GMV, MV, MSR)\n",
      "============================================================\n",
      "\n",
      "[1/52] Date: 2020-01-31 | Year: 2020\n",
      "  Window: 2005-01-31 to 2019-12-31\n",
      "  Yearly: 300 | FinBERT: 8 | Union/Intersection: 6 | Assets: 5\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.11976 | MV Net: -0.12099 | MSR Net: -0.10926\n",
      "\n",
      "[2/52] Date: 2020-02-29 | Year: 2020\n",
      "  Window: 2005-02-28 to 2020-01-31\n",
      "  Yearly: 300 | FinBERT: 10 | Union/Intersection: 5 | Assets: 4\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.05769 | MV Net: -0.09230 | MSR Net: -0.03927\n",
      "\n",
      "[3/52] Date: 2020-03-31 | Year: 2020\n",
      "  Window: 2005-03-31 to 2020-02-29\n",
      "  Yearly: 300 | FinBERT: 14 | Union/Intersection: 10 | Assets: 4\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.16383 | MV Net:  0.21039 | MSR Net:  0.18022\n",
      "\n",
      "[4/52] Date: 2020-04-30 | Year: 2020\n",
      "  Window: 2005-04-30 to 2020-03-31\n",
      "  Yearly: 300 | FinBERT: 10 | Union/Intersection: 6 | Assets: 2\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.01558 | MV Net:  0.06205 | MSR Net:  0.02697\n",
      "\n",
      "[5/52] Date: 2020-05-31 | Year: 2020\n",
      "  Window: 2005-05-31 to 2020-04-30\n",
      "  Yearly: 300 | FinBERT: 8 | Union/Intersection: 4 | Assets: 2\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.00186 | MV Net: -0.05270 | MSR Net: -0.00015\n",
      "\n",
      "[6/52] Date: 2020-06-30 | Year: 2020\n",
      "  Window: 2005-06-30 to 2020-05-31\n",
      "  Yearly: 300 | FinBERT: 7 | Union/Intersection: 4 | Assets: 3\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.03357 | MV Net:  0.04917 | MSR Net:  0.02522\n",
      "\n",
      "[7/52] Date: 2020-07-31 | Year: 2020\n",
      "  Window: 2005-07-31 to 2020-06-30\n",
      "  Yearly: 300 | FinBERT: 4 | Union/Intersection: 2 | Assets: 1\n",
      "  ⚠ Insufficient data (n=180, p=1)\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "\n",
      "[8/52] Date: 2020-08-31 | Year: 2020\n",
      "  Window: 2005-08-31 to 2020-07-31\n",
      "  Yearly: 300 | FinBERT: 12 | Union/Intersection: 9 | Assets: 5\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.03868 | MV Net:  0.00694 | MSR Net:  0.01902\n",
      "\n",
      "[9/52] Date: 2020-09-30 | Year: 2020\n",
      "  Window: 2005-09-30 to 2020-08-31\n",
      "  Yearly: 300 | FinBERT: 17 | Union/Intersection: 10 | Assets: 5\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.03245 | MV Net: -0.02243 | MSR Net: -0.06861\n",
      "\n",
      "[10/52] Date: 2020-10-31 | Year: 2020\n",
      "  Window: 2005-10-31 to 2020-09-30\n",
      "  Yearly: 300 | FinBERT: 7 | Union/Intersection: 2 | Assets: 1\n",
      "  ⚠ Insufficient data (n=180, p=1)\n",
      "  Liquidating positions | Turnover: 1.0076 | TC: 0.001008\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "  Liquidating positions | Turnover: 1.3637 | TC: 0.001364\n",
      "\n",
      "[11/52] Date: 2020-11-30 | Year: 2020\n",
      "  Window: 2005-11-30 to 2020-10-31\n",
      "  Yearly: 300 | FinBERT: 7 | Union/Intersection: 6 | Assets: 5\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.02793 | MV Net:  0.03431 | MSR Net:  0.01950\n",
      "\n",
      "[12/52] Date: 2020-12-31 | Year: 2020\n",
      "  Window: 2005-12-31 to 2020-11-30\n",
      "  Yearly: 300 | FinBERT: 7 | Union/Intersection: 5 | Assets: 1\n",
      "  ⚠ Insufficient data (n=180, p=1)\n",
      "  Liquidating positions | Turnover: 1.2401 | TC: 0.001240\n",
      "  Liquidating positions | Turnover: 1.2675 | TC: 0.001267\n",
      "  Liquidating positions | Turnover: 1.2104 | TC: 0.001210\n",
      "\n",
      "[13/52] Date: 2021-01-31 | Year: 2021\n",
      "  Window: 2006-01-31 to 2020-12-31\n",
      "  Yearly: 300 | FinBERT: 8 | Union/Intersection: 4 | Assets: 3\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.04667 | MV Net:  0.05700 | MSR Net:  0.00884\n",
      "\n",
      "[14/52] Date: 2021-02-28 | Year: 2021\n",
      "  Window: 2006-02-28 to 2021-01-31\n",
      "  Yearly: 300 | FinBERT: 15 | Union/Intersection: 4 | Assets: 2\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.06572 | MV Net:  0.06520 | MSR Net:  0.04467\n",
      "\n",
      "[15/52] Date: 2021-03-31 | Year: 2021\n",
      "  Window: 2006-03-31 to 2021-02-28\n",
      "  Yearly: 300 | FinBERT: 11 | Union/Intersection: 7 | Assets: 5\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.04790 | MV Net:  0.04968 | MSR Net:  0.04822\n",
      "\n",
      "[16/52] Date: 2021-04-30 | Year: 2021\n",
      "  Window: 2006-04-30 to 2021-03-31\n",
      "  Yearly: 300 | FinBERT: 15 | Union/Intersection: 7 | Assets: 4\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.02170 | MV Net:  0.01761 | MSR Net:  0.00942\n",
      "\n",
      "[17/52] Date: 2021-05-31 | Year: 2021\n",
      "  Window: 2006-05-31 to 2021-04-30\n",
      "  Yearly: 300 | FinBERT: 9 | Union/Intersection: 5 | Assets: 0\n",
      "  ⚠ Insufficient data (n=180, p=0)\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "\n",
      "[18/52] Date: 2021-06-30 | Year: 2021\n",
      "  Window: 2006-06-30 to 2021-05-31\n",
      "  Yearly: 300 | FinBERT: 13 | Union/Intersection: 9 | Assets: 4\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.04128 | MV Net:  0.03539 | MSR Net:  0.06497\n",
      "\n",
      "[19/52] Date: 2021-07-31 | Year: 2021\n",
      "  Window: 2006-07-31 to 2021-06-30\n",
      "  Yearly: 300 | FinBERT: 11 | Union/Intersection: 5 | Assets: 3\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.00884 | MV Net:  0.01065 | MSR Net:  0.01804\n",
      "\n",
      "[20/52] Date: 2021-08-31 | Year: 2021\n",
      "  Window: 2006-08-31 to 2021-07-31\n",
      "  Yearly: 300 | FinBERT: 11 | Union/Intersection: 7 | Assets: 2\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.04290 | MV Net:  0.00581 | MSR Net: -0.06177\n",
      "\n",
      "[21/52] Date: 2021-09-30 | Year: 2021\n",
      "  Window: 2006-09-30 to 2021-08-31\n",
      "  Yearly: 300 | FinBERT: 12 | Union/Intersection: 9 | Assets: 6\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.02659 | MV Net:  0.02118 | MSR Net:  0.02030\n",
      "\n",
      "[22/52] Date: 2021-10-31 | Year: 2021\n",
      "  Window: 2006-10-31 to 2021-09-30\n",
      "  Yearly: 300 | FinBERT: 12 | Union/Intersection: 6 | Assets: 4\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.00339 | MV Net:  0.00041 | MSR Net:  0.00409\n",
      "\n",
      "[23/52] Date: 2021-11-30 | Year: 2021\n",
      "  Window: 2006-11-30 to 2021-10-31\n",
      "  Yearly: 300 | FinBERT: 9 | Union/Intersection: 6 | Assets: 2\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.11599 | MV Net:  0.12168 | MSR Net:  0.11573\n",
      "\n",
      "[24/52] Date: 2021-12-31 | Year: 2021\n",
      "  Window: 2006-12-31 to 2021-11-30\n",
      "  Yearly: 300 | FinBERT: 8 | Union/Intersection: 3 | Assets: 1\n",
      "  ⚠ Insufficient data (n=180, p=1)\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "  Liquidating positions | Turnover: 3.2263 | TC: 0.003226\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "\n",
      "[25/52] Date: 2022-01-31 | Year: 2022\n",
      "  Window: 2007-01-31 to 2021-12-31\n",
      "  Yearly: 300 | FinBERT: 29 | Union/Intersection: 18 | Assets: 9\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.00053 | MV Net:  0.02152 | MSR Net: -0.01150\n",
      "\n",
      "[26/52] Date: 2022-02-28 | Year: 2022\n",
      "  Window: 2007-02-28 to 2022-01-31\n",
      "  Yearly: 300 | FinBERT: 15 | Union/Intersection: 8 | Assets: 3\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.03869 | MV Net: -0.01602 | MSR Net: -0.04419\n",
      "\n",
      "[27/52] Date: 2022-03-31 | Year: 2022\n",
      "  Window: 2007-03-31 to 2022-02-28\n",
      "  Yearly: 300 | FinBERT: 16 | Union/Intersection: 14 | Assets: 8\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.04086 | MV Net: -0.04267 | MSR Net: -0.03880\n",
      "\n",
      "[28/52] Date: 2022-04-30 | Year: 2022\n",
      "  Window: 2007-04-30 to 2022-03-31\n",
      "  Yearly: 300 | FinBERT: 19 | Union/Intersection: 10 | Assets: 7\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.06023 | MV Net:  0.06608 | MSR Net:  0.07329\n",
      "\n",
      "[29/52] Date: 2022-05-31 | Year: 2022\n",
      "  Window: 2007-05-31 to 2022-04-30\n",
      "  Yearly: 300 | FinBERT: 10 | Union/Intersection: 6 | Assets: 2\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.11267 | MV Net:  0.01312 | MSR Net: -0.11100\n",
      "\n",
      "[30/52] Date: 2022-06-30 | Year: 2022\n",
      "  Window: 2007-06-30 to 2022-05-31\n",
      "  Yearly: 300 | FinBERT: 11 | Union/Intersection: 4 | Assets: 1\n",
      "  ⚠ Insufficient data (n=180, p=1)\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "  Liquidating positions | Turnover: 4.3063 | TC: 0.004306\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "\n",
      "[31/52] Date: 2022-07-31 | Year: 2022\n",
      "  Window: 2007-07-31 to 2022-06-30\n",
      "  Yearly: 300 | FinBERT: 24 | Union/Intersection: 11 | Assets: 7\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.08009 | MV Net: -0.07777 | MSR Net: -0.06848\n",
      "\n",
      "[32/52] Date: 2022-08-31 | Year: 2022\n",
      "  Window: 2007-08-31 to 2022-07-31\n",
      "  Yearly: 300 | FinBERT: 12 | Union/Intersection: 7 | Assets: 3\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.10046 | MV Net: -0.10224 | MSR Net: -0.10253\n",
      "\n",
      "[33/52] Date: 2022-09-30 | Year: 2022\n",
      "  Window: 2007-09-30 to 2022-08-31\n",
      "  Yearly: 300 | FinBERT: 19 | Union/Intersection: 11 | Assets: 5\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.09477 | MV Net:  0.09681 | MSR Net:  0.04258\n",
      "\n",
      "[34/52] Date: 2022-10-31 | Year: 2022\n",
      "  Window: 2007-10-31 to 2022-09-30\n",
      "  Yearly: 300 | FinBERT: 25 | Union/Intersection: 13 | Assets: 9\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.04294 | MV Net:  0.04927 | MSR Net:  0.05688\n",
      "\n",
      "[35/52] Date: 2022-11-30 | Year: 2022\n",
      "  Window: 2007-11-30 to 2022-10-31\n",
      "  Yearly: 300 | FinBERT: 25 | Union/Intersection: 12 | Assets: 8\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.03750 | MV Net: -0.03643 | MSR Net:  0.00472\n",
      "\n",
      "[36/52] Date: 2022-12-31 | Year: 2022\n",
      "  Window: 2007-12-31 to 2022-11-30\n",
      "  Yearly: 300 | FinBERT: 9 | Union/Intersection: 7 | Assets: 6\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.06789 | MV Net:  0.07102 | MSR Net:  0.11930\n",
      "\n",
      "[37/52] Date: 2023-01-31 | Year: 2023\n",
      "  Window: 2008-01-31 to 2022-12-31\n",
      "  Yearly: 300 | FinBERT: 23 | Union/Intersection: 18 | Assets: 8\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.06481 | MV Net: -0.05884 | MSR Net: -0.05510\n",
      "\n",
      "[38/52] Date: 2023-02-28 | Year: 2023\n",
      "  Window: 2008-02-29 to 2023-01-31\n",
      "  Yearly: 300 | FinBERT: 23 | Union/Intersection: 12 | Assets: 7\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.03408 | MV Net: -0.04716 | MSR Net: -0.14807\n",
      "\n",
      "[39/52] Date: 2023-03-31 | Year: 2023\n",
      "  Window: 2008-03-31 to 2023-02-28\n",
      "  Yearly: 300 | FinBERT: 20 | Union/Intersection: 13 | Assets: 6\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.01708 | MV Net:  0.01611 | MSR Net:  0.01096\n",
      "\n",
      "[40/52] Date: 2023-04-30 | Year: 2023\n",
      "  Window: 2008-04-30 to 2023-03-31\n",
      "  Yearly: 300 | FinBERT: 23 | Union/Intersection: 14 | Assets: 6\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.07285 | MV Net: -0.06609 | MSR Net: -0.04316\n",
      "\n",
      "[41/52] Date: 2023-05-31 | Year: 2023\n",
      "  Window: 2008-05-31 to 2023-04-30\n",
      "  Yearly: 300 | FinBERT: 20 | Union/Intersection: 11 | Assets: 4\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.11709 | MV Net:  0.35903 | MSR Net: -0.10435\n",
      "\n",
      "[42/52] Date: 2023-06-30 | Year: 2023\n",
      "  Window: 2008-06-30 to 2023-05-31\n",
      "  Yearly: 300 | FinBERT: 25 | Union/Intersection: 12 | Assets: 6\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.05368 | MV Net:  0.05194 | MSR Net:  0.04321\n",
      "\n",
      "[43/52] Date: 2023-07-31 | Year: 2023\n",
      "  Window: 2008-07-31 to 2023-06-30\n",
      "  Yearly: 300 | FinBERT: 32 | Union/Intersection: 17 | Assets: 8\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.04363 | MV Net: -0.04034 | MSR Net: -0.03734\n",
      "\n",
      "[44/52] Date: 2023-08-31 | Year: 2023\n",
      "  Window: 2008-08-31 to 2023-07-31\n",
      "  Yearly: 300 | FinBERT: 29 | Union/Intersection: 10 | Assets: 6\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.03159 | MV Net: -0.03461 | MSR Net: -0.04025\n",
      "\n",
      "[45/52] Date: 2023-09-30 | Year: 2023\n",
      "  Window: 2008-09-30 to 2023-08-31\n",
      "  Yearly: 300 | FinBERT: 27 | Union/Intersection: 14 | Assets: 8\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.05782 | MV Net: -0.04202 | MSR Net: -0.02332\n",
      "\n",
      "[46/52] Date: 2023-10-31 | Year: 2023\n",
      "  Window: 2008-10-31 to 2023-09-30\n",
      "  Yearly: 300 | FinBERT: 31 | Union/Intersection: 18 | Assets: 12\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.04196 | MV Net:  0.06179 | MSR Net:  0.10871\n",
      "\n",
      "[47/52] Date: 2023-11-30 | Year: 2023\n",
      "  Window: 2008-11-30 to 2023-10-31\n",
      "  Yearly: 300 | FinBERT: 35 | Union/Intersection: 16 | Assets: 13\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.00935 | MV Net:  0.00497 | MSR Net:  0.03698\n",
      "\n",
      "[48/52] Date: 2023-12-31 | Year: 2023\n",
      "  Window: 2008-12-31 to 2023-11-30\n",
      "  Yearly: 300 | FinBERT: 36 | Union/Intersection: 23 | Assets: 16\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.01042 | MV Net: -0.00938 | MSR Net:  0.00136\n",
      "\n",
      "[49/52] Date: 2024-01-31 | Year: 2024\n",
      "  Window: 2009-01-31 to 2023-12-31\n",
      "  Yearly: 300 | FinBERT: 49 | Union/Intersection: 21 | Assets: 11\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.01192 | MV Net:  0.00309 | MSR Net:  0.02803\n",
      "\n",
      "[50/52] Date: 2024-02-29 | Year: 2024\n",
      "  Window: 2009-02-28 to 2024-01-31\n",
      "  Yearly: 300 | FinBERT: 28 | Union/Intersection: 13 | Assets: 9\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.04530 | MV Net:  0.04484 | MSR Net:  0.04756\n",
      "\n",
      "[51/52] Date: 2024-03-31 | Year: 2024\n",
      "  Window: 2009-03-31 to 2024-02-29\n",
      "  Yearly: 300 | FinBERT: 32 | Union/Intersection: 19 | Assets: 10\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net: -0.04419 | MV Net: -0.05067 | MSR Net:  0.02889\n",
      "\n",
      "[52/52] Date: 2024-04-30 | Year: 2024\n",
      "  Window: 2009-04-30 to 2024-03-31\n",
      "  Yearly: 300 | FinBERT: 42 | Union/Intersection: 21 | Assets: 13\n",
      "  Running Nodewise Regression...\n",
      "  Computing weights for all portfolios...\n",
      "  GMV Net:  0.08553 | MV Net:  0.08545 | MSR Net:  0.09127\n",
      "\n",
      "============================================================\n",
      "BACKTEST COMPLETE - ALL PORTFOLIOS\n",
      "============================================================\n",
      "\n",
      "GMV Portfolio:\n",
      "  Annual Return: 5.56%\n",
      "  Annual Volatility: 20.30%\n",
      "  Annual Sharpe Ratio: 0.274\n",
      "  Total Return: 16.65%\n",
      "  Avg Turnover: 1.7299\n",
      "\n",
      "MV Portfolio:\n",
      "  Annual Return: 17.72%\n",
      "  Annual Volatility: 26.48%\n",
      "  Annual Sharpe Ratio: 0.669\n",
      "  Total Return: 87.42%\n",
      "  Avg Turnover: 2.0879\n",
      "\n",
      "MSR Portfolio:\n",
      "  Annual Return: 4.27%\n",
      "  Annual Volatility: 21.87%\n",
      "  Annual Sharpe Ratio: 0.195\n",
      "  Total Return: 8.72%\n",
      "  Avg Turnover: 2.2173\n",
      "\n",
      "Performance Summary:\n",
      "GMV Sharpe: 0.274\n",
      "MV Sharpe:  0.669\n",
      "MSR Sharpe: 0.195\n"
     ]
    }
   ],
   "source": [
    "results_dict = backtest_nodewise_all_portfolios(\n",
    "    df,\n",
    "    factors_path='../AI Portfolio Selection/factors_ff_monthly_raw.csv',\n",
    "    ic='GIC',  # or 'BIC', 'WIC', 'AIC', 'cv'\n",
    "    test_start_date='2020-01-31',\n",
    "    test_end_date='2024-04-30',\n",
    "    lookback_window=180,\n",
    "    transaction_cost=0.001,\n",
    "    buys_path_template='../AI Portfolio Selection/novy_marx_buys_{}.csv',\n",
    "    sells_path_template='../AI Portfolio Selection/novy_marx_sells_{}.csv',\n",
    "    finbert_signals_path='monthly_signals_decay.csv',  # Your FinBERT signals\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Access individual portfolio results\n",
    "gmv_results, gmv_metrics = results_dict['GMV']\n",
    "mv_results, mv_metrics = results_dict['MV']\n",
    "msr_results, msr_metrics = results_dict['MSR']\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nPerformance Summary:\")\n",
    "print(f\"GMV Sharpe: {gmv_metrics['annual_sharpe_ratio']:.3f}\")\n",
    "print(f\"MV Sharpe:  {mv_metrics['annual_sharpe_ratio']:.3f}\")\n",
    "print(f\"MSR Sharpe: {msr_metrics['annual_sharpe_ratio']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f2cb5b6-0544-492b-87fa-b11a29c05d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GMV\n",
      "Annualized Sharpe Ratio: 0.2741\n",
      "Mean Return: 0.0556\n",
      "Variance: 0.0412\n",
      "Avg Turnover: 1.7299\n",
      "\n",
      " MV\n",
      "Annualized Sharpe Ratio: 0.6695\n",
      "Mean Return: 0.1772\n",
      "Variance: 0.0701\n",
      "Avg Turnover: 2.0879\n",
      "\n",
      " MSR\n",
      "Annualized Sharpe Ratio: 0.1955\n",
      "Mean Return: 0.0427\n",
      "Variance: 0.0478\n",
      "Avg Turnover: 2.2173\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n GMV\")\n",
    "print(f\"Annualized Sharpe Ratio: {gmv_metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {gmv_metrics['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {gmv_metrics['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {gmv_metrics['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MV\")\n",
    "print(f\"Annualized Sharpe Ratio: {mv_metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {mv_metrics['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {mv_metrics['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {mv_metrics['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MSR\")\n",
    "print(f\"Annualized Sharpe Ratio: {msr_metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {msr_metrics['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {msr_metrics['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {msr_metrics['avg_turnover']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d95446e-1652-4894-945c-de2122148979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
