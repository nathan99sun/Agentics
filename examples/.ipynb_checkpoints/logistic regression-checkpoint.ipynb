{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee8906f2-b17a-4a56-acec-955908c32af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('../green cleaned.csv', dtype={'ncusip': 'string'})\n",
    "df['ret_fwd_1'] = (df.groupby('permno')['ret_excess'].shift(-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48268543-75c0-4740-9b0c-b6e4135e41be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 89793\n",
      "Training accuracy: 0.5590\n",
      "\n",
      "Total stocks evaluated in Jan 2020: 497\n",
      "\n",
      "Buy probability statistics:\n",
      "count    497.000000\n",
      "mean       0.558957\n",
      "std        0.009452\n",
      "min        0.532203\n",
      "25%        0.553408\n",
      "50%        0.558889\n",
      "75%        0.565185\n",
      "max        0.582578\n",
      "Name: buy_probability, dtype: float64\n",
      "\n",
      "Stocks with buy probability >= 0.75: 0\n",
      "\n",
      "No stocks meet the 0.75 threshold.\n",
      "Consider using a lower threshold or selecting top N stocks.\n",
      "\n",
      "Top 50 stocks by buy probability:\n",
      "        permno    mom12m       mve        bm  buy_probability\n",
      "30921    14593  1.986466  1.857785 -0.874105         0.582578\n",
      "248109   86580  1.592618  1.798087 -0.851453         0.580572\n",
      "264584   91233  1.278524  1.857785 -1.094125         0.580365\n",
      "1145     10107  1.082318  1.857785 -0.873725         0.579112\n",
      "23644    13407  1.195430  1.857785 -0.492363         0.578680\n",
      "267582   92611  0.625689  1.857785 -0.916803         0.577457\n",
      "64085    21178  1.167951  1.501236 -1.121016         0.577337\n",
      "250080   87055  0.968955  1.684637 -0.796349         0.577207\n",
      "185702   61241  2.671570  0.716191 -0.970524         0.576900\n",
      "210653   75510  0.455684  1.857785 -0.945246         0.576868\n",
      "154247   49154  2.671570  0.925843 -0.266352         0.576867\n",
      "199443   66181  0.196895  1.857785 -1.207130         0.576469\n",
      "219453   77178  1.063722  1.407697 -1.146592         0.576295\n",
      "48594    18163  0.437092  1.857785 -0.651822         0.576130\n",
      "267401   92602  0.142576  1.705933 -1.520493         0.575837\n",
      "99067    26403  0.554471  1.857785 -0.323123         0.575833\n",
      "5707     10696  1.384706  1.134804 -0.936163         0.575008\n",
      "31721    14702  2.341626  0.760682 -0.522169         0.574944\n",
      "25865    13856 -0.027232  1.857785 -0.894125         0.574895\n",
      "16971    12308  1.679219  1.418599  0.546140         0.574892\n",
      "778      10104  0.004698  1.857785 -0.787547         0.574776\n",
      "2147     10145  0.503674  1.655826 -0.603065         0.574762\n",
      "188220   62092  0.618986  1.688247 -0.242987         0.574629\n",
      "168435   55976  0.151442  1.857785 -0.376353         0.574404\n",
      "241126   84788 -0.279848  1.857785 -0.998573         0.574161\n",
      "150936   48486  2.671570  0.438765 -0.652905         0.574100\n",
      "46217    17830  0.700487  1.679697  0.100708         0.574096\n",
      "27794    14008 -0.095295  1.787113 -0.867492         0.574043\n",
      "44125    17478  1.345825  0.955211 -1.133439         0.573962\n",
      "57347    19561 -0.447531  1.857785 -1.173205         0.573914\n",
      "222938   77702  0.381911  1.433632 -1.130874         0.573831\n",
      "254930   88873  2.145009  0.740666 -0.430836         0.573830\n",
      "172005   57665  0.048473  1.653768 -0.950683         0.573787\n",
      "36670    15579  0.199155  1.594327 -0.871428         0.573741\n",
      "246156   86111  0.469506  1.417967 -0.945366         0.573628\n",
      "15278    12060  1.248038  1.370332  0.256667         0.573530\n",
      "35697    15488  0.091937  1.659382 -0.703042         0.573432\n",
      "136348   43449 -0.615908  1.834131 -1.319129         0.573420\n",
      "8748     11308 -0.434382  1.857785 -0.922325         0.573393\n",
      "257954   89393 -0.382011  1.782615 -1.041995         0.573303\n",
      "152866   48725  0.165763  1.647406 -0.556743         0.573293\n",
      "258539   89525  0.226474  1.857785  0.239839         0.573289\n",
      "178177   59328  0.021322  1.857785 -0.104758         0.573284\n",
      "260732   90215 -0.322381  1.800049 -0.771721         0.573048\n",
      "74449    22752 -0.433964  1.857785 -0.767354         0.573041\n",
      "61173    20482 -0.274172  1.857785 -0.444989         0.572922\n",
      "148475   47896  0.546073  1.857785  1.021256         0.572739\n",
      "85715    24205  0.497949  1.583195  0.075763         0.572650\n",
      "181483   60097 -0.084115  1.857785  0.105520         0.572399\n",
      "55849    19393 -0.568930  1.846247 -0.673897         0.572222\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming df is already loaded with columns: datadate, permno, mom12m, mve, bm\n",
    "\n",
    "# Convert datadate to datetime if not already\n",
    "df['datadate'] = pd.to_datetime(df['datadate'])\n",
    "\n",
    "# Define training window (15 years before January 2020)\n",
    "train_start = pd.to_datetime('2005-01-31')\n",
    "train_end = pd.to_datetime('2019-12-31')\n",
    "predict_date = pd.to_datetime('2020-01-31')\n",
    "\n",
    "# Filter training data\n",
    "train_df = df[(df['datadate'] >= train_start) & (df['datadate'] <= train_end)].copy()\n",
    "\n",
    "# Create binary target based on top quintile (top 20%) of returns\n",
    "# Group by date and calculate quintile thresholds\n",
    "# train_df['target'] = train_df.groupby('datadate')['ret_fwd_1'].transform(\n",
    "#     lambda x: (x >= x.quantile(0.90)).astype(int)\n",
    "# )\n",
    "train_df['target'] = (train_df['ret_fwd_1'] > 0).astype(int)\n",
    "\n",
    "# Remove rows with missing values\n",
    "train_df = train_df.dropna(subset=['mom12m', 'mve', 'bm', 'target'])\n",
    "\n",
    "# Prepare features\n",
    "features = ['mom12m', 'mve', 'bm']\n",
    "X_train = train_df[features]\n",
    "y_train = train_df['target']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Train logistic regression\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get prediction data for January 2020\n",
    "predict_df = df[df['datadate'] == predict_date].copy()\n",
    "\n",
    "predict_df = predict_df.dropna(subset=['mom12m', 'mve', 'bm'])\n",
    "\n",
    "# Prepare features for prediction\n",
    "X_predict = predict_df[features]\n",
    "X_predict_scaled = scaler.transform(X_predict)\n",
    "\n",
    "# Generate buy signals (probability of positive return)\n",
    "predict_df['buy_probability'] = log_reg.predict_proba(X_predict_scaled)[:, 1]\n",
    "predict_df['buy_signal'] = log_reg.predict(X_predict_scaled)\n",
    "\n",
    "# Sort by buy probability (highest first)\n",
    "predict_df = predict_df.sort_values('buy_probability', ascending=False)\n",
    "\n",
    "# Display probability distribution\n",
    "print(f\"Training samples: {len(train_df)}\")\n",
    "print(f\"Training accuracy: {log_reg.score(X_train_scaled, y_train):.4f}\")\n",
    "print(f\"\\nTotal stocks evaluated in Jan 2020: {len(predict_df)}\")\n",
    "print(f\"\\nBuy probability statistics:\")\n",
    "print(predict_df['buy_probability'].describe())\n",
    "print(f\"\\nStocks with buy probability >= 0.75: {len(predict_df[predict_df['buy_probability'] >= 0.75])}\")\n",
    "\n",
    "# If no stocks meet 0.75 threshold, show top percentile\n",
    "threshold = 0.75\n",
    "high_confidence_buys = predict_df[predict_df['buy_probability'] >= threshold].copy()\n",
    "\n",
    "if len(high_confidence_buys) == 0:\n",
    "    print(f\"\\nNo stocks meet the 0.75 threshold.\")\n",
    "    print(f\"Consider using a lower threshold or selecting top N stocks.\")\n",
    "    print(f\"\\nTop 50 stocks by buy probability:\")\n",
    "    top_stocks = predict_df.nlargest(50, 'buy_probability')\n",
    "    print(top_stocks[['permno', 'mom12m', 'mve', 'bm', 'buy_probability']].to_string())\n",
    "    buy_signals_jan2020 = top_stocks[['permno', 'datadate', 'mom12m', 'mve', 'bm', 'buy_probability']]\n",
    "else:\n",
    "    print(f\"\\nHigh confidence buy signals (probability >= {threshold}):\")\n",
    "    print(high_confidence_buys[['permno', 'mom12m', 'mve', 'bm', 'buy_probability']].to_string())\n",
    "    buy_signals_jan2020 = high_confidence_buys[['permno', 'datadate', 'mom12m', 'mve', 'bm', 'buy_probability']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0277f96b-98e7-4dff-9fc6-a8e584ec1614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da7d43bc-e282-4939-a5c1-1919cf8f3268",
   "metadata": {},
   "source": [
    "## Then we run nodewise on the buys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa497901-9d15-4a09-8292-f76d7e385630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def naive_nodewise_regression(Y_star, lambda_grid=None):\n",
    "    \"\"\"\n",
    "    Implements Naive Nodewise Regression (Section 5.1.2).\n",
    "    Uses GIC (Generalized Information Criterion) as in the paper.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Y_star : np.ndarray, shape (n, p)\n",
    "        Demeaned returns matrix (time x assets)\n",
    "    lambda_grid : list or None\n",
    "        Grid of lambda values to try. If None, creates default grid.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Estimated precision matrix\n",
    "    \"\"\"\n",
    "    n, p = Y_star.shape\n",
    "\n",
    "    # Initialize matrices\n",
    "    Theta_hat = np.zeros((p, p))\n",
    "    tau_squared = np.zeros(p)\n",
    "    \n",
    "    # Create lambda grid if not provided\n",
    "    if lambda_grid is None:\n",
    "        lambda_grid = np.logspace(-3, 1, 50)\n",
    "    \n",
    "    # For each asset j\n",
    "    for j in range(p):\n",
    "        # Step 1: Get y_j (target) and Y_{-j} (predictors)\n",
    "        y_j = Y_star[:, j]\n",
    "        Y_minus_j = np.delete(Y_star, j, axis=1)\n",
    "        \n",
    "        # Step 2-3: Estimate gamma_j using Lasso with GIC\n",
    "        # GIC(λ) = log(σ²_λ) + |S_λ| * (log(p-1) / n) * log(log(n))\n",
    "        best_gic = np.inf\n",
    "        best_lambda = lambda_grid[0]\n",
    "        best_gamma = None\n",
    "        best_ssr = None\n",
    "        \n",
    "        for lam in lambda_grid:\n",
    "            lasso = Lasso(alpha=2*lam, fit_intercept=False, max_iter=10000)\n",
    "            lasso.fit(Y_minus_j, y_j)\n",
    "            gamma_j = lasso.coef_\n",
    "            \n",
    "            # Compute SSR and number of non-zero coefficients\n",
    "            residuals = y_j - Y_minus_j @ gamma_j\n",
    "            ssr = np.sum(residuals ** 2)\n",
    "            sigma_sq_lambda = ssr / n\n",
    "            q_lambda = np.sum(np.abs(gamma_j) > 1e-8)\n",
    "            \n",
    "            # Compute GIC\n",
    "            if sigma_sq_lambda > 1e-10: # Check for non-zero variance\n",
    "                # GIC formula from paper\n",
    "                gic = np.log(sigma_sq_lambda) + q_lambda * (np.log(p) / n) * np.log(np.log(n))\n",
    "            else:\n",
    "                gic = np.inf\n",
    "            \n",
    "            if gic < best_gic:\n",
    "                best_gic = gic\n",
    "                best_lambda = lam\n",
    "                best_gamma = gamma_j.copy()\n",
    "                best_ssr = ssr\n",
    "        \n",
    "        gamma_j_star = best_gamma\n",
    "        \n",
    "\n",
    "        tau_squared[j] = best_ssr / n + best_lambda * np.sum(np.abs(gamma_j_star))\n",
    "\n",
    "        # [cite_start]Step 5: Form the j-th row of Theta_hat [cite: 579, 543-547]\n",
    "        Theta_hat[j, j] = 1 / tau_squared[j]\n",
    "        off_diag = -gamma_j_star / tau_squared[j]\n",
    "        Theta_hat[j, :j] = off_diag[:j]\n",
    "        Theta_hat[j, j+1:] = off_diag[j:]\n",
    "    \n",
    "    # Step 6: Symmetrize\n",
    "    Theta_hat_sym = (Theta_hat + Theta_hat.T) / 2\n",
    "    \n",
    "    return Theta_hat_sym\n",
    "\n",
    "\n",
    "def gmv_weights(Theta_hat):\n",
    "    \"\"\"\n",
    "    Compute Global Minimum Variance (GMV) portfolio weights (Section 6.1).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # w* = (Θ 1_p) / (1_p' Θ 1_p)\n",
    "    numerator = Theta_hat @ ones_p\n",
    "    denominator = ones_p @ Theta_hat @ ones_p\n",
    "    \n",
    "    if np.abs(denominator) < 1e-10:\n",
    "        # Fallback to equal weights if precision matrix is near-singular\n",
    "        return ones_p / p\n",
    "    \n",
    "    w_star = numerator / denominator\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "\n",
    "def compute_portfolio_metrics(returns, weights):\n",
    "    \"\"\"\n",
    "    Compute portfolio return, variance, and Sharpe ratio.\n",
    "    \"\"\"\n",
    "\n",
    "    portfolio_returns = returns @ weights\n",
    "    mean_return = np.mean(portfolio_returns)\n",
    "    variance = np.var(portfolio_returns, ddof=1)\n",
    "    sharpe_ratio = mean_return / np.sqrt(variance) if variance > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'return': mean_return,\n",
    "        'variance': variance,\n",
    "        'sharpe_ratio': sharpe_ratio\n",
    "    }\n",
    "\n",
    "\n",
    "def backtest_nodewise_gmv(df, \n",
    "                          test_start_date='2000-01-31', \n",
    "                          test_end_date='2003-12-31',\n",
    "                          lookback_window=180,\n",
    "                          transaction_cost=0.005,\n",
    "                          verbose=True):\n",
    "    \"\"\"\n",
    "    Backtest Nodewise + GMV strategy with monthly rebalancing,\n",
    "    180-month rolling window, and NaN filtering as per the paper.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with columns: permno, datadate, ret_fwd_1\n",
    "    test_start_date : str\n",
    "        First date for out-of-sample returns (format: 'YYYY-MM-DD')\n",
    "    test_end_date : str\n",
    "        Last date for out-of-sample returns (format: 'YYYY-MM-DD')\n",
    "    lookback_window : int\n",
    "        Number of months in rolling training window (default: 180)\n",
    "    transaction_cost : float\n",
    "        Proportional transaction cost (default: 0.005 = 50 bps)\n",
    "    verbose : bool\n",
    "        If True, prints detailed log at each time step.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results_df : pd.DataFrame\n",
    "        DataFrame with columns: date, portfolio_return, cumulative_return\n",
    "    metrics : dict\n",
    "        Overall performance metrics\n",
    "    \"\"\"\n",
    "    # --- 1. Setup ---\n",
    "    df = df.copy()\n",
    "    if 'datadate' not in df.columns or 'permno' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have 'datadate' and 'permno' columns\")\n",
    "    df['datadate'] = pd.to_datetime(df['datadate'])\n",
    "    \n",
    "    # Get unique dates\n",
    "    all_dates = sorted(df['datadate'].unique())\n",
    "    \n",
    "    # Convert test dates to datetime\n",
    "    test_start_dt = pd.to_datetime(test_start_date)\n",
    "    test_end_dt = pd.to_datetime(test_end_date)\n",
    "    \n",
    "    # Find date indices\n",
    "    try:\n",
    "        test_start_idx = all_dates.index(test_start_dt)\n",
    "        test_end_idx = all_dates.index(test_end_dt)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Date not found in DataFrame: {e}\")\n",
    "    \n",
    "    if test_start_idx < lookback_window:\n",
    "        raise ValueError(f\"Not enough data for lookback. Test start date {test_start_date} \"\n",
    "                         f\"requires data back to {all_dates[test_start_idx - lookback_window]}, \"\n",
    "                         f\"but only {test_start_idx} periods are available.\")\n",
    "    \n",
    "    # Storage for results\n",
    "    portfolio_returns = []\n",
    "    portfolio_dates = []\n",
    "    portfolio_weights_list = []\n",
    "    portfolio_turnover_list = []\n",
    "    \n",
    "    # FIX 7: Use dictionary to track weights by permno (handles entry/exit)\n",
    "    prev_weights_dict = {}  # Maps permno -> weight\n",
    "    prev_oos_returns_dict = {}  # Maps permno -> return\n",
    "    prev_gross_return = 0.0\n",
    "    \n",
    "    # --- 2. Rolling Window Backtest ---\n",
    "    if verbose:\n",
    "        print(\"=\"*60)\n",
    "        print(\"STARTING BACKTEST\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "    for t in range(test_start_idx, test_end_idx + 1):\n",
    "        current_date = all_dates[t]\n",
    "        \n",
    "        # Define the lookback window\n",
    "        window_start_date = all_dates[t - lookback_window]\n",
    "        window_end_date = all_dates[t - 1]\n",
    "        \n",
    "        # Get training data for this window\n",
    "        train_data = df[(df['datadate'] >= window_start_date) & \n",
    "                        (df['datadate'] <= window_end_date)]\n",
    "        \n",
    "        # Pivot to get returns matrix (time x assets)\n",
    "        returns_pivot = train_data.pivot(index='datadate', columns='permno', values='ret_fwd_1')\n",
    "        \n",
    "        # Reindex to ensure all dates are present\n",
    "        window_dates = all_dates[t - lookback_window : t]\n",
    "        returns_pivot = returns_pivot.reindex(index=window_dates)\n",
    "        \n",
    "        # Filter assets with any NaNs in this window\n",
    "        # (This follows the paper's approach of requiring complete data)\n",
    "        nan_assets = returns_pivot.columns[returns_pivot.isna().any()]\n",
    "        filtered_pivot = returns_pivot.drop(columns=nan_assets)\n",
    "        \n",
    "        current_assets = filtered_pivot.columns.tolist()\n",
    "        Y = filtered_pivot.values\n",
    "        n_train, p_current = Y.shape\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                  f\"Date: {current_date.strftime('%Y-%m-%d')}\")\n",
    "            print(f\"  Window: {window_start_date.strftime('%Y-%m-%d')} to \"\n",
    "                  f\"{window_end_date.strftime('%Y-%m-%d')}\")\n",
    "            print(f\"  Assets: {p_current} with complete data\")\n",
    "\n",
    "        # Check for valid data\n",
    "        if n_train < lookback_window or p_current < 2:\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ Insufficient data (n={n_train}, p={p_current}), using prev weights\")\n",
    "            new_weights_dict = prev_weights_dict.copy()\n",
    "        else:\n",
    "            try:\n",
    "                # Demean the returns\n",
    "                Y_bar = Y.mean(axis=0)\n",
    "                Y_star = Y - Y_bar\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Running Nodewise Regression...\")\n",
    "                Theta_hat = naive_nodewise_regression(Y_star)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Computing GMV weights...\")\n",
    "                w_star = gmv_weights(Theta_hat)\n",
    "                \n",
    "                # Create weights dictionary\n",
    "                new_weights_dict = {asset: w_star[i] for i, asset in enumerate(current_assets)}\n",
    "                \n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"  ✗ Error: {e}\")\n",
    "                    print(f\"  Using previous weights\")\n",
    "                new_weights_dict = prev_weights_dict.copy()\n",
    "\n",
    "        # Normalize weights to sum to 1\n",
    "        weight_sum = sum(new_weights_dict.values())\n",
    "        if weight_sum > 1e-10:\n",
    "            new_weights_dict = {k: v/weight_sum for k, v in new_weights_dict.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ Zero weight sum, using previous weights\")\n",
    "            new_weights_dict = prev_weights_dict.copy()\n",
    "        \n",
    "        # --- 3. OOS Returns & Transaction Costs ---\n",
    "        \n",
    "        # Get out-of-sample returns for current month\n",
    "        oos_data = df[df['datadate'] == current_date]\n",
    "        oos_returns_series = oos_data.set_index('permno')['ret_fwd_1']\n",
    "        \n",
    "        # FIX 8: Filter out NaN returns and create dictionary\n",
    "        oos_returns_series = oos_returns_series.dropna()\n",
    "        oos_returns_dict = oos_returns_series.to_dict()\n",
    "        \n",
    "        # Find common assets between weights and returns (both existing and non-NaN)\n",
    "        common_assets = set(new_weights_dict.keys()) & set(oos_returns_dict.keys())\n",
    "        \n",
    "        if len(common_assets) == 0:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ No common assets with valid returns, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Filter to common assets and renormalize\n",
    "        common_weights = {a: new_weights_dict[a] for a in common_assets}\n",
    "        common_weight_sum = sum(common_weights.values())\n",
    "        if common_weight_sum > 1e-10:\n",
    "            common_weights = {k: v/common_weight_sum for k, v in common_weights.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ Zero weight sum after filtering, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Compute gross portfolio return (all returns should be valid now)\n",
    "        gross_return = sum(common_weights[a] * oos_returns_dict[a] for a in common_assets)\n",
    "        \n",
    "        # Sanity check\n",
    "        if np.isnan(gross_return) or np.isinf(gross_return):\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ Invalid gross return: {gross_return}, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # FIX 9: Calculate transaction costs with proper weight adjustment\n",
    "        if len(prev_weights_dict) > 0:\n",
    "            # Get the universe of all assets (current + previous)\n",
    "            all_traded_assets = set(common_weights.keys()) | set(prev_weights_dict.keys())\n",
    "            \n",
    "            # Adjust previous weights for all assets that were held\n",
    "            # w+_{t,j} = w_{t,j} * (1 + r_{t,j}) / (1 + r_p,t)\n",
    "            adjusted_prev = {}\n",
    "            for asset in all_traded_assets:\n",
    "                prev_w = prev_weights_dict.get(asset, 0.0)\n",
    "                \n",
    "                if asset in prev_oos_returns_dict:\n",
    "                    prev_r = prev_oos_returns_dict[asset]\n",
    "                    # Avoid division by zero\n",
    "                    if prev_gross_return > -0.99:  # Allow for up to 99% loss\n",
    "                        adjusted_prev[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return)\n",
    "                    else:\n",
    "                        adjusted_prev[asset] = 0.0\n",
    "                else:\n",
    "                    # Asset wasn't in portfolio last period, so adjusted weight is 0\n",
    "                    adjusted_prev[asset] = 0.0\n",
    "            \n",
    "            # Renormalize adjusted weights (only over assets that still exist)\n",
    "            adj_sum = sum(adjusted_prev.get(a, 0.0) for a in common_weights.keys())\n",
    "            if adj_sum > 1e-10:\n",
    "                adjusted_prev_normalized = {k: adjusted_prev.get(k, 0.0)/adj_sum \n",
    "                                           for k in common_weights.keys()}\n",
    "            else:\n",
    "                adjusted_prev_normalized = {k: 0.0 for k in common_weights.keys()}\n",
    "            \n",
    "            # Turnover: sum over ALL assets (current and previous)\n",
    "            # This captures: rebalancing existing positions + exiting old + entering new\n",
    "            turnover = sum(abs(common_weights.get(a, 0.0) - adjusted_prev_normalized.get(a, 0.0)) \n",
    "                          for a in all_traded_assets)\n",
    "            \n",
    "            # Transaction cost: c * (1 + gross_return) * turnover\n",
    "            tc = transaction_cost * (1 + gross_return) * turnover\n",
    "        else:\n",
    "            # First period: full turnover (entering all positions)\n",
    "            turnover = sum(abs(w) for w in common_weights.values())\n",
    "            tc = transaction_cost * turnover\n",
    "        \n",
    "        # Net return\n",
    "        net_return = gross_return - tc\n",
    "        \n",
    "        # Store results\n",
    "        portfolio_returns.append(net_return)\n",
    "        portfolio_dates.append(current_date)\n",
    "        portfolio_weights_list.append(common_weights.copy())\n",
    "        portfolio_turnover_list.append(turnover)\n",
    "        \n",
    "        # Update previous values for next iteration\n",
    "        prev_weights_dict = common_weights.copy()\n",
    "        prev_oos_returns_dict = {a: oos_returns_dict[a] for a in common_assets}\n",
    "        prev_gross_return = gross_return\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  Gross: {gross_return:>8.5f} | Turnover: {turnover:>6.4f} | \"\n",
    "                  f\"TC: {tc:>8.6f} | Net: {net_return:>8.5f}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BACKTEST COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    # --- 4. Compile Results ---\n",
    "    results_df = pd.DataFrame({\n",
    "        'date': portfolio_dates,\n",
    "        'portfolio_return': portfolio_returns,\n",
    "        'portfolio_weights': portfolio_weights_list,\n",
    "        'portfolio_turnover': portfolio_turnover_list\n",
    "    })\n",
    "    results_df['cumulative_return'] = (1 + results_df['portfolio_return']).cumprod() - 1\n",
    "    \n",
    "    # Compute overall metrics\n",
    "    if len(portfolio_returns) > 0:\n",
    "        mean_return = np.mean(portfolio_returns)\n",
    "        variance = np.var(portfolio_returns, ddof=1)\n",
    "        sharpe_ratio = mean_return / np.sqrt(variance) if variance > 0 else 0\n",
    "        \n",
    "        # Annualized metrics (monthly data)\n",
    "        annual_return = mean_return * 12\n",
    "        annual_volatility = np.sqrt(variance * 12)\n",
    "        annual_sharpe = annual_return / annual_volatility if annual_volatility > 0 else 0\n",
    "        \n",
    "        metrics = {\n",
    "            'mean_return': mean_return,\n",
    "            'variance': variance,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'annual_return': annual_return,\n",
    "            'annual_volatility': annual_volatility,\n",
    "            'annual_sharpe_ratio': annual_sharpe,\n",
    "            'total_return': results_df['cumulative_return'].iloc[-1],\n",
    "            'avg_turnover': np.mean(portfolio_turnover_list),\n",
    "            'n_periods': len(portfolio_returns)\n",
    "        }\n",
    "    else:\n",
    "        metrics = {\n",
    "            'mean_return': 0,\n",
    "            'variance': 0,\n",
    "            'sharpe_ratio': 0,\n",
    "            'annual_return': 0,\n",
    "            'annual_volatility': 0,\n",
    "            'annual_sharpe_ratio': 0,\n",
    "            'total_return': 0,\n",
    "            'avg_turnover': 0,\n",
    "            'n_periods': 0\n",
    "        }\n",
    "    \n",
    "    return results_df, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f90eb5a-c4bd-49e1-b62d-976ba8b9c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "buys = buy_signals_jan2020['permno'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8df5eca6-27c6-44b4-89fa-448442842885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df['permno'].isin(buys)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1c14d9b-d2cd-4585-aa70-2c6e3c653dfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STARTING BACKTEST\n",
      "============================================================\n",
      "\n",
      "[1/59] Date: 2020-01-31\n",
      "  Window: 2005-01-31 to 2019-12-31\n",
      "  Assets: 37 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.08749 | Turnover: 1.0177 | TC: 0.001018 | Net: -0.08850\n",
      "\n",
      "[2/59] Date: 2020-02-29\n",
      "  Window: 2005-02-28 to 2020-01-31\n",
      "  Assets: 37 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.09407 | Turnover: 0.0296 | TC: 0.000027 | Net: -0.09410\n",
      "\n",
      "[3/59] Date: 2020-03-31\n",
      "  Window: 2005-03-31 to 2020-02-29\n",
      "  Assets: 37 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.10468 | Turnover: 0.0610 | TC: 0.000067 | Net:  0.10462\n",
      "\n",
      "[4/59] Date: 2020-04-30\n",
      "  Window: 2005-04-30 to 2020-03-31\n",
      "  Assets: 37 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.03333 | Turnover: 0.0669 | TC: 0.000069 | Net:  0.03326\n",
      "\n",
      "[5/59] Date: 2020-05-31\n",
      "  Window: 2005-05-31 to 2020-04-30\n",
      "  Assets: 37 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.00692 | Turnover: 0.0382 | TC: 0.000038 | Net: -0.00696\n",
      "\n",
      "[6/59] Date: 2020-06-30\n",
      "  Window: 2005-06-30 to 2020-05-31\n",
      "  Assets: 37 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.04677 | Turnover: 0.0368 | TC: 0.000039 | Net:  0.04673\n",
      "\n",
      "[7/59] Date: 2020-07-31\n",
      "  Window: 2005-07-31 to 2020-06-30\n",
      "  Assets: 37 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.07107 | Turnover: 0.0508 | TC: 0.000054 | Net:  0.07102\n",
      "\n",
      "[8/59] Date: 2020-08-31\n",
      "  Window: 2005-08-31 to 2020-07-31\n",
      "  Assets: 37 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.00022 | Turnover: 0.0441 | TC: 0.000044 | Net:  0.00018\n",
      "\n",
      "[9/59] Date: 2020-09-30\n",
      "  Window: 2005-09-30 to 2020-08-31\n",
      "  Assets: 37 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.03119 | Turnover: 0.0272 | TC: 0.000026 | Net: -0.03122\n",
      "\n",
      "[10/59] Date: 2020-10-31\n",
      "  Window: 2005-10-31 to 2020-09-30\n",
      "  Assets: 37 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.10429 | Turnover: 0.0295 | TC: 0.000033 | Net:  0.10426\n",
      "\n",
      "[11/59] Date: 2020-11-30\n",
      "  Window: 2005-11-30 to 2020-10-31\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.02463 | Turnover: 0.1032 | TC: 0.000106 | Net:  0.02453\n",
      "\n",
      "[12/59] Date: 2020-12-31\n",
      "  Window: 2005-12-31 to 2020-11-30\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.02838 | Turnover: 0.0419 | TC: 0.000041 | Net: -0.02842\n",
      "\n",
      "[13/59] Date: 2021-01-31\n",
      "  Window: 2006-01-31 to 2020-12-31\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.00208 | Turnover: 0.0480 | TC: 0.000048 | Net:  0.00203\n",
      "\n",
      "[14/59] Date: 2021-02-28\n",
      "  Window: 2006-02-28 to 2021-01-31\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.06101 | Turnover: 0.0572 | TC: 0.000061 | Net:  0.06095\n",
      "\n",
      "[15/59] Date: 2021-03-31\n",
      "  Window: 2006-03-31 to 2021-02-28\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.02578 | Turnover: 0.0423 | TC: 0.000043 | Net:  0.02574\n",
      "\n",
      "[16/59] Date: 2021-04-30\n",
      "  Window: 2006-04-30 to 2021-03-31\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.00747 | Turnover: 0.0302 | TC: 0.000030 | Net:  0.00744\n",
      "\n",
      "[17/59] Date: 2021-05-31\n",
      "  Window: 2006-05-31 to 2021-04-30\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.01024 | Turnover: 0.0327 | TC: 0.000033 | Net:  0.01021\n",
      "\n",
      "[18/59] Date: 2021-06-30\n",
      "  Window: 2006-06-30 to 2021-05-31\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.04229 | Turnover: 0.0362 | TC: 0.000038 | Net:  0.04225\n",
      "\n",
      "[19/59] Date: 2021-07-31\n",
      "  Window: 2006-07-31 to 2021-06-30\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.01076 | Turnover: 0.0364 | TC: 0.000037 | Net:  0.01073\n",
      "\n",
      "[20/59] Date: 2021-08-31\n",
      "  Window: 2006-08-31 to 2021-07-31\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.04341 | Turnover: 0.0279 | TC: 0.000027 | Net: -0.04344\n",
      "\n",
      "[21/59] Date: 2021-09-30\n",
      "  Window: 2006-09-30 to 2021-08-31\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.05323 | Turnover: 0.0309 | TC: 0.000033 | Net:  0.05319\n",
      "\n",
      "[22/59] Date: 2021-10-31\n",
      "  Window: 2006-10-31 to 2021-09-30\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.01680 | Turnover: 0.0660 | TC: 0.000065 | Net: -0.01686\n",
      "\n",
      "[23/59] Date: 2021-11-30\n",
      "  Window: 2006-11-30 to 2021-10-31\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.05761 | Turnover: 0.0463 | TC: 0.000049 | Net:  0.05757\n",
      "\n",
      "[24/59] Date: 2021-12-31\n",
      "  Window: 2006-12-31 to 2021-11-30\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.03836 | Turnover: 0.0536 | TC: 0.000052 | Net: -0.03841\n",
      "\n",
      "[25/59] Date: 2022-01-31\n",
      "  Window: 2007-01-31 to 2021-12-31\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.02594 | Turnover: 0.0459 | TC: 0.000045 | Net: -0.02598\n",
      "\n",
      "[26/59] Date: 2022-02-28\n",
      "  Window: 2007-02-28 to 2022-01-31\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.03268 | Turnover: 0.0446 | TC: 0.000046 | Net:  0.03264\n",
      "\n",
      "[27/59] Date: 2022-03-31\n",
      "  Window: 2007-03-31 to 2022-02-28\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.04135 | Turnover: 0.0499 | TC: 0.000048 | Net: -0.04140\n",
      "\n",
      "[28/59] Date: 2022-04-30\n",
      "  Window: 2007-04-30 to 2022-03-31\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.01256 | Turnover: 0.0724 | TC: 0.000072 | Net: -0.01263\n",
      "\n",
      "[29/59] Date: 2022-05-31\n",
      "  Window: 2007-05-31 to 2022-04-30\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.05096 | Turnover: 0.0460 | TC: 0.000044 | Net: -0.05101\n",
      "\n",
      "[30/59] Date: 2022-06-30\n",
      "  Window: 2007-06-30 to 2022-05-31\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.06259 | Turnover: 0.0482 | TC: 0.000051 | Net:  0.06254\n",
      "\n",
      "[31/59] Date: 2022-07-31\n",
      "  Window: 2007-07-31 to 2022-06-30\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.03413 | Turnover: 0.0643 | TC: 0.000062 | Net: -0.03419\n",
      "\n",
      "[32/59] Date: 2022-08-31\n",
      "  Window: 2007-08-31 to 2022-07-31\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.08718 | Turnover: 0.0274 | TC: 0.000025 | Net: -0.08720\n",
      "\n",
      "[33/59] Date: 2022-09-30\n",
      "  Window: 2007-09-30 to 2022-08-31\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.09956 | Turnover: 0.0415 | TC: 0.000046 | Net:  0.09952\n",
      "\n",
      "[34/59] Date: 2022-10-31\n",
      "  Window: 2007-10-31 to 2022-09-30\n",
      "  Assets: 38 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.05956 | Turnover: 0.0923 | TC: 0.000098 | Net:  0.05946\n",
      "\n",
      "[35/59] Date: 2022-11-30\n",
      "  Window: 2007-11-30 to 2022-10-31\n",
      "  Assets: 39 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.03859 | Turnover: 0.0994 | TC: 0.000096 | Net: -0.03869\n",
      "\n",
      "[36/59] Date: 2022-12-31\n",
      "  Window: 2007-12-31 to 2022-11-30\n",
      "  Assets: 39 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.02065 | Turnover: 0.0389 | TC: 0.000040 | Net:  0.02061\n",
      "\n",
      "[37/59] Date: 2023-01-31\n",
      "  Window: 2008-01-31 to 2022-12-31\n",
      "  Assets: 39 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.03918 | Turnover: 0.0713 | TC: 0.000069 | Net: -0.03925\n",
      "\n",
      "[38/59] Date: 2023-02-28\n",
      "  Window: 2008-02-29 to 2023-01-31\n",
      "  Assets: 39 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.03739 | Turnover: 0.0372 | TC: 0.000039 | Net:  0.03735\n",
      "\n",
      "[39/59] Date: 2023-03-31\n",
      "  Window: 2008-03-31 to 2023-02-28\n",
      "  Assets: 39 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.02674 | Turnover: 0.0499 | TC: 0.000051 | Net:  0.02669\n",
      "\n",
      "[40/59] Date: 2023-04-30\n",
      "  Window: 2008-04-30 to 2023-03-31\n",
      "  Assets: 40 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.05259 | Turnover: 0.0788 | TC: 0.000075 | Net: -0.05266\n",
      "\n",
      "[41/59] Date: 2023-05-31\n",
      "  Window: 2008-05-31 to 2023-04-30\n",
      "  Assets: 40 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.04989 | Turnover: 0.0471 | TC: 0.000049 | Net:  0.04984\n",
      "\n",
      "[42/59] Date: 2023-06-30\n",
      "  Window: 2008-06-30 to 2023-05-31\n",
      "  Assets: 40 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.00838 | Turnover: 0.0369 | TC: 0.000037 | Net:  0.00834\n",
      "\n",
      "[43/59] Date: 2023-07-31\n",
      "  Window: 2008-07-31 to 2023-06-30\n",
      "  Assets: 41 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.02884 | Turnover: 0.0592 | TC: 0.000057 | Net: -0.02890\n",
      "\n",
      "[44/59] Date: 2023-08-31\n",
      "  Window: 2008-08-31 to 2023-07-31\n",
      "  Assets: 41 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.06036 | Turnover: 0.0292 | TC: 0.000027 | Net: -0.06039\n",
      "\n",
      "[45/59] Date: 2023-09-30\n",
      "  Window: 2008-09-30 to 2023-08-31\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.00957 | Turnover: 0.0537 | TC: 0.000053 | Net: -0.00963\n",
      "\n",
      "[46/59] Date: 2023-10-31\n",
      "  Window: 2008-10-31 to 2023-09-30\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.07169 | Turnover: 0.0713 | TC: 0.000076 | Net:  0.07162\n",
      "\n",
      "[47/59] Date: 2023-11-30\n",
      "  Window: 2008-11-30 to 2023-10-31\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.03369 | Turnover: 0.0638 | TC: 0.000066 | Net:  0.03363\n",
      "\n",
      "[48/59] Date: 2023-12-31\n",
      "  Window: 2008-12-31 to 2023-11-30\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.00611 | Turnover: 0.0410 | TC: 0.000041 | Net:  0.00607\n",
      "\n",
      "[49/59] Date: 2024-01-31\n",
      "  Window: 2009-01-31 to 2023-12-31\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.01145 | Turnover: 0.0477 | TC: 0.000048 | Net:  0.01141\n",
      "\n",
      "[50/59] Date: 2024-02-29\n",
      "  Window: 2009-02-28 to 2024-01-31\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.02377 | Turnover: 0.0449 | TC: 0.000046 | Net:  0.02373\n",
      "\n",
      "[51/59] Date: 2024-03-31\n",
      "  Window: 2009-03-31 to 2024-02-29\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.04315 | Turnover: 0.0418 | TC: 0.000040 | Net: -0.04319\n",
      "\n",
      "[52/59] Date: 2024-04-30\n",
      "  Window: 2009-04-30 to 2024-03-31\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.02293 | Turnover: 0.0527 | TC: 0.000054 | Net:  0.02288\n",
      "\n",
      "[53/59] Date: 2024-05-31\n",
      "  Window: 2009-05-31 to 2024-04-30\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.00089 | Turnover: 0.0644 | TC: 0.000064 | Net: -0.00095\n",
      "\n",
      "[54/59] Date: 2024-06-30\n",
      "  Window: 2009-06-30 to 2024-05-31\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.03749 | Turnover: 0.0397 | TC: 0.000041 | Net:  0.03745\n",
      "\n",
      "[55/59] Date: 2024-07-31\n",
      "  Window: 2009-07-31 to 2024-06-30\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.04116 | Turnover: 0.0623 | TC: 0.000065 | Net:  0.04109\n",
      "\n",
      "[56/59] Date: 2024-08-31\n",
      "  Window: 2009-08-31 to 2024-07-31\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.01511 | Turnover: 0.0464 | TC: 0.000047 | Net:  0.01506\n",
      "\n",
      "[57/59] Date: 2024-09-30\n",
      "  Window: 2009-09-30 to 2024-08-31\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.02957 | Turnover: 0.0398 | TC: 0.000039 | Net: -0.02961\n",
      "\n",
      "[58/59] Date: 2024-10-31\n",
      "  Window: 2009-10-31 to 2024-09-30\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross:  0.03492 | Turnover: 0.0437 | TC: 0.000045 | Net:  0.03487\n",
      "\n",
      "[59/59] Date: 2024-11-30\n",
      "  Window: 2009-11-30 to 2024-10-31\n",
      "  Assets: 42 with complete data\n",
      "  Running Nodewise Regression...\n",
      "  Computing GMV weights...\n",
      "  Gross: -0.05716 | Turnover: 0.0626 | TC: 0.000059 | Net: -0.05722\n",
      "\n",
      "============================================================\n",
      "BACKTEST COMPLETE\n",
      "============================================================\n",
      "Sharpe Ratio: 0.1398\n",
      "Annualized Sharpe Ratio: 0.4842\n"
     ]
    }
   ],
   "source": [
    "results_df, metrics = backtest_nodewise_gmv(\n",
    "    df_filtered,\n",
    "    test_start_date='2020-01-31',  # Last date of training period\n",
    "    test_end_date='2024-11-30',   # Last date of testing period\n",
    "    lookback_window=180,\n",
    "    transaction_cost=0.001\n",
    ")\n",
    "print(f\"Sharpe Ratio: {metrics['sharpe_ratio']:.4f}\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics['annual_sharpe_ratio']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2d90d2-6bb7-4fad-b1a4-34568f670356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
