{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10109b0e-ccfe-416e-8832-4f4694a89296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mv_weights(Theta_hat, mu, target_return=0.01):\n",
    "    \"\"\"\n",
    "    Compute Mean-Variance portfolio weights with target return.\n",
    "    \n",
    "    Solves the constrained optimization:\n",
    "    min w' Sigma w  subject to  w' mu = target_return  and  w' 1 = 1\n",
    "    \n",
    "    Solution uses Lagrange multipliers with two constraints.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix (Sigma^{-1})\n",
    "    mu : np.ndarray, shape (p,)\n",
    "        Expected returns\n",
    "    target_return : float\n",
    "        Target portfolio return (default: 0.01 = 1% monthly)\n",
    "    long_only : bool\n",
    "        If True, falls back to GMV if MV produces negative weights\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # Compute key quantities\n",
    "    A = ones_p @ Theta_hat @ ones_p  # 1' Theta 1\n",
    "    B = ones_p @ Theta_hat @ mu       # 1' Theta mu  \n",
    "    C = mu @ Theta_hat @ mu           # mu' Theta mu\n",
    "    D = A * C - B * B                  # Determinant\n",
    "    \n",
    "    # Check for singularity\n",
    "    if np.abs(D) < 1e-10:\n",
    "        print('SINGULARITY')\n",
    "        # System is singular, use GMV instead\n",
    "        if np.abs(A) > 1e-10:\n",
    "            w_star = (Theta_hat @ ones_p) / A\n",
    "            return w_star\n",
    "        else:\n",
    "            return ones_p / p\n",
    "    \n",
    "    \n",
    "    # Compute Lagrange multipliers\n",
    "    lambda1 = (C - B * target_return) / D\n",
    "    lambda2 = (A * target_return - B) / D\n",
    "    \n",
    "    # Compute weights: w = lambda1 * Theta^{-1} 1 + lambda2 * Theta^{-1} mu\n",
    "    w_star = lambda1 * (Theta_hat @ ones_p) + lambda2 * (Theta_hat @ mu)\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "def msr_weights(Theta_hat, mu):\n",
    "    \"\"\"\n",
    "    Compute Maximum Sharpe Ratio portfolio weights.\n",
    "    \n",
    "    The maximum Sharpe ratio portfolio solves:\n",
    "    max (w' mu) / sqrt(w' Sigma w)\n",
    "    \n",
    "    Solution (when mu represents excess returns):\n",
    "    w ∝ Sigma^{-1} mu = Theta mu\n",
    "    \n",
    "    Then normalize so that sum(w) = 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix (Sigma^{-1})\n",
    "    mu : np.ndarray, shape (p,)\n",
    "        Expected excess returns\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights (sum to 1)\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # Compute unnormalized weights: w ∝ Theta mu\n",
    "    w_unnorm = Theta_hat @ mu\n",
    "    \n",
    "    # Normalize to sum to 1\n",
    "    weight_sum = np.sum(w_unnorm)\n",
    "    \n",
    "    if np.abs(weight_sum) < 1e-10:\n",
    "        print('WARNING: Weight sum near zero, returning equal weights')\n",
    "        return ones_p / p\n",
    "    \n",
    "    w_star = w_unnorm / weight_sum\n",
    "    \n",
    "    return w_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc7b474f-d8c0-4704-89a1-525bfc76f353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, LassoCV, LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def train_logistic_regression(df, train_start, train_end, features=['mom12m', 'mve', 'bm']):\n",
    "    \"\"\"\n",
    "    Train logistic regression on historical data to predict positive returns.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Full dataset with features and returns\n",
    "    train_start : str or pd.Timestamp\n",
    "        Start date for training window\n",
    "    train_end : str or pd.Timestamp\n",
    "        End date for training window\n",
    "    features : list\n",
    "        List of feature column names\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    log_reg : LogisticRegression\n",
    "        Trained model\n",
    "    scaler : StandardScaler\n",
    "        Fitted scaler for features\n",
    "    \"\"\"\n",
    "    train_df = df[(df['datadate'] >= train_start) & (df['datadate'] <= train_end)].copy()\n",
    "    \n",
    "    # Create binary target: 1 if positive return, 0 otherwise\n",
    "    train_df['target'] = (train_df['ret_fwd_1'] > 0).astype(int)\n",
    "    \n",
    "    # Remove rows with missing values\n",
    "    train_df = train_df.dropna(subset=features + ['target'])\n",
    "    \n",
    "    # Prepare features\n",
    "    X_train = train_df[features]\n",
    "    y_train = train_df['target']\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Train logistic regression\n",
    "    log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    log_reg.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(f\"  Training samples: {len(train_df)}\")\n",
    "    print(f\"  Training accuracy: {log_reg.score(X_train_scaled, y_train):.4f}\")\n",
    "    \n",
    "    return log_reg, scaler\n",
    "\n",
    "\n",
    "def select_stocks_with_logistic(df, predict_date, log_reg, scaler, \n",
    "                                 features=['mom12m', 'mve', 'bm'],\n",
    "                                 method='top_n', n_stocks=100, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Use trained logistic regression to select stocks for a given date.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Full dataset\n",
    "    predict_date : str or pd.Timestamp\n",
    "        Date to generate predictions for\n",
    "    log_reg : LogisticRegression\n",
    "        Trained model\n",
    "    scaler : StandardScaler\n",
    "        Fitted scaler\n",
    "    features : list\n",
    "        List of feature column names\n",
    "    method : str\n",
    "        Selection method: 'top_n', 'threshold', or 'top_and_bottom'\n",
    "    n_stocks : int\n",
    "        Number of stocks to select (used if method='top_n' or 'top_and_bottom')\n",
    "    threshold : float\n",
    "        Probability threshold (used if method='threshold')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    selected_permnos : list\n",
    "        List of selected PERMNOs\n",
    "    \"\"\"\n",
    "    predict_df = df[df['datadate'] == predict_date].copy()\n",
    "    predict_df = predict_df.dropna(subset=features)\n",
    "    \n",
    "    if len(predict_df) == 0:\n",
    "        print(f\"  ⚠ No stocks with complete data on {predict_date}\")\n",
    "        return []\n",
    "    \n",
    "    # Prepare features for prediction\n",
    "    X_predict = predict_df[features]\n",
    "    X_predict_scaled = scaler.transform(X_predict)\n",
    "    \n",
    "    # Generate buy probabilities\n",
    "    predict_df['buy_probability'] = log_reg.predict_proba(X_predict_scaled)[:, 1]\n",
    "    \n",
    "    # Select stocks based on method\n",
    "    if method == 'top_n':\n",
    "        selected_df = predict_df.nlargest(n_stocks, 'buy_probability')\n",
    "    elif method == 'top_and_bottom':\n",
    "        top_n = predict_df.nlargest(n_stocks, 'buy_probability')\n",
    "        bottom_n = predict_df.nsmallest(n_stocks, 'buy_probability')\n",
    "        selected_df = pd.concat([top_n, bottom_n])\n",
    "    elif method == 'threshold':\n",
    "        selected_df = predict_df[predict_df['buy_probability'] >= threshold]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    selected_permnos = selected_df['permno'].tolist()\n",
    "    \n",
    "    print(f\"  Stocks evaluated: {len(predict_df)}\")\n",
    "    print(f\"  Stocks selected: {len(selected_permnos)}\")\n",
    "    print(f\"  Buy probability range: [{predict_df['buy_probability'].min():.4f}, \"\n",
    "          f\"{predict_df['buy_probability'].max():.4f}]\")\n",
    "    \n",
    "    return selected_permnos\n",
    "\n",
    "\n",
    "def est_ndwcov_factor(Y, factors, ic, lambda_min=True):\n",
    "    \"\"\"\n",
    "    Estimate nodewise covariance with factor models using LASSO.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Y : numpy.ndarray\n",
    "        n x p matrix of observations\n",
    "    factors : numpy.ndarray\n",
    "        n x k matrix of factors\n",
    "    ic : str\n",
    "        Information criterion: 'WIC', 'BIC', 'GIC', 'AIC', or 'cv'\n",
    "    lambda_min : bool\n",
    "        If True and ic='cv', use lambda.min; otherwise use lambda.1se\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    TAU : numpy.ndarray\n",
    "        p x p precision matrix estimate\n",
    "    \"\"\"\n",
    "    # Initialization\n",
    "    p = Y.shape[1]\n",
    "    n = Y.shape[0]\n",
    "    C = np.zeros((p, p))\n",
    "    np.fill_diagonal(C, 1)\n",
    "    tau = []\n",
    "    ns1 = np.ones((n, 1))\n",
    "    \n",
    "    # Fit factor model: Y = factors * beta + u\n",
    "    # Add intercept to factors\n",
    "    factors_with_intercept = np.column_stack([np.ones(n), factors])\n",
    "    \n",
    "    # Fit linear regression for each column of Y\n",
    "    factormodel = LinearRegression(fit_intercept=False)\n",
    "    factormodel.fit(factors_with_intercept, Y)\n",
    "    \n",
    "    # Get residuals and beta coefficients (excluding intercept)\n",
    "    u = Y - factormodel.predict(factors_with_intercept)\n",
    "    beta = factormodel.coef_[:, 1:]  # p x k matrix (excluding intercept)\n",
    "    \n",
    "    # Loop over the assets\n",
    "    for j in range(p):\n",
    "        # Create design matrix excluding column j\n",
    "        X_j = np.delete(u, j, axis=1)\n",
    "        y_j = u[:, j]\n",
    "        \n",
    "        if ic != 'cv':\n",
    "            # Fit LASSO path\n",
    "            alphas = np.logspace(-4, 1, 100)  # Create lambda sequence\n",
    "            df_list = []\n",
    "            sig_list = []\n",
    "            bic_list = []\n",
    "            coef_list = []\n",
    "            res_list = []\n",
    "            \n",
    "            for alpha in alphas:\n",
    "                model = Lasso(alpha=alpha, fit_intercept=False, max_iter=10000)\n",
    "                model.fit(X_j, y_j)\n",
    "                \n",
    "                # Predictions and residuals\n",
    "                y_pred = model.predict(X_j)\n",
    "                res = y_j - y_pred\n",
    "                \n",
    "                # Degrees of freedom (number of non-zero coefficients)\n",
    "                df = np.sum(np.abs(model.coef_) > 1e-8)\n",
    "                \n",
    "                # Variance of residuals\n",
    "                sig = np.sum(res**2) / n\n",
    "                \n",
    "                # Compute information criterion\n",
    "                if ic == 'WIC':\n",
    "                    bic_val = np.log(sig) + df * np.log(n) / n * np.log(np.log(p))\n",
    "                elif ic == 'BIC':\n",
    "                    bic_val = np.log(sig) + df * np.log(n) / n\n",
    "                elif ic == 'GIC':\n",
    "                    bic_val = np.log(sig) + df * np.log(p) * np.log(np.log(n)) / n\n",
    "                elif ic == 'AIC':\n",
    "                    bic_val = np.log(sig) + 2 * df\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown IC: {ic}\")\n",
    "                \n",
    "                df_list.append(df)\n",
    "                sig_list.append(sig)\n",
    "                bic_list.append(bic_val)\n",
    "                coef_list.append(model.coef_.copy())\n",
    "                res_list.append(res)\n",
    "            \n",
    "            # Select model with minimum IC\n",
    "            jind = np.argmin(bic_list)\n",
    "            jpar = coef_list[jind]\n",
    "            jres = res_list[jind]\n",
    "            jtau = np.sum(y_j * jres) / n\n",
    "            \n",
    "        else:  # Cross-validation\n",
    "            lasso_cv = LassoCV(cv=5, fit_intercept=False, max_iter=10000, n_alphas=100)\n",
    "            lasso_cv.fit(X_j, y_j)\n",
    "            \n",
    "            if lambda_min:\n",
    "                # Use alpha that minimizes CV error (lambda.min equivalent)\n",
    "                jfit = lasso_cv.predict(X_j)\n",
    "                jpar = lasso_cv.coef_\n",
    "            else:\n",
    "                # Use alpha within 1 SE of minimum (lambda.1se equivalent)\n",
    "                cv_scores = lasso_cv.mse_path_.mean(axis=1)\n",
    "                cv_std = lasso_cv.mse_path_.std(axis=1)\n",
    "                min_idx = np.argmin(cv_scores)\n",
    "                threshold = cv_scores[min_idx] + cv_std[min_idx]\n",
    "                \n",
    "                # Find largest alpha with CV score below threshold\n",
    "                valid_indices = np.where(cv_scores <= threshold)[0]\n",
    "                se_idx = valid_indices[0] if len(valid_indices) > 0 else min_idx\n",
    "                \n",
    "                selected_alpha = lasso_cv.alphas_[se_idx]\n",
    "                model_1se = Lasso(alpha=selected_alpha, fit_intercept=False, max_iter=10000)\n",
    "                model_1se.fit(X_j, y_j)\n",
    "                jfit = model_1se.predict(X_j)\n",
    "                jpar = model_1se.coef_\n",
    "            \n",
    "            jres = y_j - jfit\n",
    "            jtau = np.sum(y_j * jres) / n\n",
    "        \n",
    "        # Fill in C matrix\n",
    "        # Insert coefficients back (accounting for missing j-th position)\n",
    "        C_row = np.insert(-jpar / jtau, j, 0)\n",
    "        C[j, :] = C_row\n",
    "        tau.append(jtau)\n",
    "    \n",
    "    # Set diagonal\n",
    "    np.fill_diagonal(C, 1 / np.array(tau))\n",
    "    omega = C.copy()\n",
    "    omegasym = (C + C.T) / 2\n",
    "    \n",
    "    # Compute factor covariance - ensure float64\n",
    "    covft = (1/n) * (factors.T @ factors) - (1/(n**2)) * (factors.T @ ns1 @ ns1.T @ factors)\n",
    "    covft = covft.astype(np.float64)\n",
    "    \n",
    "    # Ensure beta and omegasym are float64\n",
    "    beta = beta.astype(np.float64)\n",
    "    omegasym = omegasym.astype(np.float64)\n",
    "    \n",
    "\n",
    "    covft_inv = np.linalg.inv(covft)\n",
    "    p1 = np.linalg.inv(covft_inv + beta.T @ omegasym @ beta)\n",
    "    TAU = omega - omega @ beta @ p1 @ beta.T @ omega\n",
    "    \n",
    "    return TAU\n",
    "\n",
    "\n",
    "def gmv_weights(Theta_hat):\n",
    "    \"\"\"\n",
    "    Compute Global Minimum Variance portfolio weights.\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    numerator = Theta_hat @ ones_p\n",
    "    denominator = ones_p @ Theta_hat @ ones_p\n",
    "    \n",
    "    if np.abs(denominator) < 1e-10:\n",
    "        return ones_p / p\n",
    "    \n",
    "    w_star = numerator / denominator\n",
    "    return w_star\n",
    "\n",
    "def load_ff_factors(factors_path='factors_ff_monthly_raw.csv'):\n",
    "    \"\"\"\n",
    "    Load Fama-French factors from CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    factors_path : str\n",
    "        Path to the factors CSV file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    factors_df : pd.DataFrame\n",
    "        DataFrame with date index and factor columns\n",
    "    \"\"\"\n",
    "    factors_df = pd.read_csv(factors_path)\n",
    "    \n",
    "    # Convert month column (e.g., 192707) to datetime\n",
    "    # This gives us the first day of the month (1927-07-01)\n",
    "    factors_df['date'] = pd.to_datetime(factors_df.iloc[:, 0].astype(str), format='%Y%m')\n",
    "    \n",
    "    # Convert to end of month to match returns data\n",
    "    factors_df['date'] = factors_df['date'] + pd.offsets.MonthEnd(0)\n",
    "    \n",
    "    # Set date as index and keep only factor columns\n",
    "    factors_df = factors_df.set_index('date')[['Mkt-RF', 'SMB', 'HML']]\n",
    "    \n",
    "    # Convert to decimal form (assuming factors are in percentage points)\n",
    "    factors_df = factors_df / 100\n",
    "    \n",
    "    return factors_df\n",
    "\n",
    "def integrated_backtest(df,\n",
    "                        factors_path='factors_ff_monthly_raw.csv',\n",
    "                        ic='GIC',\n",
    "                       test_start_date='2020-01-31',\n",
    "                       test_end_date='2024-04-30',\n",
    "                       logistic_train_years=15,\n",
    "                       logistic_features=['mom12m', 'mve', 'bm'],\n",
    "                       stock_selection_method='top_n',\n",
    "                       n_stocks=100,\n",
    "                       lookback_window=180,\n",
    "                       transaction_cost=0.005,\n",
    "                       portfolio_type='all',  # 'gmv', 'mv', 'msr', or 'all'\n",
    "                       mv_target_return=0.01,\n",
    "                       verbose=True):\n",
    "    \"\"\"\n",
    "    Integrated backtest combining logistic regression stock selection \n",
    "    with nodewise regression portfolio optimization.\n",
    "    \n",
    "    Annual workflow:\n",
    "    1. Train logistic regression on past 15 years (every January)\n",
    "    2. Select stocks based on buy probability\n",
    "    3. Run nodewise regression on selected stocks monthly until next retrain\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Full dataset with columns: datadate, permno, ret_fwd_1, mom12m, mve, bm\n",
    "    test_start_date : str\n",
    "        Start date for testing (format: 'YYYY-MM-DD')\n",
    "    test_end_date : str\n",
    "        End date for testing (format: 'YYYY-MM-DD')\n",
    "    logistic_train_years : int\n",
    "        Number of years to use for training logistic regression\n",
    "    logistic_features : list\n",
    "        Features for logistic regression\n",
    "    stock_selection_method : str\n",
    "        'top_n', 'threshold', or 'top_and_bottom'\n",
    "    n_stocks : int\n",
    "        Number of stocks to select\n",
    "    lookback_window : int\n",
    "        Number of months for nodewise regression rolling window\n",
    "    transaction_cost : float\n",
    "        Proportional transaction cost\n",
    "    portfolio_type : str\n",
    "        'gmv', 'mv', 'msr', or 'all' (compute all three portfolios)\n",
    "    mv_target_return : float\n",
    "        Target return for MV portfolio (default: 0.01 = 1% monthly)\n",
    "    verbose : bool\n",
    "        Print detailed logs\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results_dict : dict\n",
    "        Dictionary with keys 'gmv', 'mv', 'msr' (depending on portfolio_type)\n",
    "        Each contains: {'results_df': DataFrame, 'metrics': dict}\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['datadate'] = pd.to_datetime(df['datadate'])\n",
    "\n",
    "    # Load Fama-French factors\n",
    "    factors_df = load_ff_factors(factors_path)\n",
    "    \n",
    "    all_dates = sorted(df['datadate'].unique())\n",
    "    \n",
    "    # Parse test dates\n",
    "    test_start_dt = pd.to_datetime(test_start_date)\n",
    "    test_end_dt = pd.to_datetime(test_end_date)\n",
    "    \n",
    "    # Extract years that need logistic regression retraining (every January in test period)\n",
    "    start_year = test_start_dt.year\n",
    "    end_year = test_end_dt.year\n",
    "    test_years = list(range(start_year, end_year + 1))\n",
    "    \n",
    "    # Determine which portfolios to compute\n",
    "    if portfolio_type == 'all':\n",
    "        portfolio_types = ['gmv', 'mv', 'msr']\n",
    "    else:\n",
    "        portfolio_types = [portfolio_type]\n",
    "    \n",
    "    # Storage for each portfolio type\n",
    "    results_storage = {ptype: {\n",
    "        'returns': [],\n",
    "        'dates': [],\n",
    "        'weights_list': [],\n",
    "        'turnover_list': [],\n",
    "        'gross_returns': [],\n",
    "        'prev_weights_dict': {},\n",
    "        'prev_oos_returns_dict': {},\n",
    "        'prev_gross_return': 0.0\n",
    "    } for ptype in portfolio_types}\n",
    "    \n",
    "    # Track current stock universe\n",
    "    current_permnos = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"=\"*70)\n",
    "        print(\"INTEGRATED BACKTEST: LOGISTIC REGRESSION + NODEWISE\")\n",
    "        print(f\"Test Period: {test_start_date} to {test_end_date}\")\n",
    "        print(\"=\"*70)\n",
    "    \n",
    "    for year in test_years:\n",
    "        # Retrain logistic regression in January\n",
    "        retrain_date = pd.to_datetime(f'{year}-01-31')\n",
    "        \n",
    "        if retrain_date not in all_dates:\n",
    "            print(f\"\\n⚠ Warning: {retrain_date} not in dataset, skipping year {year}\")\n",
    "            continue\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"YEAR {year}: RETRAINING LOGISTIC REGRESSION\")\n",
    "            print(f\"{'='*70}\")\n",
    "        \n",
    "        # Define training window for logistic regression\n",
    "        train_end = pd.to_datetime(f'{year-1}-12-31')\n",
    "        train_start = pd.to_datetime(f'{year - logistic_train_years}-01-31')\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Logistic training period: {train_start.strftime('%Y-%m-%d')} to \"\n",
    "                  f\"{train_end.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        # Train logistic regression\n",
    "        log_reg, scaler = train_logistic_regression(\n",
    "            df, train_start, train_end, features=logistic_features\n",
    "        )\n",
    "        \n",
    "        # Select stocks for this year\n",
    "        current_permnos = select_stocks_with_logistic(\n",
    "            df, retrain_date, log_reg, scaler,\n",
    "            features=logistic_features,\n",
    "            method=stock_selection_method,\n",
    "            n_stocks=n_stocks\n",
    "        )\n",
    "        \n",
    "        if len(current_permnos) == 0:\n",
    "            print(f\"  ⚠ No stocks selected for {year}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        # Determine date range for this year\n",
    "        year_start_date = retrain_date\n",
    "        \n",
    "        # Determine end date for this year's strategy\n",
    "        if year == end_year:\n",
    "            # Last year: use test_end_date\n",
    "            year_end_date = test_end_dt\n",
    "        else:\n",
    "            # Use December of current year\n",
    "            year_end_date = pd.to_datetime(f'{year}-12-31')\n",
    "            if year_end_date not in all_dates:\n",
    "                # Find last available date in this year\n",
    "                year_dates = [d for d in all_dates if d.year == year]\n",
    "                year_end_date = max(year_dates) if year_dates else year_start_date\n",
    "        \n",
    "        # For the first year, respect test_start_date\n",
    "        if year == start_year and test_start_dt > year_start_date:\n",
    "            year_start_date = test_start_dt\n",
    "        \n",
    "        try:\n",
    "            year_start_idx = all_dates.index(year_start_date)\n",
    "            year_end_idx = all_dates.index(year_end_date)\n",
    "        except ValueError as e:\n",
    "            print(f\"  ⚠ Date error: {e}\")\n",
    "            continue\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nRunning monthly rebalancing from {year_start_date.strftime('%Y-%m-%d')} \"\n",
    "                  f\"to {year_end_date.strftime('%Y-%m-%d')}\")\n",
    "            print(f\"{'='*70}\")\n",
    "        \n",
    "        # Monthly loop for this year\n",
    "        for t in range(year_start_idx, year_end_idx + 1):\n",
    "            current_date = all_dates[t]\n",
    "            \n",
    "            if t < lookback_window:\n",
    "                if verbose:\n",
    "                    print(f\"\\n[{current_date.strftime('%Y-%m-%d')}] \"\n",
    "                          f\"Skipping: insufficient lookback\")\n",
    "                continue\n",
    "            \n",
    "            # Define training window\n",
    "            window_start_date = all_dates[t - lookback_window]\n",
    "            window_end_date = all_dates[t - 1]\n",
    "            \n",
    "            # Filter data to selected stocks only\n",
    "            train_data = df[\n",
    "                (df['datadate'] >= window_start_date) & \n",
    "                (df['datadate'] <= window_end_date) &\n",
    "                (df['permno'].isin(current_permnos))\n",
    "            ]\n",
    "            \n",
    "            # Pivot returns\n",
    "            returns_pivot = train_data.pivot(\n",
    "                index='datadate', columns='permno', values='ret_fwd_1'\n",
    "            )\n",
    "            \n",
    "            # Reindex to ensure all dates\n",
    "            window_dates = all_dates[t - lookback_window : t]\n",
    "            returns_pivot = returns_pivot.reindex(index=window_dates)\n",
    "\n",
    "            # Align factors with return realization dates\n",
    "            factor_dates = [(d + pd.DateOffset(months=1) + pd.offsets.MonthEnd(0)) for d in window_dates]\n",
    "            \n",
    "            try:\n",
    "                factors_window = factors_df.loc[factor_dates]\n",
    "            except KeyError as e:\n",
    "                raise ValueError(f\"Factor dates not found in factors file. Missing dates: {e}\")\n",
    "            \n",
    "            if factors_window.isna().any().any():\n",
    "                if verbose:\n",
    "                    print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                          f\"Date: {current_date.strftime('%Y-%m-%d')}\")\n",
    "                    print(f\"  ⚠ Missing factor data in window, skipping period\")\n",
    "                continue\n",
    "            \n",
    "            # Filter assets with any NaNs\n",
    "            nan_assets = returns_pivot.columns[returns_pivot.isna().any()]\n",
    "            filtered_pivot = returns_pivot.drop(columns=nan_assets)\n",
    "            \n",
    "            current_assets = filtered_pivot.columns.tolist()\n",
    "            Y = filtered_pivot.values\n",
    "            factors = factors_window.values\n",
    "            n_train, p_current = Y.shape\n",
    "            \n",
    "            if verbose:\n",
    "                month_num = t - year_start_idx + 1\n",
    "                print(f\"\\n[Month {month_num}] {current_date.strftime('%Y-%m-%d')}\")\n",
    "                print(f\"  Assets: {p_current}/{len(current_permnos)} with complete data\")\n",
    "            \n",
    "            # Check validity\n",
    "            if n_train < lookback_window or p_current < 2:\n",
    "                if verbose:\n",
    "                    print(f\"  ⚠ Insufficient data, using previous weights\")\n",
    "                \n",
    "                # Use previous weights for all portfolio types\n",
    "                new_weights_dict = {ptype: results_storage[ptype]['prev_weights_dict'].copy() \n",
    "                                   for ptype in portfolio_types}\n",
    "            else:\n",
    "                try:\n",
    "                    # Demean\n",
    "                    Y_bar = Y.mean(axis=0)\n",
    "                    Y_star = Y - Y_bar\n",
    "                    \n",
    "                    # Run nodewise regression\n",
    "                    Theta_hat = est_ndwcov_factor(Y, factors, ic=ic, lambda_min=True)\n",
    "                    \n",
    "                    # Compute weights for each portfolio type\n",
    "                    new_weights_dict = {}\n",
    "                    \n",
    "                    if 'gmv' in portfolio_types:\n",
    "                        w_gmv = gmv_weights(Theta_hat)\n",
    "                        new_weights_dict['gmv'] = {\n",
    "                            asset: w_gmv[i] for i, asset in enumerate(current_assets)\n",
    "                        }\n",
    "                    \n",
    "                    if 'mv' in portfolio_types or 'msr' in portfolio_types:\n",
    "                        # Need expected returns (use sample mean from training window)\n",
    "                        mu = Y_bar\n",
    "                        \n",
    "                        if 'mv' in portfolio_types:\n",
    "                            w_mv = mv_weights(Theta_hat, mu, target_return=mv_target_return)\n",
    "                            new_weights_dict['mv'] = {\n",
    "                                asset: w_mv[i] for i, asset in enumerate(current_assets)\n",
    "                            }\n",
    "                        \n",
    "                        if 'msr' in portfolio_types:\n",
    "                            w_msr = msr_weights(Theta_hat, mu)\n",
    "                            new_weights_dict['msr'] = {\n",
    "                                asset: w_msr[i] for i, asset in enumerate(current_assets)\n",
    "                            }\n",
    "                    \n",
    "                    if verbose:\n",
    "                        print(f\"  ✓ Nodewise completed for {', '.join(portfolio_types)}\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    if verbose:\n",
    "                        print(f\"  ✗ Error: {e}\")\n",
    "                    new_weights_dict = {ptype: results_storage[ptype]['prev_weights_dict'].copy() \n",
    "                                       for ptype in portfolio_types}\n",
    "            \n",
    "            # Process each portfolio type\n",
    "            for ptype in portfolio_types:\n",
    "                # Normalize weights\n",
    "                weights = new_weights_dict[ptype]\n",
    "                weight_sum = sum(weights.values())\n",
    "                if weight_sum > 1e-10:\n",
    "                    weights = {k: v/weight_sum for k, v in weights.items()}\n",
    "                else:\n",
    "                    weights = results_storage[ptype]['prev_weights_dict'].copy()\n",
    "            \n",
    "            # Get OOS returns (common for all portfolio types)\n",
    "            oos_data = df[df['datadate'] == current_date]\n",
    "            oos_returns_series = oos_data.set_index('permno')['ret_fwd_1'].dropna()\n",
    "            oos_returns_dict = oos_returns_series.to_dict()\n",
    "            \n",
    "            # Process each portfolio type\n",
    "            for ptype in portfolio_types:\n",
    "                # Get weights for this portfolio\n",
    "                weights = new_weights_dict[ptype]\n",
    "                prev_weights = results_storage[ptype]['prev_weights_dict']\n",
    "                prev_oos_returns = results_storage[ptype]['prev_oos_returns_dict']\n",
    "                prev_gross_ret = results_storage[ptype]['prev_gross_return']\n",
    "                \n",
    "                # Common assets\n",
    "                common_assets = set(weights.keys()) & set(oos_returns_dict.keys())\n",
    "                \n",
    "                if len(common_assets) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Filter and renormalize\n",
    "                common_weights = {a: weights[a] for a in common_assets}\n",
    "                common_weight_sum = sum(common_weights.values())\n",
    "                if common_weight_sum > 1e-10:\n",
    "                    common_weights = {k: v/common_weight_sum for k, v in common_weights.items()}\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                # Gross return\n",
    "                gross_return = sum(\n",
    "                    common_weights[a] * oos_returns_dict[a] for a in common_assets\n",
    "                )\n",
    "                \n",
    "                if np.isnan(gross_return) or np.isinf(gross_return):\n",
    "                    continue\n",
    "                \n",
    "                # Transaction costs\n",
    "                if len(prev_weights) > 0:\n",
    "                    adjusted_prev = {}\n",
    "                    for asset, prev_w in prev_weights.items():\n",
    "                        if asset in prev_oos_returns:\n",
    "                            prev_r = prev_oos_returns[asset]\n",
    "                            if abs(1 + prev_gross_ret) > 1e-6:\n",
    "                                adjusted_prev[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_ret)\n",
    "                            else:\n",
    "                                adjusted_prev[asset] = 0.0\n",
    "                        else:\n",
    "                            if abs(1 + prev_gross_ret) > 1e-6:\n",
    "                                adjusted_prev[asset] = prev_w / (1 + prev_gross_ret)\n",
    "                            else:\n",
    "                                adjusted_prev[asset] = 0.0\n",
    "                    \n",
    "                    all_assets = set(adjusted_prev.keys()) | set(common_weights.keys())\n",
    "                    turnover = sum(\n",
    "                        abs(common_weights.get(a, 0.0) - adjusted_prev.get(a, 0.0))\n",
    "                        for a in all_assets\n",
    "                    )\n",
    "                    tc = transaction_cost * (1 + gross_return) * turnover\n",
    "                else:\n",
    "                    turnover = sum(abs(w) for w in common_weights.values())\n",
    "                    tc = transaction_cost * (1 + gross_return) * turnover\n",
    "                \n",
    "                net_return = gross_return - tc\n",
    "                \n",
    "                # Store results for this portfolio\n",
    "                results_storage[ptype]['returns'].append(net_return)\n",
    "                results_storage[ptype]['dates'].append(current_date)\n",
    "                results_storage[ptype]['weights_list'].append(common_weights.copy())\n",
    "                results_storage[ptype]['turnover_list'].append(turnover)\n",
    "                results_storage[ptype]['gross_returns'].append(gross_return)\n",
    "                \n",
    "                # Update state\n",
    "                results_storage[ptype]['prev_weights_dict'] = common_weights.copy()\n",
    "                results_storage[ptype]['prev_oos_returns_dict'] = {a: oos_returns_dict[a] for a in common_assets}\n",
    "                results_storage[ptype]['prev_gross_return'] = gross_return\n",
    "            \n",
    "            if verbose:\n",
    "                # Print summary for all portfolios\n",
    "                print(f\"  Portfolio Returns:\")\n",
    "                for ptype in portfolio_types:\n",
    "                    if len(results_storage[ptype]['returns']) > 0:\n",
    "                        last_idx = len(results_storage[ptype]['returns']) - 1\n",
    "                        gross_ret = results_storage[ptype]['gross_returns'][last_idx]\n",
    "                        net_ret = results_storage[ptype]['returns'][last_idx]\n",
    "                        to = results_storage[ptype]['turnover_list'][last_idx]\n",
    "                        tc = gross_ret - net_ret\n",
    "                        print(f\"    {ptype.upper()}: Gross={gross_ret:>7.4f} | TO={to:>5.3f} | \"\n",
    "                              f\"TC={tc:>7.5f} | Net={net_ret:>7.4f}\")\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"BACKTEST COMPLETE\")\n",
    "        print(\"=\"*70)\n",
    "    \n",
    "    # Compile results for each portfolio type\n",
    "    results_dict = {}\n",
    "    \n",
    "    for ptype in portfolio_types:\n",
    "        portfolio_returns = results_storage[ptype]['returns']\n",
    "        portfolio_dates = results_storage[ptype]['dates']\n",
    "        portfolio_turnover_list = results_storage[ptype]['turnover_list']\n",
    "        portfolio_gross_returns = results_storage[ptype]['gross_returns']\n",
    "        \n",
    "        if len(portfolio_returns) == 0:\n",
    "            results_dict[ptype] = {\n",
    "                'results_df': pd.DataFrame(),\n",
    "                'metrics': {}\n",
    "            }\n",
    "            continue\n",
    "        \n",
    "        results_df = pd.DataFrame({\n",
    "            'date': portfolio_dates,\n",
    "            'portfolio_return': portfolio_returns,\n",
    "            'portfolio_gross_return': portfolio_gross_returns,\n",
    "            'portfolio_turnover': portfolio_turnover_list\n",
    "        })\n",
    "        results_df['cumulative_return'] = (1 + results_df['portfolio_return']).cumprod() - 1\n",
    "        \n",
    "        # Overall metrics\n",
    "        mean_return = np.mean(portfolio_returns)\n",
    "        variance = np.var(portfolio_returns, ddof=1)\n",
    "        sharpe_ratio = mean_return / np.sqrt(variance) if variance > 0 else 0\n",
    "        \n",
    "        annual_return = mean_return * 12\n",
    "        annual_volatility = np.sqrt(variance * 12)\n",
    "        annual_sharpe = annual_return / annual_volatility if annual_volatility > 0 else 0\n",
    "        \n",
    "        overall_metrics = {\n",
    "            'mean_return': mean_return,\n",
    "            'variance': variance,\n",
    "            'sharpe_ratio': sharpe_ratio,\n",
    "            'annual_return': annual_return,\n",
    "            'annual_volatility': annual_volatility,\n",
    "            'annual_sharpe_ratio': annual_sharpe,\n",
    "            'total_return': results_df['cumulative_return'].iloc[-1],\n",
    "            'avg_turnover': np.mean(portfolio_turnover_list),\n",
    "            'n_periods': len(portfolio_returns)\n",
    "        }\n",
    "        \n",
    "        results_dict[ptype] = {\n",
    "            'results_df': results_df,\n",
    "            'metrics': overall_metrics\n",
    "        }\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0173714-8360-4647-b99f-b4ab978f90fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../green cleaned.csv', dtype={'ncusip': 'string'})\n",
    "df['ret_fwd_1'] = (df.groupby('permno')['ret_excess'].shift(-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3214ecb5-84c1-4220-8bd7-88d7be06b616",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INTEGRATED BACKTEST: LOGISTIC REGRESSION + NODEWISE\n",
      "Test Period: 2020-01-31 to 2024-04-30\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "YEAR 2020: RETRAINING LOGISTIC REGRESSION\n",
      "======================================================================\n",
      "Logistic training period: 2005-01-31 to 2019-12-31\n",
      "  Training samples: 89793\n",
      "  Training accuracy: 0.5590\n",
      "  Stocks evaluated: 497\n",
      "  Stocks selected: 100\n",
      "  Buy probability range: [0.5322, 0.5826]\n",
      "\n",
      "Running monthly rebalancing from 2020-01-31 to 2020-12-31\n",
      "======================================================================\n",
      "\n",
      "[Month 1] 2020-01-31\n",
      "  Assets: 64/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0861 | TO=1.910 | TC=0.00175 | Net=-0.0878\n",
      "    MV: Gross=-0.0803 | TO=1.929 | TC=0.00177 | Net=-0.0821\n",
      "    MSR: Gross=-0.0399 | TO=3.411 | TC=0.00327 | Net=-0.0432\n",
      "\n",
      "[Month 2] 2020-02-29\n",
      "  Assets: 64/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0590 | TO=0.182 | TC=0.00017 | Net=-0.0592\n",
      "    MV: Gross=-0.0373 | TO=0.229 | TC=0.00022 | Net=-0.0375\n",
      "    MSR: Gross= 0.1106 | TO=0.790 | TC=0.00088 | Net= 0.1097\n",
      "\n",
      "[Month 3] 2020-03-31\n",
      "  Assets: 65/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0725 | TO=0.262 | TC=0.00028 | Net= 0.0722\n",
      "    MV: Gross= 0.0625 | TO=0.291 | TC=0.00031 | Net= 0.0622\n",
      "    MSR: Gross=-0.0194 | TO=1.037 | TC=0.00102 | Net=-0.0204\n",
      "\n",
      "[Month 4] 2020-04-30\n",
      "  Assets: 64/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0271 | TO=0.266 | TC=0.00027 | Net= 0.0268\n",
      "    MV: Gross= 0.0378 | TO=0.279 | TC=0.00029 | Net= 0.0375\n",
      "    MSR: Gross= 0.1453 | TO=0.749 | TC=0.00086 | Net= 0.1444\n",
      "\n",
      "[Month 5] 2020-05-31\n",
      "  Assets: 64/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0554 | TO=0.187 | TC=0.00018 | Net=-0.0556\n",
      "    MV: Gross=-0.0560 | TO=0.194 | TC=0.00018 | Net=-0.0562\n",
      "    MSR: Gross=-0.0615 | TO=0.705 | TC=0.00066 | Net=-0.0622\n",
      "\n",
      "[Month 6] 2020-06-30\n",
      "  Assets: 62/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0797 | TO=0.222 | TC=0.00024 | Net= 0.0794\n",
      "    MV: Gross= 0.0886 | TO=0.240 | TC=0.00026 | Net= 0.0884\n",
      "    MSR: Gross= 0.1799 | TO=0.602 | TC=0.00071 | Net= 0.1791\n",
      "\n",
      "[Month 7] 2020-07-31\n",
      "  Assets: 62/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0358 | TO=0.220 | TC=0.00023 | Net= 0.0355\n",
      "    MV: Gross= 0.0441 | TO=0.208 | TC=0.00022 | Net= 0.0439\n",
      "    MSR: Gross= 0.1339 | TO=0.675 | TC=0.00077 | Net= 0.1332\n",
      "\n",
      "[Month 8] 2020-08-31\n",
      "  Assets: 62/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0327 | TO=0.259 | TC=0.00027 | Net= 0.0324\n",
      "    MV: Gross= 0.0348 | TO=0.252 | TC=0.00026 | Net= 0.0345\n",
      "    MSR: Gross= 0.0597 | TO=0.421 | TC=0.00045 | Net= 0.0593\n",
      "\n",
      "[Month 9] 2020-09-30\n",
      "  Assets: 60/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0227 | TO=0.135 | TC=0.00013 | Net=-0.0229\n",
      "    MV: Gross=-0.0258 | TO=0.190 | TC=0.00018 | Net=-0.0260\n",
      "    MSR: Gross=-0.0811 | TO=0.503 | TC=0.00046 | Net=-0.0816\n",
      "\n",
      "[Month 10] 2020-10-31\n",
      "  Assets: 59/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0257 | TO=0.246 | TC=0.00025 | Net= 0.0255\n",
      "    MV: Gross= 0.0147 | TO=0.279 | TC=0.00028 | Net= 0.0145\n",
      "    MSR: Gross=-0.1200 | TO=1.024 | TC=0.00090 | Net=-0.1209\n",
      "\n",
      "[Month 11] 2020-11-30\n",
      "  Assets: 59/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0116 | TO=0.322 | TC=0.00032 | Net=-0.0119\n",
      "    MV: Gross=-0.0126 | TO=0.301 | TC=0.00030 | Net=-0.0129\n",
      "    MSR: Gross=-0.0241 | TO=1.192 | TC=0.00116 | Net=-0.0252\n",
      "\n",
      "[Month 12] 2020-12-31\n",
      "  Assets: 59/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0178 | TO=0.141 | TC=0.00014 | Net=-0.0179\n",
      "    MV: Gross=-0.0218 | TO=0.156 | TC=0.00015 | Net=-0.0220\n",
      "    MSR: Gross=-0.0685 | TO=0.546 | TC=0.00051 | Net=-0.0690\n",
      "\n",
      "======================================================================\n",
      "YEAR 2021: RETRAINING LOGISTIC REGRESSION\n",
      "======================================================================\n",
      "Logistic training period: 2006-01-31 to 2020-12-31\n",
      "  Training samples: 89754\n",
      "  Training accuracy: 0.5589\n",
      "  Stocks evaluated: 497\n",
      "  Stocks selected: 100\n",
      "  Buy probability range: [0.5277, 0.5799]\n",
      "\n",
      "Running monthly rebalancing from 2021-01-31 to 2021-12-31\n",
      "======================================================================\n",
      "\n",
      "[Month 1] 2021-01-31\n",
      "  Assets: 67/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0583 | TO=1.256 | TC=0.00118 | Net=-0.0595\n",
      "    MV: Gross=-0.0624 | TO=1.261 | TC=0.00118 | Net=-0.0636\n",
      "    MSR: Gross=-0.0933 | TO=2.640 | TC=0.00239 | Net=-0.0957\n",
      "\n",
      "[Month 2] 2021-02-28\n",
      "  Assets: 67/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0682 | TO=0.279 | TC=0.00030 | Net= 0.0679\n",
      "    MV: Gross= 0.0576 | TO=0.351 | TC=0.00037 | Net= 0.0572\n",
      "    MSR: Gross=-0.0038 | TO=0.974 | TC=0.00097 | Net=-0.0047\n",
      "\n",
      "[Month 3] 2021-03-31\n",
      "  Assets: 66/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0001 | TO=0.197 | TC=0.00020 | Net=-0.0001\n",
      "    MV: Gross= 0.0055 | TO=0.211 | TC=0.00021 | Net= 0.0053\n",
      "    MSR: Gross= 0.0414 | TO=0.592 | TC=0.00062 | Net= 0.0408\n",
      "\n",
      "[Month 4] 2021-04-30\n",
      "  Assets: 66/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0085 | TO=0.209 | TC=0.00021 | Net= 0.0083\n",
      "    MV: Gross=-0.0015 | TO=0.184 | TC=0.00018 | Net=-0.0017\n",
      "    MSR: Gross=-0.0732 | TO=0.350 | TC=0.00032 | Net=-0.0735\n",
      "\n",
      "[Month 5] 2021-05-31\n",
      "  Assets: 66/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0146 | TO=0.116 | TC=0.00012 | Net= 0.0145\n",
      "    MV: Gross= 0.0258 | TO=0.152 | TC=0.00016 | Net= 0.0256\n",
      "    MSR: Gross= 0.0991 | TO=0.690 | TC=0.00076 | Net= 0.0983\n",
      "\n",
      "[Month 6] 2021-06-30\n",
      "  Assets: 67/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0456 | TO=0.145 | TC=0.00015 | Net= 0.0455\n",
      "    MV: Gross= 0.0536 | TO=0.160 | TC=0.00017 | Net= 0.0535\n",
      "    MSR: Gross= 0.1097 | TO=0.511 | TC=0.00057 | Net= 0.1091\n",
      "\n",
      "[Month 7] 2021-07-31\n",
      "  Assets: 67/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0025 | TO=0.178 | TC=0.00018 | Net=-0.0026\n",
      "    MV: Gross=-0.0006 | TO=0.142 | TC=0.00014 | Net=-0.0008\n",
      "    MSR: Gross= 0.0122 | TO=0.733 | TC=0.00074 | Net= 0.0115\n",
      "\n",
      "[Month 8] 2021-08-31\n",
      "  Assets: 67/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0306 | TO=0.173 | TC=0.00017 | Net=-0.0308\n",
      "    MV: Gross=-0.0334 | TO=0.166 | TC=0.00016 | Net=-0.0336\n",
      "    MSR: Gross=-0.0528 | TO=0.475 | TC=0.00045 | Net=-0.0533\n",
      "\n",
      "[Month 9] 2021-09-30\n",
      "  Assets: 65/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0420 | TO=0.201 | TC=0.00021 | Net= 0.0418\n",
      "    MV: Gross= 0.0597 | TO=0.275 | TC=0.00029 | Net= 0.0594\n",
      "    MSR: Gross= 0.1637 | TO=0.707 | TC=0.00082 | Net= 0.1629\n",
      "\n",
      "[Month 10] 2021-10-31\n",
      "  Assets: 65/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0092 | TO=0.272 | TC=0.00027 | Net=-0.0094\n",
      "    MV: Gross= 0.0021 | TO=0.239 | TC=0.00024 | Net= 0.0019\n",
      "    MSR: Gross= 0.0683 | TO=0.526 | TC=0.00056 | Net= 0.0677\n",
      "\n",
      "[Month 11] 2021-11-30\n",
      "  Assets: 65/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.1028 | TO=0.161 | TC=0.00018 | Net= 0.1026\n",
      "    MV: Gross= 0.0931 | TO=0.179 | TC=0.00020 | Net= 0.0929\n",
      "    MSR: Gross= 0.0298 | TO=0.595 | TC=0.00061 | Net= 0.0292\n",
      "\n",
      "[Month 12] 2021-12-31\n",
      "  Assets: 65/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0354 | TO=0.172 | TC=0.00017 | Net=-0.0355\n",
      "    MV: Gross=-0.0515 | TO=0.168 | TC=0.00016 | Net=-0.0517\n",
      "    MSR: Gross=-0.1795 | TO=0.576 | TC=0.00047 | Net=-0.1799\n",
      "\n",
      "======================================================================\n",
      "YEAR 2022: RETRAINING LOGISTIC REGRESSION\n",
      "======================================================================\n",
      "Logistic training period: 2007-01-31 to 2021-12-31\n",
      "  Training samples: 89722\n",
      "  Training accuracy: 0.5607\n",
      "  Stocks evaluated: 497\n",
      "  Stocks selected: 100\n",
      "  Buy probability range: [0.5367, 0.5843]\n",
      "\n",
      "Running monthly rebalancing from 2022-01-31 to 2022-12-31\n",
      "======================================================================\n",
      "\n",
      "[Month 1] 2022-01-31\n",
      "  Assets: 59/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0161 | TO=0.979 | TC=0.00096 | Net=-0.0170\n",
      "    MV: Gross=-0.0176 | TO=0.966 | TC=0.00095 | Net=-0.0185\n",
      "    MSR: Gross=-0.0360 | TO=2.019 | TC=0.00195 | Net=-0.0379\n",
      "\n",
      "[Month 2] 2022-02-28\n",
      "  Assets: 59/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0578 | TO=0.152 | TC=0.00016 | Net= 0.0576\n",
      "    MV: Gross= 0.0559 | TO=0.164 | TC=0.00017 | Net= 0.0558\n",
      "    MSR: Gross= 0.0366 | TO=0.523 | TC=0.00054 | Net= 0.0360\n",
      "\n",
      "[Month 3] 2022-03-31\n",
      "  Assets: 59/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0026 | TO=0.182 | TC=0.00018 | Net= 0.0024\n",
      "    MV: Gross=-0.0022 | TO=0.161 | TC=0.00016 | Net=-0.0023\n",
      "    MSR: Gross=-0.0627 | TO=0.419 | TC=0.00039 | Net=-0.0631\n",
      "\n",
      "[Month 4] 2022-04-30\n",
      "  Assets: 60/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0102 | TO=0.221 | TC=0.00022 | Net= 0.0100\n",
      "    MV: Gross= 0.0057 | TO=0.240 | TC=0.00024 | Net= 0.0054\n",
      "    MSR: Gross=-0.0433 | TO=0.639 | TC=0.00061 | Net=-0.0439\n",
      "\n",
      "[Month 5] 2022-05-31\n",
      "  Assets: 60/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0153 | TO=0.157 | TC=0.00015 | Net=-0.0154\n",
      "    MV: Gross=-0.0149 | TO=0.153 | TC=0.00015 | Net=-0.0150\n",
      "    MSR: Gross=-0.0094 | TO=0.672 | TC=0.00067 | Net=-0.0101\n",
      "\n",
      "[Month 6] 2022-06-30\n",
      "  Assets: 60/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0257 | TO=0.170 | TC=0.00017 | Net= 0.0256\n",
      "    MV: Gross= 0.0306 | TO=0.185 | TC=0.00019 | Net= 0.0304\n",
      "    MSR: Gross= 0.1137 | TO=0.426 | TC=0.00047 | Net= 0.1133\n",
      "\n",
      "[Month 7] 2022-07-31\n",
      "  Assets: 60/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0270 | TO=0.197 | TC=0.00019 | Net=-0.0272\n",
      "    MV: Gross=-0.0258 | TO=0.189 | TC=0.00018 | Net=-0.0260\n",
      "    MSR: Gross=-0.0053 | TO=0.398 | TC=0.00040 | Net=-0.0057\n",
      "\n",
      "[Month 8] 2022-08-31\n",
      "  Assets: 60/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0346 | TO=0.117 | TC=0.00011 | Net=-0.0347\n",
      "    MV: Gross=-0.0328 | TO=0.134 | TC=0.00013 | Net=-0.0330\n",
      "    MSR: Gross=-0.0085 | TO=0.420 | TC=0.00042 | Net=-0.0089\n",
      "\n",
      "[Month 9] 2022-09-30\n",
      "  Assets: 60/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0405 | TO=0.265 | TC=0.00028 | Net= 0.0402\n",
      "    MV: Gross= 0.0363 | TO=0.265 | TC=0.00028 | Net= 0.0360\n",
      "    MSR: Gross=-0.0262 | TO=0.689 | TC=0.00067 | Net=-0.0268\n",
      "\n",
      "[Month 10] 2022-10-31\n",
      "  Assets: 60/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0660 | TO=0.254 | TC=0.00027 | Net= 0.0658\n",
      "    MV: Gross= 0.0653 | TO=0.229 | TC=0.00024 | Net= 0.0650\n",
      "    MSR: Gross= 0.0560 | TO=0.750 | TC=0.00079 | Net= 0.0552\n",
      "\n",
      "[Month 11] 2022-11-30\n",
      "  Assets: 61/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0228 | TO=0.272 | TC=0.00027 | Net=-0.0231\n",
      "    MV: Gross=-0.0251 | TO=0.270 | TC=0.00026 | Net=-0.0253\n",
      "    MSR: Gross=-0.0614 | TO=0.509 | TC=0.00048 | Net=-0.0619\n",
      "\n",
      "[Month 12] 2022-12-31\n",
      "  Assets: 61/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0661 | TO=0.122 | TC=0.00011 | Net=-0.0662\n",
      "    MV: Gross=-0.0637 | TO=0.132 | TC=0.00012 | Net=-0.0638\n",
      "    MSR: Gross=-0.0355 | TO=0.791 | TC=0.00076 | Net=-0.0363\n",
      "\n",
      "======================================================================\n",
      "YEAR 2023: RETRAINING LOGISTIC REGRESSION\n",
      "======================================================================\n",
      "Logistic training period: 2008-01-31 to 2022-12-31\n",
      "  Training samples: 89704\n",
      "  Training accuracy: 0.5621\n",
      "  Stocks evaluated: 498\n",
      "  Stocks selected: 100\n",
      "  Buy probability range: [0.5409, 0.5783]\n",
      "\n",
      "Running monthly rebalancing from 2023-01-31 to 2023-12-31\n",
      "======================================================================\n",
      "\n",
      "[Month 1] 2023-01-31\n",
      "  Assets: 61/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0315 | TO=2.143 | TC=0.00208 | Net=-0.0336\n",
      "    MV: Gross=-0.0306 | TO=2.151 | TC=0.00208 | Net=-0.0327\n",
      "    MSR: Gross=-0.0087 | TO=3.206 | TC=0.00318 | Net=-0.0119\n",
      "\n",
      "[Month 2] 2023-02-28\n",
      "  Assets: 61/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0420 | TO=0.140 | TC=0.00015 | Net= 0.0418\n",
      "    MV: Gross= 0.0427 | TO=0.144 | TC=0.00015 | Net= 0.0425\n",
      "    MSR: Gross= 0.0597 | TO=0.466 | TC=0.00049 | Net= 0.0592\n",
      "\n",
      "[Month 3] 2023-03-31\n",
      "  Assets: 60/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0486 | TO=0.226 | TC=0.00024 | Net= 0.0483\n",
      "    MV: Gross= 0.0479 | TO=0.228 | TC=0.00024 | Net= 0.0476\n",
      "    MSR: Gross= 0.0202 | TO=0.677 | TC=0.00069 | Net= 0.0195\n",
      "\n",
      "[Month 4] 2023-04-30\n",
      "  Assets: 61/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0355 | TO=0.225 | TC=0.00022 | Net=-0.0358\n",
      "    MV: Gross=-0.0356 | TO=0.223 | TC=0.00021 | Net=-0.0359\n",
      "    MSR: Gross= 0.0190 | TO=0.387 | TC=0.00039 | Net= 0.0186\n",
      "\n",
      "[Month 5] 2023-05-31\n",
      "  Assets: 61/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0143 | TO=0.109 | TC=0.00011 | Net= 0.0142\n",
      "    MV: Gross= 0.0143 | TO=0.113 | TC=0.00011 | Net= 0.0142\n",
      "    MSR: Gross= 0.0090 | TO=0.476 | TC=0.00048 | Net= 0.0085\n",
      "\n",
      "[Month 6] 2023-06-30\n",
      "  Assets: 61/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0161 | TO=0.259 | TC=0.00026 | Net= 0.0158\n",
      "    MV: Gross= 0.0166 | TO=0.277 | TC=0.00028 | Net= 0.0163\n",
      "    MSR: Gross= 0.0080 | TO=0.678 | TC=0.00068 | Net= 0.0073\n",
      "\n",
      "[Month 7] 2023-07-31\n",
      "  Assets: 63/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0051 | TO=0.262 | TC=0.00026 | Net= 0.0048\n",
      "    MV: Gross= 0.0050 | TO=0.281 | TC=0.00028 | Net= 0.0047\n",
      "    MSR: Gross= 0.0098 | TO=0.663 | TC=0.00067 | Net= 0.0091\n",
      "\n",
      "[Month 8] 2023-08-31\n",
      "  Assets: 63/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0294 | TO=0.189 | TC=0.00018 | Net=-0.0296\n",
      "    MV: Gross=-0.0294 | TO=0.226 | TC=0.00022 | Net=-0.0296\n",
      "    MSR: Gross=-0.0317 | TO=0.445 | TC=0.00043 | Net=-0.0321\n",
      "\n",
      "[Month 9] 2023-09-30\n",
      "  Assets: 61/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0004 | TO=0.324 | TC=0.00032 | Net=-0.0007\n",
      "    MV: Gross=-0.0005 | TO=0.323 | TC=0.00032 | Net=-0.0009\n",
      "    MSR: Gross= 0.0310 | TO=1.099 | TC=0.00113 | Net= 0.0299\n",
      "\n",
      "[Month 10] 2023-10-31\n",
      "  Assets: 61/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0073 | TO=0.504 | TC=0.00051 | Net= 0.0068\n",
      "    MV: Gross= 0.0082 | TO=0.489 | TC=0.00049 | Net= 0.0077\n",
      "    MSR: Gross=-0.0195 | TO=1.195 | TC=0.00117 | Net=-0.0207\n",
      "\n",
      "[Month 11] 2023-11-30\n",
      "  Assets: 62/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0028 | TO=0.340 | TC=0.00034 | Net=-0.0031\n",
      "    MV: Gross=-0.0024 | TO=0.332 | TC=0.00033 | Net=-0.0028\n",
      "    MSR: Gross=-0.0091 | TO=0.928 | TC=0.00092 | Net=-0.0100\n",
      "\n",
      "[Month 12] 2023-12-31\n",
      "  Assets: 62/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0496 | TO=0.213 | TC=0.00022 | Net= 0.0494\n",
      "    MV: Gross= 0.0496 | TO=0.211 | TC=0.00022 | Net= 0.0494\n",
      "    MSR: Gross= 0.0507 | TO=0.477 | TC=0.00050 | Net= 0.0502\n",
      "\n",
      "======================================================================\n",
      "YEAR 2024: RETRAINING LOGISTIC REGRESSION\n",
      "======================================================================\n",
      "Logistic training period: 2009-01-31 to 2023-12-31\n",
      "  Training samples: 89703\n",
      "  Training accuracy: 0.5689\n",
      "  Stocks evaluated: 500\n",
      "  Stocks selected: 100\n",
      "  Buy probability range: [0.5485, 0.5899]\n",
      "\n",
      "Running monthly rebalancing from 2024-01-31 to 2024-04-30\n",
      "======================================================================\n",
      "\n",
      "[Month 1] 2024-01-31\n",
      "  Assets: 67/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0057 | TO=2.102 | TC=0.00211 | Net= 0.0036\n",
      "    MV: Gross= 0.0108 | TO=2.142 | TC=0.00217 | Net= 0.0086\n",
      "    MSR: Gross= 0.1051 | TO=4.041 | TC=0.00447 | Net= 0.1006\n",
      "\n",
      "[Month 2] 2024-02-29\n",
      "  Assets: 67/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross= 0.0227 | TO=0.442 | TC=0.00045 | Net= 0.0223\n",
      "    MV: Gross= 0.0222 | TO=0.465 | TC=0.00048 | Net= 0.0217\n",
      "    MSR: Gross= 0.0013 | TO=0.857 | TC=0.00086 | Net= 0.0004\n",
      "\n",
      "[Month 3] 2024-03-31\n",
      "  Assets: 65/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0185 | TO=0.275 | TC=0.00027 | Net=-0.0188\n",
      "    MV: Gross=-0.0181 | TO=0.272 | TC=0.00027 | Net=-0.0184\n",
      "    MSR: Gross= 0.0045 | TO=1.264 | TC=0.00127 | Net= 0.0032\n",
      "\n",
      "[Month 4] 2024-04-30\n",
      "  Assets: 63/100 with complete data\n",
      "  ✓ Nodewise completed for gmv, mv, msr\n",
      "  Portfolio Returns:\n",
      "    GMV: Gross=-0.0099 | TO=0.203 | TC=0.00020 | Net=-0.0101\n",
      "    MV: Gross=-0.0097 | TO=0.218 | TC=0.00022 | Net=-0.0099\n",
      "    MSR: Gross=-0.0020 | TO=1.168 | TC=0.00117 | Net=-0.0032\n",
      "\n",
      "======================================================================\n",
      "BACKTEST COMPLETE\n",
      "======================================================================\n",
      "GMV Sharpe: 0.4170\n",
      "MV Sharpe:  0.4646\n",
      "MSR Sharpe: 0.4156\n"
     ]
    }
   ],
   "source": [
    "results = integrated_backtest(\n",
    "    df,\n",
    "    factors_path='../AI Portfolio Selection/factors_ff_monthly_raw.csv',\n",
    "    ic='GIC',  # or 'BIC', 'WIC', 'AIC', 'cv'\n",
    "    test_start_date='2020-01-31',\n",
    "    test_end_date='2024-04-30',\n",
    "    logistic_train_years=15,\n",
    "    stock_selection_method='top_and_bottom',\n",
    "    n_stocks=50,\n",
    "    lookback_window=180,\n",
    "    transaction_cost=0.001,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Access results for each portfolio\n",
    "gmv_results = results['gmv']['results_df']\n",
    "gmv_metrics = results['gmv']['metrics']\n",
    "\n",
    "mv_results = results['mv']['results_df']\n",
    "mv_metrics = results['mv']['metrics']\n",
    "\n",
    "msr_results = results['msr']['results_df']\n",
    "msr_metrics = results['msr']['metrics']\n",
    "\n",
    "# Compare Sharpe ratios\n",
    "print(f\"GMV Sharpe: {gmv_metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"MV Sharpe:  {mv_metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"MSR Sharpe: {msr_metrics['annual_sharpe_ratio']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dc475f9-c242-4893-b468-67d950d625c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GMV\n",
      "Annualized Sharpe Ratio: 0.4170\n",
      "Mean Return: 0.0583\n",
      "Variance: 0.0195\n",
      "Avg Turnover: 0.3606\n",
      "\n",
      " MV\n",
      "Annualized Sharpe Ratio: 0.4646\n",
      "Mean Return: 0.0646\n",
      "Variance: 0.0194\n",
      "Avg Turnover: 0.3696\n",
      "\n",
      " MSR\n",
      "Annualized Sharpe Ratio: 0.4156\n",
      "Mean Return: 0.1048\n",
      "Variance: 0.0637\n",
      "Avg Turnover: 0.9097\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n GMV\")\n",
    "print(f\"Annualized Sharpe Ratio: {gmv_metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {gmv_metrics['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {gmv_metrics['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {gmv_metrics['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MV\")\n",
    "print(f\"Annualized Sharpe Ratio: {mv_metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {mv_metrics['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {mv_metrics['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {mv_metrics['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MSR\")\n",
    "print(f\"Annualized Sharpe Ratio: {msr_metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {msr_metrics['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {msr_metrics['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {msr_metrics['avg_turnover']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e691398-376d-4817-ab35-3ee2d6b251ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
