{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34bd4c6e-e1fc-4905-88a9-6c69f92a9cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mv_weights(Theta_hat, mu, target_return=0.01):\n",
    "    \"\"\"\n",
    "    Compute Mean-Variance portfolio weights with target return.\n",
    "    \n",
    "    Solves the constrained optimization:\n",
    "    min w' Sigma w  subject to  w' mu = target_return  and  w' 1 = 1\n",
    "    \n",
    "    Solution uses Lagrange multipliers with two constraints.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix (Sigma^{-1})\n",
    "    mu : np.ndarray, shape (p,)\n",
    "        Expected returns\n",
    "    target_return : float\n",
    "        Target portfolio return (default: 0.01 = 1% monthly)\n",
    "    long_only : bool\n",
    "        If True, falls back to GMV if MV produces negative weights\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # Compute key quantities\n",
    "    A = ones_p @ Theta_hat @ ones_p  # 1' Theta 1\n",
    "    B = ones_p @ Theta_hat @ mu       # 1' Theta mu  \n",
    "    C = mu @ Theta_hat @ mu           # mu' Theta mu\n",
    "    D = A * C - B * B                  # Determinant\n",
    "    \n",
    "    # Check for singularity\n",
    "    if np.abs(D) < 1e-10:\n",
    "        print('SINGULARITY')\n",
    "        # System is singular, use GMV instead\n",
    "        if np.abs(A) > 1e-10:\n",
    "            w_star = (Theta_hat @ ones_p) / A\n",
    "            return w_star\n",
    "        else:\n",
    "            return ones_p / p\n",
    "    \n",
    "    \n",
    "    # Compute Lagrange multipliers\n",
    "    lambda1 = (C - B * target_return) / D\n",
    "    lambda2 = (A * target_return - B) / D\n",
    "    \n",
    "    # Compute weights: w = lambda1 * Theta^{-1} 1 + lambda2 * Theta^{-1} mu\n",
    "    w_star = lambda1 * (Theta_hat @ ones_p) + lambda2 * (Theta_hat @ mu)\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "def msr_weights(Theta_hat, mu):\n",
    "    \"\"\"\n",
    "    Compute Maximum Sharpe Ratio portfolio weights.\n",
    "    \n",
    "    The maximum Sharpe ratio portfolio solves:\n",
    "    max (w' mu) / sqrt(w' Sigma w)\n",
    "    \n",
    "    Solution (when mu represents excess returns):\n",
    "    w ∝ Sigma^{-1} mu = Theta mu\n",
    "    \n",
    "    Then normalize so that sum(w) = 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix (Sigma^{-1})\n",
    "    mu : np.ndarray, shape (p,)\n",
    "        Expected excess returns\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights (sum to 1)\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # Compute unnormalized weights: w ∝ Theta mu\n",
    "    w_unnorm = Theta_hat @ mu\n",
    "    \n",
    "    # Normalize to sum to 1\n",
    "    weight_sum = np.sum(w_unnorm)\n",
    "    \n",
    "    if np.abs(weight_sum) < 1e-10:\n",
    "        print('WARNING: Weight sum near zero, returning equal weights')\n",
    "        return ones_p / p\n",
    "    \n",
    "    w_star = w_unnorm / weight_sum\n",
    "    \n",
    "    return w_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f3d9953-584f-47c2-9da8-6a28149da1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso, LassoCV, LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def est_ndwcov_factor(Y, factors, ic, lambda_min=True):\n",
    "    \"\"\"\n",
    "    Estimate nodewise covariance with factor models using LASSO.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Y : numpy.ndarray\n",
    "        n x p matrix of observations\n",
    "    factors : numpy.ndarray\n",
    "        n x k matrix of factors\n",
    "    ic : str\n",
    "        Information criterion: 'WIC', 'BIC', 'GIC', 'AIC', or 'cv'\n",
    "    lambda_min : bool\n",
    "        If True and ic='cv', use lambda.min; otherwise use lambda.1se\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    TAU : numpy.ndarray\n",
    "        p x p precision matrix estimate\n",
    "    \"\"\"\n",
    "    # Initialization\n",
    "    p = Y.shape[1]\n",
    "    n = Y.shape[0]\n",
    "    C = np.zeros((p, p))\n",
    "    np.fill_diagonal(C, 1)\n",
    "    tau = []\n",
    "    ns1 = np.ones((n, 1))\n",
    "    \n",
    "    # Fit factor model: Y = factors * beta + u\n",
    "    # Add intercept to factors\n",
    "    factors_with_intercept = np.column_stack([np.ones(n), factors])\n",
    "    \n",
    "    # Fit linear regression for each column of Y\n",
    "    factormodel = LinearRegression(fit_intercept=False)\n",
    "    factormodel.fit(factors_with_intercept, Y)\n",
    "    \n",
    "    # Get residuals and beta coefficients (excluding intercept)\n",
    "    u = Y - factormodel.predict(factors_with_intercept)\n",
    "    beta = factormodel.coef_[:, 1:]  # p x k matrix (excluding intercept)\n",
    "    \n",
    "    # Loop over the assets\n",
    "    for j in range(p):\n",
    "        # Create design matrix excluding column j\n",
    "        X_j = np.delete(u, j, axis=1)\n",
    "        y_j = u[:, j]\n",
    "        \n",
    "        if ic != 'cv':\n",
    "            # Fit LASSO path\n",
    "            alphas = np.logspace(-4, 1, 100)  # Create lambda sequence\n",
    "            df_list = []\n",
    "            sig_list = []\n",
    "            bic_list = []\n",
    "            coef_list = []\n",
    "            res_list = []\n",
    "            \n",
    "            for alpha in alphas:\n",
    "                model = Lasso(alpha=alpha, fit_intercept=False, max_iter=10000)\n",
    "                model.fit(X_j, y_j)\n",
    "                \n",
    "                # Predictions and residuals\n",
    "                y_pred = model.predict(X_j)\n",
    "                res = y_j - y_pred\n",
    "                \n",
    "                # Degrees of freedom (number of non-zero coefficients)\n",
    "                df = np.sum(np.abs(model.coef_) > 1e-8)\n",
    "                \n",
    "                # Variance of residuals\n",
    "                sig = np.sum(res**2) / n\n",
    "                \n",
    "                # Compute information criterion\n",
    "                if ic == 'WIC':\n",
    "                    bic_val = np.log(sig) + df * np.log(n) / n * np.log(np.log(p))\n",
    "                elif ic == 'BIC':\n",
    "                    bic_val = np.log(sig) + df * np.log(n) / n\n",
    "                elif ic == 'GIC':\n",
    "                    bic_val = np.log(sig) + df * np.log(p) * np.log(np.log(n)) / n\n",
    "                elif ic == 'AIC':\n",
    "                    bic_val = np.log(sig) + 2 * df\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown IC: {ic}\")\n",
    "                \n",
    "                df_list.append(df)\n",
    "                sig_list.append(sig)\n",
    "                bic_list.append(bic_val)\n",
    "                coef_list.append(model.coef_.copy())\n",
    "                res_list.append(res)\n",
    "            \n",
    "            # Select model with minimum IC\n",
    "            jind = np.argmin(bic_list)\n",
    "            jpar = coef_list[jind]\n",
    "            jres = res_list[jind]\n",
    "            jtau = np.sum(y_j * jres) / n\n",
    "            \n",
    "        else:  # Cross-validation\n",
    "            lasso_cv = LassoCV(cv=5, fit_intercept=False, max_iter=10000, n_alphas=100)\n",
    "            lasso_cv.fit(X_j, y_j)\n",
    "            \n",
    "            if lambda_min:\n",
    "                # Use alpha that minimizes CV error (lambda.min equivalent)\n",
    "                jfit = lasso_cv.predict(X_j)\n",
    "                jpar = lasso_cv.coef_\n",
    "            else:\n",
    "                # Use alpha within 1 SE of minimum (lambda.1se equivalent)\n",
    "                cv_scores = lasso_cv.mse_path_.mean(axis=1)\n",
    "                cv_std = lasso_cv.mse_path_.std(axis=1)\n",
    "                min_idx = np.argmin(cv_scores)\n",
    "                threshold = cv_scores[min_idx] + cv_std[min_idx]\n",
    "                \n",
    "                # Find largest alpha with CV score below threshold\n",
    "                valid_indices = np.where(cv_scores <= threshold)[0]\n",
    "                se_idx = valid_indices[0] if len(valid_indices) > 0 else min_idx\n",
    "                \n",
    "                selected_alpha = lasso_cv.alphas_[se_idx]\n",
    "                model_1se = Lasso(alpha=selected_alpha, fit_intercept=False, max_iter=10000)\n",
    "                model_1se.fit(X_j, y_j)\n",
    "                jfit = model_1se.predict(X_j)\n",
    "                jpar = model_1se.coef_\n",
    "            \n",
    "            jres = y_j - jfit\n",
    "            jtau = np.sum(y_j * jres) / n\n",
    "        \n",
    "        # Fill in C matrix\n",
    "        # Insert coefficients back (accounting for missing j-th position)\n",
    "        C_row = np.insert(-jpar / jtau, j, 0)\n",
    "        C[j, :] = C_row\n",
    "        tau.append(jtau)\n",
    "    \n",
    "    # Set diagonal\n",
    "    np.fill_diagonal(C, 1 / np.array(tau))\n",
    "    omega = C.copy()\n",
    "    omegasym = (C + C.T) / 2\n",
    "    \n",
    "    # Compute factor covariance - ensure float64\n",
    "    covft = (1/n) * (factors.T @ factors) - (1/(n**2)) * (factors.T @ ns1 @ ns1.T @ factors)\n",
    "    covft = covft.astype(np.float64)\n",
    "    \n",
    "    # Ensure beta and omegasym are float64\n",
    "    beta = beta.astype(np.float64)\n",
    "    omegasym = omegasym.astype(np.float64)\n",
    "    \n",
    "    # Compute TAU\n",
    "    if factors.shape[1] == 1:\n",
    "        covft_inv = 1.0 / float(covft[0, 0])\n",
    "        p1 = 1.0 / (covft_inv + beta.T @ omegasym @ beta)\n",
    "        TAU = omega - omega @ beta @ p1 @ beta.T @ omega\n",
    "    else:\n",
    "        covft_inv = np.linalg.inv(covft)\n",
    "        p1 = np.linalg.inv(covft_inv + beta.T @ omegasym @ beta)\n",
    "        TAU = omega - omega @ beta @ p1 @ beta.T @ omega\n",
    "    \n",
    "    return TAU\n",
    "\n",
    "\n",
    "def gmv_weights(Theta_hat):\n",
    "    \"\"\"\n",
    "    Compute Global Minimum Variance (GMV) portfolio weights.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # w* = (Θ 1_p) / (1_p' Θ 1_p)\n",
    "    numerator = Theta_hat @ ones_p\n",
    "    denominator = ones_p @ Theta_hat @ ones_p\n",
    "    \n",
    "    if np.abs(denominator) < 1e-10:\n",
    "        # Fallback to equal weights if precision matrix is near-singular\n",
    "        return ones_p / p\n",
    "    \n",
    "    w_star = numerator / denominator\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "\n",
    "def load_recommendation_changes(rec_changes_path):\n",
    "    \"\"\"\n",
    "    Load recommendation changes from CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rec_changes_path : str\n",
    "        Path to monthly_mean_recommendations_decay.csv file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    rec_changes_df : pd.DataFrame\n",
    "        DataFrame with columns: permno, date, ticker, weighted_mean_recommendation, \n",
    "        recommendation_change, num_recommendations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rec_changes_df = pd.read_csv(rec_changes_path)\n",
    "        rec_changes_df['date'] = pd.to_datetime(rec_changes_df['date'])\n",
    "        rec_changes_df['permno'] = rec_changes_df['permno'].astype(int)\n",
    "        return rec_changes_df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  ⚠ Warning: Could not load recommendation changes: {e}\")\n",
    "        return pd.DataFrame(columns=['permno', 'date', 'ticker', 'weighted_mean_recommendation', \n",
    "                                    'recommendation_change', 'num_recommendations'])\n",
    "\n",
    "\n",
    "def get_signal_permnos_for_date(rec_changes_df, date, buy_threshold=-0.5, sell_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Get sets of permnos with buy/sell signals based on recommendation changes.\n",
    "    \n",
    "    Note: Negative change = upgrade (moving toward Strong Buy) = BUY signal\n",
    "          Positive change = downgrade (moving toward Sell) = SELL signal\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rec_changes_df : pd.DataFrame\n",
    "        Recommendation changes dataframe\n",
    "    date : pd.Timestamp\n",
    "        Date to get signals for\n",
    "    buy_threshold : float\n",
    "        Threshold for buy signals (default: -0.5)\n",
    "    sell_threshold : float\n",
    "        Threshold for sell signals (default: 0.5)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    buy_permnos : set\n",
    "        Set of permnos with buy signals\n",
    "    sell_permnos : set\n",
    "        Set of permnos with sell signals\n",
    "    \"\"\"\n",
    "    date_changes = rec_changes_df[rec_changes_df['date'] == date]\n",
    "    \n",
    "    # Buy signals: negative changes (recommendations getting better)\n",
    "    buys = date_changes[date_changes['recommendation_change'] <= buy_threshold]\n",
    "    buy_permnos = set(buys['permno'].values)\n",
    "    \n",
    "    # Sell signals: positive changes (recommendations getting worse)\n",
    "    sells = date_changes[date_changes['recommendation_change'] >= sell_threshold]\n",
    "    sell_permnos = set(sells['permno'].values)\n",
    "    \n",
    "    return buy_permnos, sell_permnos\n",
    "\n",
    "\n",
    "def load_ff_factors(factors_path='factors_ff_monthly_raw.csv'):\n",
    "    \"\"\"\n",
    "    Load Fama-French factors from CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    factors_path : str\n",
    "        Path to the factors CSV file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    factors_df : pd.DataFrame\n",
    "        DataFrame with date index and factor columns\n",
    "    \"\"\"\n",
    "    factors_df = pd.read_csv(factors_path)\n",
    "    \n",
    "    # Convert month column (e.g., 192707) to datetime\n",
    "    # This gives us the first day of the month (1927-07-01)\n",
    "    factors_df['date'] = pd.to_datetime(factors_df.iloc[:, 0].astype(str), format='%Y%m')\n",
    "    \n",
    "    # Convert to end of month to match returns data\n",
    "    factors_df['date'] = factors_df['date'] + pd.offsets.MonthEnd(0)\n",
    "    \n",
    "    # Set date as index and keep only factor columns\n",
    "    factors_df = factors_df.set_index('date')[['Mkt-RF', 'SMB', 'HML']]\n",
    "    \n",
    "    # Convert to decimal form (assuming factors are in percentage points)\n",
    "    factors_df = factors_df / 100\n",
    "    \n",
    "    return factors_df\n",
    "\n",
    "\n",
    "def backtest_factor_nodewise_gmv_analyst(df, \n",
    "                                         factors_path='factors_ff_monthly_raw.csv',\n",
    "                                         test_start_date='2020-01-31', \n",
    "                                         test_end_date='2024-11-30',\n",
    "                                         lookback_window=180,\n",
    "                                         transaction_cost=0.001,\n",
    "                                         rec_changes_path=None,\n",
    "                                         buy_threshold=-0.5,\n",
    "                                         sell_threshold=0.5,\n",
    "                                         ic='GIC',\n",
    "                                         mv_target_return=0.01,\n",
    "                                         verbose=True):\n",
    "    \"\"\"\n",
    "    Backtest Factor-based Nodewise + GMV strategy with analyst recommendation signals.\n",
    "    Identical to baseline except only invests in stocks with buy/sell signals.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with columns: permno, datadate, ret_fwd_1\n",
    "    factors_path : str\n",
    "        Path to Fama-French factors CSV file\n",
    "    test_start_date : str\n",
    "        First date for out-of-sample returns (format: 'YYYY-MM-DD')\n",
    "    test_end_date : str\n",
    "        Last date for out-of-sample returns (format: 'YYYY-MM-DD')\n",
    "    lookback_window : int\n",
    "        Number of months in rolling training window (default: 180)\n",
    "    transaction_cost : float\n",
    "        Proportional transaction cost (default: 0.005 = 50 bps)\n",
    "    rec_changes_path : str\n",
    "        Path to monthly_mean_recommendations_decay.csv file (required)\n",
    "    buy_threshold : float\n",
    "        Threshold for buy signals (default: -0.5)\n",
    "    sell_threshold : float\n",
    "        Threshold for sell signals (default: 0.5)\n",
    "    ic : str\n",
    "        Information criterion for LASSO: 'WIC', 'BIC', 'GIC', 'AIC', or 'cv'\n",
    "    verbose : bool\n",
    "        If True, prints detailed log at each time step.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    results_df : pd.DataFrame\n",
    "        DataFrame with columns: date, portfolio_return, cumulative_return\n",
    "    metrics : dict\n",
    "        Overall performance metrics\n",
    "    \"\"\"\n",
    "    # --- 1. Setup ---\n",
    "    df = df.copy()\n",
    "    if 'datadate' not in df.columns or 'permno' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have 'datadate' and 'permno' columns\")\n",
    "    df['datadate'] = pd.to_datetime(df['datadate'])\n",
    "    \n",
    "    # Load recommendation changes (required)\n",
    "    if rec_changes_path is None:\n",
    "        raise ValueError(\"rec_changes_path is required for this strategy\")\n",
    "    \n",
    "    rec_changes_df = load_recommendation_changes(rec_changes_path)\n",
    "    if len(rec_changes_df) == 0:\n",
    "        raise ValueError(\"No recommendation changes loaded\")\n",
    "    \n",
    "    # Load Fama-French factors\n",
    "    factors_df = load_ff_factors(factors_path)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Loaded recommendation changes: {len(rec_changes_df)} records\")\n",
    "        print(f\"Strategy: BUY threshold <= {buy_threshold}, SELL threshold >= {sell_threshold}\")\n",
    "    \n",
    "    # Get unique dates\n",
    "    all_dates = sorted(df['datadate'].unique())\n",
    "    \n",
    "    # Convert test dates to datetime\n",
    "    test_start_dt = pd.to_datetime(test_start_date)\n",
    "    test_end_dt = pd.to_datetime(test_end_date)\n",
    "    \n",
    "    # Find date indices\n",
    "    try:\n",
    "        test_start_idx = all_dates.index(test_start_dt)\n",
    "        test_end_idx = all_dates.index(test_end_dt)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Date not found in DataFrame: {e}\")\n",
    "    \n",
    "    if test_start_idx < lookback_window:\n",
    "        raise ValueError(f\"Not enough data for lookback. Test start date {test_start_date} \"\n",
    "                         f\"requires data back to {all_dates[test_start_idx - lookback_window]}, \"\n",
    "                         f\"but only {test_start_idx} periods are available.\")\n",
    "    \n",
    "    # Storage for results - separate for each portfolio type\n",
    "    portfolio_results = {\n",
    "        'gmv': {'returns': [], 'dates': [], 'weights': [], 'turnover': [], 'gross_returns': []},\n",
    "        'mv': {'returns': [], 'dates': [], 'weights': [], 'turnover': [], 'gross_returns': []},\n",
    "        'msr': {'returns': [], 'dates': [], 'weights': [], 'turnover': [], 'gross_returns': []}\n",
    "    }\n",
    "    \n",
    "    # Track previous state for each portfolio\n",
    "    prev_state = {\n",
    "        'gmv': {'weights_dict': {}, 'oos_returns_dict': {}, 'gross_return': 0.0},\n",
    "        'mv': {'weights_dict': {}, 'oos_returns_dict': {}, 'gross_return': 0.0},\n",
    "        'msr': {'weights_dict': {}, 'oos_returns_dict': {}, 'gross_return': 0.0}\n",
    "    }\n",
    "    \n",
    "    # Cache for yearly signals\n",
    "    yearly_signals_cache = {}\n",
    "    \n",
    "    # --- 2. Rolling Window Backtest ---\n",
    "    if verbose:\n",
    "        print(\"=\"*60)\n",
    "        print(\"STARTING BACKTEST WITH FACTOR-BASED NODEWISE + ANALYST SIGNALS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "    for t in range(test_start_idx, test_end_idx + 1):\n",
    "        current_date = all_dates[t]\n",
    "        current_year = current_date.year\n",
    "        \n",
    "        # Get buy and sell signals for current date\n",
    "        buy_permnos, sell_permnos = get_signal_permnos_for_date(\n",
    "            rec_changes_df, current_date, buy_threshold, sell_threshold\n",
    "        )\n",
    "        \n",
    "        # Combine all permnos with signals\n",
    "        allowed_permnos = buy_permnos | sell_permnos\n",
    "        \n",
    "        # Get OOS returns FIRST before any early exits\n",
    "        oos_data = df[(df['datadate'] == current_date) & (df['permno'].isin(allowed_permnos))]\n",
    "        oos_returns_series = oos_data.set_index('permno')['ret_fwd_1']\n",
    "        oos_returns_series = oos_returns_series.dropna()\n",
    "        oos_returns_dict = oos_returns_series.to_dict()\n",
    "        \n",
    "        # Handle early exit cases\n",
    "        if len(allowed_permnos) == 0:\n",
    "            if verbose:\n",
    "                print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                      f\"Date: {current_date.strftime('%Y-%m-%d')}\")\n",
    "                print(f\"  ⚠ No signals for {current_date.strftime('%Y-%m-%d')}, recording zero return\")\n",
    "            \n",
    "            # Process exit for all three portfolios\n",
    "            for ptype in ['gmv', 'mv', 'msr']:\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    prev_state[ptype]['weights_dict'], \n",
    "                    prev_state[ptype]['oos_returns_dict'], \n",
    "                    prev_state[ptype]['gross_return'], \n",
    "                    transaction_cost,\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                portfolio_results[ptype]['returns'].append(net_return)\n",
    "                portfolio_results[ptype]['dates'].append(current_date)\n",
    "                portfolio_results[ptype]['weights'].append({})\n",
    "                portfolio_results[ptype]['turnover'].append(turnover)\n",
    "                portfolio_results[ptype]['gross_returns'].append(0.0)\n",
    "                \n",
    "                prev_state[ptype] = {'weights_dict': {}, 'oos_returns_dict': {}, 'gross_return': 0.0}\n",
    "            continue\n",
    "        \n",
    "        # Define the lookback window\n",
    "        window_start_date = all_dates[t - lookback_window]\n",
    "        window_end_date = all_dates[t - 1]\n",
    "        \n",
    "        # Get training data for this window\n",
    "        train_data = df[(df['datadate'] >= window_start_date) & \n",
    "                        (df['datadate'] <= window_end_date) &\n",
    "                        (df['permno'].isin(allowed_permnos))]\n",
    "        \n",
    "        # Pivot to get returns matrix\n",
    "        returns_pivot = train_data.pivot(index='datadate', columns='permno', values='ret_fwd_1')\n",
    "        window_dates = all_dates[t - lookback_window : t]\n",
    "        returns_pivot = returns_pivot.reindex(index=window_dates)\n",
    "\n",
    "        # Align factors with return realization dates\n",
    "        factor_dates = [(d + pd.DateOffset(months=1) + pd.offsets.MonthEnd(0)) for d in window_dates]\n",
    "        \n",
    "        try:\n",
    "            factors_window = factors_df.loc[factor_dates]\n",
    "        except KeyError as e:\n",
    "            raise ValueError(f\"Factor dates not found in factors file. Missing dates: {e}\")\n",
    "        \n",
    "        if factors_window.isna().any().any():\n",
    "            if verbose:\n",
    "                print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                      f\"Date: {current_date.strftime('%Y-%m-%d')}\")\n",
    "                print(f\"  ⚠ Missing factor data in window, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Filter assets with any NaNs\n",
    "        nan_assets = returns_pivot.columns[returns_pivot.isna().any()]\n",
    "        filtered_pivot = returns_pivot.drop(columns=nan_assets)\n",
    "        \n",
    "        current_assets = filtered_pivot.columns.tolist()\n",
    "        Y = filtered_pivot.values\n",
    "        factors = factors_window.values\n",
    "        n_train, p_current = Y.shape\n",
    "    \n",
    "        if verbose:\n",
    "            print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                  f\"Date: {current_date.strftime('%Y-%m-%d')} | Year: {current_year}\")\n",
    "            print(f\"  Window: {window_start_date.strftime('%Y-%m-%d')} to \"\n",
    "                  f\"{window_end_date.strftime('%Y-%m-%d')}\")\n",
    "            print(f\" Analyst: {len(allowed_permnos)} | \"\n",
    "                  f\" | Assets w/ data: {p_current}\")\n",
    "    \n",
    "        # Check for valid data\n",
    "        if n_train < lookback_window or p_current < 2:\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ Insufficient data (n={n_train}, p={p_current}), recording zero return\")\n",
    "            \n",
    "            for ptype in ['gmv', 'mv', 'msr']:\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    prev_state[ptype]['weights_dict'], \n",
    "                    prev_state[ptype]['oos_returns_dict'], \n",
    "                    prev_state[ptype]['gross_return'], \n",
    "                    transaction_cost,\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                portfolio_results[ptype]['returns'].append(net_return)\n",
    "                portfolio_results[ptype]['dates'].append(current_date)\n",
    "                portfolio_results[ptype]['weights'].append({})\n",
    "                portfolio_results[ptype]['turnover'].append(turnover)\n",
    "                portfolio_results[ptype]['gross_returns'].append(0.0)\n",
    "                \n",
    "                prev_state[ptype] = {'weights_dict': {}, 'oos_returns_dict': {}, 'gross_return': 0.0}\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Demean the returns\n",
    "            Y_bar = Y.mean(axis=0)\n",
    "            Y_star = Y - Y_bar\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  Running Residual Nodewise Regression...\")\n",
    "            Theta_hat = est_ndwcov_factor(Y, factors, ic=ic, lambda_min=True)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  Computing portfolio weights...\")\n",
    "\n",
    "            mu = Y.mean(axis=0)\n",
    "            \n",
    "            # Compute weights for all three portfolios\n",
    "            weights_dict = {\n",
    "                'gmv': gmv_weights(Theta_hat),\n",
    "                'mv': mv_weights(Theta_hat, mu, target_return=mv_target_return),\n",
    "                'msr': msr_weights(Theta_hat, mu)\n",
    "            }\n",
    "            \n",
    "            # Create weights dictionaries for each portfolio\n",
    "            new_weights_dicts = {\n",
    "                ptype: {asset: weights_dict[ptype][i] for i, asset in enumerate(current_assets)}\n",
    "                for ptype in ['gmv', 'mv', 'msr']\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"  ✗ Error: {e}\")\n",
    "                print(f\"  Recording zero return for all portfolios\")\n",
    "            \n",
    "            for ptype in ['gmv', 'mv', 'msr']:\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    prev_state[ptype]['weights_dict'], \n",
    "                    prev_state[ptype]['oos_returns_dict'], \n",
    "                    prev_state[ptype]['gross_return'], \n",
    "                    transaction_cost,\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                portfolio_results[ptype]['returns'].append(net_return)\n",
    "                portfolio_results[ptype]['dates'].append(current_date)\n",
    "                portfolio_results[ptype]['weights'].append({})\n",
    "                portfolio_results[ptype]['turnover'].append(turnover)\n",
    "                portfolio_results[ptype]['gross_returns'].append(0.0)\n",
    "                \n",
    "                prev_state[ptype] = {'weights_dict': {}, 'oos_returns_dict': {}, 'gross_return': 0.0}\n",
    "            continue\n",
    "\n",
    "        # Process each portfolio type\n",
    "        for ptype in ['gmv', 'mv', 'msr']:\n",
    "            new_weights_dict = new_weights_dicts[ptype]\n",
    "            \n",
    "            # Normalize weights to sum to 1\n",
    "            weight_sum = sum(new_weights_dict.values())\n",
    "            if weight_sum > 1e-10:\n",
    "                new_weights_dict = {k: v/weight_sum for k, v in new_weights_dict.items()}\n",
    "            else:\n",
    "                if verbose and ptype == 'gmv':  # Only print once\n",
    "                    print(f\"  ⚠ Zero weight sum for {ptype.upper()}, recording zero return\")\n",
    "                \n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    prev_state[ptype]['weights_dict'], \n",
    "                    prev_state[ptype]['oos_returns_dict'], \n",
    "                    prev_state[ptype]['gross_return'], \n",
    "                    transaction_cost,\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                portfolio_results[ptype]['returns'].append(net_return)\n",
    "                portfolio_results[ptype]['dates'].append(current_date)\n",
    "                portfolio_results[ptype]['weights'].append({})\n",
    "                portfolio_results[ptype]['turnover'].append(turnover)\n",
    "                portfolio_results[ptype]['gross_returns'].append(0.0)\n",
    "                \n",
    "                prev_state[ptype] = {'weights_dict': {}, 'oos_returns_dict': {}, 'gross_return': 0.0}\n",
    "                continue\n",
    "            \n",
    "            # Find common assets between weights and returns\n",
    "            common_assets = set(new_weights_dict.keys()) & set(oos_returns_dict.keys())\n",
    "            \n",
    "            if len(common_assets) == 0:\n",
    "                if verbose and ptype == 'gmv':\n",
    "                    print(f\"  ⚠ No common assets with valid returns\")\n",
    "                \n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    prev_state[ptype]['weights_dict'], \n",
    "                    prev_state[ptype]['oos_returns_dict'], \n",
    "                    prev_state[ptype]['gross_return'], \n",
    "                    transaction_cost,\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                portfolio_results[ptype]['returns'].append(net_return)\n",
    "                portfolio_results[ptype]['dates'].append(current_date)\n",
    "                portfolio_results[ptype]['weights'].append({})\n",
    "                portfolio_results[ptype]['turnover'].append(turnover)\n",
    "                portfolio_results[ptype]['gross_returns'].append(0.0)\n",
    "                \n",
    "                prev_state[ptype] = {'weights_dict': {}, 'oos_returns_dict': {}, 'gross_return': 0.0}\n",
    "                continue\n",
    "            \n",
    "            # Filter to common assets and renormalize\n",
    "            common_weights = {a: new_weights_dict[a] for a in common_assets}\n",
    "            common_weight_sum = sum(common_weights.values())\n",
    "            if common_weight_sum > 1e-10:\n",
    "                common_weights = {k: v/common_weight_sum for k, v in common_weights.items()}\n",
    "            else:\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    prev_state[ptype]['weights_dict'], \n",
    "                    prev_state[ptype]['oos_returns_dict'], \n",
    "                    prev_state[ptype]['gross_return'], \n",
    "                    transaction_cost,\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                portfolio_results[ptype]['returns'].append(net_return)\n",
    "                portfolio_results[ptype]['dates'].append(current_date)\n",
    "                portfolio_results[ptype]['weights'].append({})\n",
    "                portfolio_results[ptype]['turnover'].append(turnover)\n",
    "                portfolio_results[ptype]['gross_returns'].append(0.0)\n",
    "                \n",
    "                prev_state[ptype] = {'weights_dict': {}, 'oos_returns_dict': {}, 'gross_return': 0.0}\n",
    "                continue\n",
    "            \n",
    "            # Compute gross portfolio return\n",
    "            gross_return = sum(common_weights[a] * oos_returns_dict[a] for a in common_assets)\n",
    "            \n",
    "            # Sanity check\n",
    "            if np.isnan(gross_return) or np.isinf(gross_return):\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    prev_state[ptype]['weights_dict'], \n",
    "                    prev_state[ptype]['oos_returns_dict'], \n",
    "                    prev_state[ptype]['gross_return'], \n",
    "                    transaction_cost,\n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                portfolio_results[ptype]['returns'].append(net_return)\n",
    "                portfolio_results[ptype]['dates'].append(current_date)\n",
    "                portfolio_results[ptype]['weights'].append({})\n",
    "                portfolio_results[ptype]['turnover'].append(turnover)\n",
    "                portfolio_results[ptype]['gross_returns'].append(0.0)\n",
    "                \n",
    "                prev_state[ptype] = {'weights_dict': {}, 'oos_returns_dict': {}, 'gross_return': 0.0}\n",
    "                continue\n",
    "            \n",
    "            # Calculate transaction costs\n",
    "            if len(prev_state[ptype]['weights_dict']) > 0:\n",
    "                # Adjust previous weights for returns\n",
    "                adjusted_prev = {}\n",
    "                prev_weights_dict = prev_state[ptype]['weights_dict']\n",
    "                prev_oos_returns_dict = prev_state[ptype]['oos_returns_dict']\n",
    "                prev_gross_return = prev_state[ptype]['gross_return']\n",
    "                \n",
    "                for asset, prev_w in prev_weights_dict.items():\n",
    "                    if asset in prev_oos_returns_dict:\n",
    "                        prev_r = prev_oos_returns_dict[asset]\n",
    "                        if abs(1 + prev_gross_return) > 1e-6:\n",
    "                            adjusted_prev[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return)\n",
    "                        else:\n",
    "                            adjusted_prev[asset] = 0.0\n",
    "                    else:\n",
    "                        if abs(1 + prev_gross_return) > 1e-6:\n",
    "                            adjusted_prev[asset] = prev_w / (1 + prev_gross_return)\n",
    "                        else:\n",
    "                            adjusted_prev[asset] = 0.0\n",
    "                \n",
    "                # Calculate turnover\n",
    "                all_assets = set(adjusted_prev.keys()) | set(common_weights.keys())\n",
    "                turnover = 0.0\n",
    "                for asset in all_assets:\n",
    "                    old_w = adjusted_prev.get(asset, 0.0)\n",
    "                    new_w = common_weights.get(asset, 0.0)\n",
    "                    turnover += abs(new_w - old_w)\n",
    "                \n",
    "                tc = transaction_cost * (1 + gross_return) * turnover\n",
    "            else:\n",
    "                # First period\n",
    "                turnover = sum(abs(w) for w in common_weights.values())\n",
    "                tc = transaction_cost * (1 + gross_return) * turnover\n",
    "            \n",
    "            # Net return\n",
    "            net_return = gross_return - tc\n",
    "            \n",
    "            # Store results\n",
    "            portfolio_results[ptype]['returns'].append(net_return)\n",
    "            portfolio_results[ptype]['dates'].append(current_date)\n",
    "            portfolio_results[ptype]['weights'].append(common_weights.copy())\n",
    "            portfolio_results[ptype]['turnover'].append(turnover)\n",
    "            portfolio_results[ptype]['gross_returns'].append(gross_return)\n",
    "            \n",
    "            # Update previous state\n",
    "            prev_state[ptype] = {\n",
    "                'weights_dict': common_weights.copy(),\n",
    "                'oos_returns_dict': {a: oos_returns_dict[a] for a in common_assets},\n",
    "                'gross_return': gross_return\n",
    "            }\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  GMV  - Gross: {portfolio_results['gmv']['gross_returns'][-1]:>8.5f} | \"\n",
    "                  f\"Turnover: {portfolio_results['gmv']['turnover'][-1]:>6.4f} | \"\n",
    "                  f\"Net: {portfolio_results['gmv']['returns'][-1]:>8.5f}\")\n",
    "            print(f\"  MV   - Gross: {portfolio_results['mv']['gross_returns'][-1]:>8.5f} | \"\n",
    "                  f\"Turnover: {portfolio_results['mv']['turnover'][-1]:>6.4f} | \"\n",
    "                  f\"Net: {portfolio_results['mv']['returns'][-1]:>8.5f}\")\n",
    "            print(f\"  MSR  - Gross: {portfolio_results['msr']['gross_returns'][-1]:>8.5f} | \"\n",
    "                  f\"Turnover: {portfolio_results['msr']['turnover'][-1]:>6.4f} | \"\n",
    "                  f\"Net: {portfolio_results['msr']['returns'][-1]:>8.5f}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BACKTEST COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    # --- 4. Compile Results for Each Portfolio ---\n",
    "    results_dict = {}\n",
    "    \n",
    "    for ptype in ['gmv', 'mv', 'msr']:\n",
    "        results_df = pd.DataFrame({\n",
    "            'date': portfolio_results[ptype]['dates'],\n",
    "            'portfolio_return': portfolio_results[ptype]['returns'],\n",
    "            'portfolio_gross_return': portfolio_results[ptype]['gross_returns'],\n",
    "            'portfolio_weights': portfolio_results[ptype]['weights'],\n",
    "            'portfolio_turnover': portfolio_results[ptype]['turnover']\n",
    "        })\n",
    "        results_df['cumulative_return'] = (1 + results_df['portfolio_return']).cumprod() - 1\n",
    "        \n",
    "        # Compute overall metrics\n",
    "        if len(portfolio_results[ptype]['returns']) > 0:\n",
    "            returns = portfolio_results[ptype]['returns']\n",
    "            mean_return = np.mean(returns)\n",
    "            variance = np.var(returns, ddof=1)\n",
    "            sharpe_ratio = mean_return / np.sqrt(variance) if variance > 0 else 0\n",
    "            \n",
    "            # Annualized metrics (monthly data)\n",
    "            annual_return = mean_return * 12\n",
    "            annual_volatility = np.sqrt(variance * 12)\n",
    "            annual_sharpe = annual_return / annual_volatility if annual_volatility > 0 else 0\n",
    "            \n",
    "            metrics = {\n",
    "                'mean_return': mean_return,\n",
    "                'variance': variance,\n",
    "                'sharpe_ratio': sharpe_ratio,\n",
    "                'annual_return': annual_return,\n",
    "                'annual_volatility': annual_volatility,\n",
    "                'annual_sharpe_ratio': annual_sharpe,\n",
    "                'total_return': results_df['cumulative_return'].iloc[-1],\n",
    "                'avg_turnover': np.mean(portfolio_results[ptype]['turnover']),\n",
    "                'n_periods': len(returns),\n",
    "                'n_zero_periods': sum(1 for r in returns if r == 0)\n",
    "            }\n",
    "        else:\n",
    "            metrics = {\n",
    "                'mean_return': 0,\n",
    "                'variance': 0,\n",
    "                'sharpe_ratio': 0,\n",
    "                'annual_return': 0,\n",
    "                'annual_volatility': 0,\n",
    "                'annual_sharpe_ratio': 0,\n",
    "                'total_return': 0,\n",
    "                'avg_turnover': 0,\n",
    "                'n_periods': 0,\n",
    "                'n_zero_periods': 0\n",
    "            }\n",
    "        \n",
    "        results_dict[ptype] = (results_df, metrics)\n",
    "    \n",
    "    return results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3765c3c-1c95-490b-a755-dc7e34821677",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../green cleaned.csv', dtype={'ncusip': 'string'})\n",
    "df['ret_fwd_1'] = df.groupby('permno')['ret_excess'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27f275bf-5af3-4b17-b231-0f21d8d3df72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded recommendation changes: 16960 records\n",
      "Strategy: BUY threshold <= -0.5, SELL threshold >= 0.5\n",
      "============================================================\n",
      "STARTING BACKTEST WITH FACTOR-BASED NODEWISE + ANALYST SIGNALS\n",
      "============================================================\n",
      "\n",
      "[1/52] Date: 2020-01-31 | Year: 2020\n",
      "  Window: 2005-01-31 to 2019-12-31\n",
      " Analyst: 71 |  | Assets w/ data: 41\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.09814 | Turnover: 1.7567 | Net: -0.09972\n",
      "  MV   - Gross: -0.09190 | Turnover: 1.7744 | Net: -0.09351\n",
      "  MSR  - Gross: -0.06000 | Turnover: 2.6891 | Net: -0.06253\n",
      "\n",
      "[2/52] Date: 2020-02-29 | Year: 2020\n",
      "  Window: 2005-02-28 to 2020-01-31\n",
      " Analyst: 73 |  | Assets w/ data: 38\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.07945 | Turnover: 2.6413 | Net: -0.08189\n",
      "  MV   - Gross: -0.08874 | Turnover: 2.6729 | Net: -0.09117\n",
      "  MSR  - Gross:  0.02090 | Turnover: 3.7678 | Net:  0.01705\n",
      "\n",
      "[3/52] Date: 2020-03-31 | Year: 2020\n",
      "  Window: 2005-03-31 to 2020-02-29\n",
      " Analyst: 174 |  | Assets w/ data: 87\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.07112 | Turnover: 2.6275 | Net:  0.06831\n",
      "  MV   - Gross:  0.06637 | Turnover: 2.6295 | Net:  0.06357\n",
      "  MSR  - Gross:  0.02550 | Turnover: 3.5084 | Net:  0.02190\n",
      "\n",
      "[4/52] Date: 2020-04-30 | Year: 2020\n",
      "  Window: 2005-04-30 to 2020-03-31\n",
      " Analyst: 203 |  | Assets w/ data: 95\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.00145 | Turnover: 2.2128 | Net: -0.00076\n",
      "  MV   - Gross:  0.00786 | Turnover: 2.1858 | Net:  0.00565\n",
      "  MSR  - Gross:  0.03789 | Turnover: 4.1451 | Net:  0.03359\n",
      "\n",
      "[5/52] Date: 2020-05-31 | Year: 2020\n",
      "  Window: 2005-05-31 to 2020-04-30\n",
      " Analyst: 123 |  | Assets w/ data: 50\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.05324 | Turnover: 3.4298 | Net: -0.05648\n",
      "  MV   - Gross: -0.04982 | Turnover: 3.4637 | Net: -0.05311\n",
      "  MSR  - Gross: -0.03155 | Turnover: 5.5037 | Net: -0.03688\n",
      "\n",
      "[6/52] Date: 2020-06-30 | Year: 2020\n",
      "  Window: 2005-06-30 to 2020-05-31\n",
      " Analyst: 110 |  | Assets w/ data: 46\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.04673 | Turnover: 3.5927 | Net:  0.04296\n",
      "  MV   - Gross:  0.05182 | Turnover: 3.5719 | Net:  0.04807\n",
      "  MSR  - Gross:  0.08949 | Turnover: 5.6548 | Net:  0.08333\n",
      "\n",
      "[7/52] Date: 2020-07-31 | Year: 2020\n",
      "  Window: 2005-07-31 to 2020-06-30\n",
      " Analyst: 138 |  | Assets w/ data: 72\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.00119 | Turnover: 3.3536 | Net: -0.00454\n",
      "  MV   - Gross:  0.00870 | Turnover: 3.4321 | Net:  0.00523\n",
      "  MSR  - Gross:  0.05176 | Turnover: 5.6231 | Net:  0.04584\n",
      "\n",
      "[8/52] Date: 2020-08-31 | Year: 2020\n",
      "  Window: 2005-08-31 to 2020-07-31\n",
      " Analyst: 67 |  | Assets w/ data: 20\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.00711 | Turnover: 3.1112 | Net:  0.00398\n",
      "  MV   - Gross:  0.01399 | Turnover: 3.1308 | Net:  0.01081\n",
      "  MSR  - Gross:  0.04615 | Turnover: 5.4934 | Net:  0.04040\n",
      "\n",
      "[9/52] Date: 2020-09-30 | Year: 2020\n",
      "  Window: 2005-09-30 to 2020-08-31\n",
      " Analyst: 111 |  | Assets w/ data: 46\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.01907 | Turnover: 2.8782 | Net: -0.02190\n",
      "  MV   - Gross: -0.01789 | Turnover: 2.8969 | Net: -0.02074\n",
      "  MSR  - Gross: -0.00933 | Turnover: 4.3794 | Net: -0.01367\n",
      "\n",
      "[10/52] Date: 2020-10-31 | Year: 2020\n",
      "  Window: 2005-10-31 to 2020-09-30\n",
      " Analyst: 94 |  | Assets w/ data: 38\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.05119 | Turnover: 3.5550 | Net:  0.04746\n",
      "  MV   - Gross:  0.02763 | Turnover: 3.5800 | Net:  0.02395\n",
      "  MSR  - Gross: -0.17437 | Turnover: 6.5126 | Net: -0.17975\n",
      "\n",
      "[11/52] Date: 2020-11-30 | Year: 2020\n",
      "  Window: 2005-11-30 to 2020-10-31\n",
      " Analyst: 110 |  | Assets w/ data: 55\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.02450 | Turnover: 3.4290 | Net: -0.02785\n",
      "  MV   - Gross: -0.02474 | Turnover: 3.5435 | Net: -0.02819\n",
      "  MSR  - Gross: -0.07213 | Turnover: 6.8918 | Net: -0.07852\n",
      "\n",
      "[12/52] Date: 2020-12-31 | Year: 2020\n",
      "  Window: 2005-12-31 to 2020-11-30\n",
      " Analyst: 75 |  | Assets w/ data: 33\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.01030 | Turnover: 2.9273 | Net: -0.01319\n",
      "  MV   - Gross: -0.01634 | Turnover: 3.0106 | Net: -0.01930\n",
      "  MSR  - Gross: -0.07169 | Turnover: 5.1079 | Net: -0.07643\n",
      "\n",
      "[13/52] Date: 2021-01-31 | Year: 2021\n",
      "  Window: 2006-01-31 to 2020-12-31\n",
      " Analyst: 116 |  | Assets w/ data: 60\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.02624 | Turnover: 3.5014 | Net: -0.02965\n",
      "  MV   - Gross: -0.03478 | Turnover: 3.6571 | Net: -0.03831\n",
      "  MSR  - Gross: -0.09091 | Turnover: 6.4913 | Net: -0.09682\n",
      "\n",
      "[14/52] Date: 2021-02-28 | Year: 2021\n",
      "  Window: 2006-02-28 to 2021-01-31\n",
      " Analyst: 87 |  | Assets w/ data: 42\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.07927 | Turnover: 2.7962 | Net:  0.07625\n",
      "  MV   - Gross:  0.07502 | Turnover: 2.8780 | Net:  0.07192\n",
      "  MSR  - Gross:  0.06154 | Turnover: 5.1544 | Net:  0.05607\n",
      "\n",
      "[15/52] Date: 2021-03-31 | Year: 2021\n",
      "  Window: 2006-03-31 to 2021-02-28\n",
      " Analyst: 103 |  | Assets w/ data: 43\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.00670 | Turnover: 2.8311 | Net:  0.00385\n",
      "  MV   - Gross:  0.00618 | Turnover: 2.8529 | Net:  0.00331\n",
      "  MSR  - Gross:  0.00273 | Turnover: 4.0000 | Net: -0.00128\n",
      "\n",
      "[16/52] Date: 2021-04-30 | Year: 2021\n",
      "  Window: 2006-04-30 to 2021-03-31\n",
      " Analyst: 104 |  | Assets w/ data: 59\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.00894 | Turnover: 2.7463 | Net: -0.01166\n",
      "  MV   - Gross: -0.00960 | Turnover: 2.8399 | Net: -0.01241\n",
      "  MSR  - Gross: -0.04187 | Turnover: 4.5833 | Net: -0.04626\n",
      "\n",
      "[17/52] Date: 2021-05-31 | Year: 2021\n",
      "  Window: 2006-05-31 to 2021-04-30\n",
      " Analyst: 92 |  | Assets w/ data: 41\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.02608 | Turnover: 3.1767 | Net: -0.02917\n",
      "  MV   - Gross: -0.01539 | Turnover: 3.1646 | Net: -0.01851\n",
      "  MSR  - Gross:  0.08039 | Turnover: 5.3418 | Net:  0.07462\n",
      "\n",
      "[18/52] Date: 2021-06-30 | Year: 2021\n",
      "  Window: 2006-06-30 to 2021-05-31\n",
      " Analyst: 100 |  | Assets w/ data: 48\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.04844 | Turnover: 2.8505 | Net:  0.04545\n",
      "  MV   - Gross:  0.05615 | Turnover: 2.8548 | Net:  0.05314\n",
      "  MSR  - Gross:  0.10845 | Turnover: 4.5613 | Net:  0.10339\n",
      "\n",
      "[19/52] Date: 2021-07-31 | Year: 2021\n",
      "  Window: 2006-07-31 to 2021-06-30\n",
      " Analyst: 77 |  | Assets w/ data: 42\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.00342 | Turnover: 2.5820 | Net:  0.00083\n",
      "  MV   - Gross:  0.00308 | Turnover: 2.5894 | Net:  0.00049\n",
      "  MSR  - Gross: -0.01387 | Turnover: 3.8050 | Net: -0.01762\n",
      "\n",
      "[20/52] Date: 2021-08-31 | Year: 2021\n",
      "  Window: 2006-08-31 to 2021-07-31\n",
      " Analyst: 65 |  | Assets w/ data: 28\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.03259 | Turnover: 2.6583 | Net: -0.03516\n",
      "  MV   - Gross: -0.03311 | Turnover: 2.6350 | Net: -0.03566\n",
      "  MSR  - Gross: -0.04713 | Turnover: 3.6976 | Net: -0.05065\n",
      "\n",
      "[21/52] Date: 2021-09-30 | Year: 2021\n",
      "  Window: 2006-09-30 to 2021-08-31\n",
      " Analyst: 80 |  | Assets w/ data: 32\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.03192 | Turnover: 2.4790 | Net:  0.02936\n",
      "  MV   - Gross:  0.03684 | Turnover: 2.4675 | Net:  0.03428\n",
      "  MSR  - Gross:  0.07924 | Turnover: 3.5248 | Net:  0.07543\n",
      "\n",
      "[22/52] Date: 2021-10-31 | Year: 2021\n",
      "  Window: 2006-10-31 to 2021-09-30\n",
      " Analyst: 141 |  | Assets w/ data: 70\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.02572 | Turnover: 3.3322 | Net: -0.02897\n",
      "  MV   - Gross: -0.00342 | Turnover: 3.2962 | Net: -0.00670\n",
      "  MSR  - Gross:  0.08670 | Turnover: 4.5455 | Net:  0.08176\n",
      "\n",
      "[23/52] Date: 2021-11-30 | Year: 2021\n",
      "  Window: 2006-11-30 to 2021-10-31\n",
      " Analyst: 103 |  | Assets w/ data: 57\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.06529 | Turnover: 2.8551 | Net:  0.06225\n",
      "  MV   - Gross:  0.06284 | Turnover: 2.9632 | Net:  0.05969\n",
      "  MSR  - Gross:  0.05280 | Turnover: 5.3858 | Net:  0.04713\n",
      "\n",
      "[24/52] Date: 2021-12-31 | Year: 2021\n",
      "  Window: 2006-12-31 to 2021-11-30\n",
      " Analyst: 63 |  | Assets w/ data: 35\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.01366 | Turnover: 2.7768 | Net: -0.01639\n",
      "  MV   - Gross: -0.03139 | Turnover: 2.9064 | Net: -0.03420\n",
      "  MSR  - Gross: -0.13329 | Turnover: 5.5495 | Net: -0.13810\n",
      "\n",
      "[25/52] Date: 2022-01-31 | Year: 2022\n",
      "  Window: 2007-01-31 to 2021-12-31\n",
      " Analyst: 114 |  | Assets w/ data: 62\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.02155 | Turnover: 3.1124 | Net: -0.02459\n",
      "  MV   - Gross: -0.02977 | Turnover: 3.1729 | Net: -0.03284\n",
      "  MSR  - Gross: -0.06080 | Turnover: 6.1709 | Net: -0.06659\n",
      "\n",
      "[26/52] Date: 2022-02-28 | Year: 2022\n",
      "  Window: 2007-02-28 to 2022-01-31\n",
      " Analyst: 99 |  | Assets w/ data: 45\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.06326 | Turnover: 2.1239 | Net:  0.06100\n",
      "  MV   - Gross:  0.06463 | Turnover: 2.1306 | Net:  0.06236\n",
      "  MSR  - Gross:  0.07005 | Turnover: 3.6995 | Net:  0.06609\n",
      "\n",
      "[27/52] Date: 2022-03-31 | Year: 2022\n",
      "  Window: 2007-03-31 to 2022-02-28\n",
      " Analyst: 88 |  | Assets w/ data: 53\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.02459 | Turnover: 3.1498 | Net:  0.02137\n",
      "  MV   - Gross:  0.02167 | Turnover: 3.3009 | Net:  0.01829\n",
      "  MSR  - Gross: -0.02182 | Turnover: 5.0763 | Net: -0.02678\n",
      "\n",
      "[28/52] Date: 2022-04-30 | Year: 2022\n",
      "  Window: 2007-04-30 to 2022-03-31\n",
      " Analyst: 101 |  | Assets w/ data: 52\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.02758 | Turnover: 2.7667 | Net:  0.02474\n",
      "  MV   - Gross:  0.00890 | Turnover: 2.9319 | Net:  0.00594\n",
      "  MSR  - Gross: -0.04063 | Turnover: 4.3998 | Net: -0.04485\n",
      "\n",
      "[29/52] Date: 2022-05-31 | Year: 2022\n",
      "  Window: 2007-05-31 to 2022-04-30\n",
      " Analyst: 78 |  | Assets w/ data: 37\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.00142 | Turnover: 2.1493 | Net: -0.00357\n",
      "  MV   - Gross: -0.00556 | Turnover: 2.4348 | Net: -0.00798\n",
      "  MSR  - Gross: -0.03017 | Turnover: 3.7399 | Net: -0.03379\n",
      "\n",
      "[30/52] Date: 2022-06-30 | Year: 2022\n",
      "  Window: 2007-06-30 to 2022-05-31\n",
      " Analyst: 96 |  | Assets w/ data: 47\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.00711 | Turnover: 3.0378 | Net: -0.01013\n",
      "  MV   - Gross: -0.00290 | Turnover: 3.0658 | Net: -0.00596\n",
      "  MSR  - Gross:  0.04761 | Turnover: 4.8917 | Net:  0.04248\n",
      "\n",
      "[31/52] Date: 2022-07-31 | Year: 2022\n",
      "  Window: 2007-07-31 to 2022-06-30\n",
      " Analyst: 100 |  | Assets w/ data: 49\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.05100 | Turnover: 3.0321 | Net: -0.05388\n",
      "  MV   - Gross: -0.05040 | Turnover: 2.9921 | Net: -0.05324\n",
      "  MSR  - Gross: -0.04735 | Turnover: 5.1963 | Net: -0.05230\n",
      "\n",
      "[32/52] Date: 2022-08-31 | Year: 2022\n",
      "  Window: 2007-08-31 to 2022-07-31\n",
      " Analyst: 80 |  | Assets w/ data: 34\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.05295 | Turnover: 3.0680 | Net: -0.05586\n",
      "  MV   - Gross: -0.05233 | Turnover: 3.1713 | Net: -0.05533\n",
      "  MSR  - Gross: -0.02812 | Turnover: 5.5711 | Net: -0.03354\n",
      "\n",
      "[33/52] Date: 2022-09-30 | Year: 2022\n",
      "  Window: 2007-09-30 to 2022-08-31\n",
      " Analyst: 79 |  | Assets w/ data: 35\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.08923 | Turnover: 2.9561 | Net:  0.08601\n",
      "  MV   - Gross:  0.08763 | Turnover: 2.9713 | Net:  0.08439\n",
      "  MSR  - Gross:  0.12585 | Turnover: 4.6727 | Net:  0.12059\n",
      "\n",
      "[34/52] Date: 2022-10-31 | Year: 2022\n",
      "  Window: 2007-10-31 to 2022-09-30\n",
      " Analyst: 88 |  | Assets w/ data: 51\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.05872 | Turnover: 2.9968 | Net:  0.05554\n",
      "  MV   - Gross:  0.05906 | Turnover: 2.9589 | Net:  0.05593\n",
      "  MSR  - Gross:  0.06098 | Turnover: 3.8375 | Net:  0.05691\n",
      "\n",
      "[35/52] Date: 2022-11-30 | Year: 2022\n",
      "  Window: 2007-11-30 to 2022-10-31\n",
      " Analyst: 79 |  | Assets w/ data: 42\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.00840 | Turnover: 2.6076 | Net: -0.01098\n",
      "  MV   - Gross: -0.01521 | Turnover: 2.5212 | Net: -0.01769\n",
      "  MSR  - Gross: -0.05754 | Turnover: 3.6780 | Net: -0.06101\n",
      "\n",
      "[36/52] Date: 2022-12-31 | Year: 2022\n",
      "  Window: 2007-12-31 to 2022-11-30\n",
      " Analyst: 50 |  | Assets w/ data: 28\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.03172 | Turnover: 2.8141 | Net: -0.03445\n",
      "  MV   - Gross: -0.03106 | Turnover: 2.7354 | Net: -0.03371\n",
      "  MSR  - Gross: -0.01841 | Turnover: 4.4832 | Net: -0.02281\n",
      "\n",
      "[37/52] Date: 2023-01-31 | Year: 2023\n",
      "  Window: 2008-01-31 to 2022-12-31\n",
      " Analyst: 98 |  | Assets w/ data: 47\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.02802 | Turnover: 3.1195 | Net: -0.03105\n",
      "  MV   - Gross: -0.03196 | Turnover: 3.1941 | Net: -0.03505\n",
      "  MSR  - Gross: -0.05269 | Turnover: 5.4734 | Net: -0.05787\n",
      "\n",
      "[38/52] Date: 2023-02-28 | Year: 2023\n",
      "  Window: 2008-02-29 to 2023-01-31\n",
      " Analyst: 99 |  | Assets w/ data: 38\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.00653 | Turnover: 2.7353 | Net:  0.00378\n",
      "  MV   - Gross:  0.00962 | Turnover: 2.7496 | Net:  0.00685\n",
      "  MSR  - Gross:  0.06480 | Turnover: 5.1984 | Net:  0.05927\n",
      "\n",
      "[39/52] Date: 2023-03-31 | Year: 2023\n",
      "  Window: 2008-03-31 to 2023-02-28\n",
      " Analyst: 70 |  | Assets w/ data: 27\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.03160 | Turnover: 2.7259 | Net:  0.02879\n",
      "  MV   - Gross:  0.03209 | Turnover: 2.7354 | Net:  0.02927\n",
      "  MSR  - Gross:  0.04583 | Turnover: 4.6899 | Net:  0.04093\n",
      "\n",
      "[40/52] Date: 2023-04-30 | Year: 2023\n",
      "  Window: 2008-04-30 to 2023-03-31\n",
      " Analyst: 88 |  | Assets w/ data: 34\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.04597 | Turnover: 2.9996 | Net: -0.04883\n",
      "  MV   - Gross: -0.03562 | Turnover: 3.1242 | Net: -0.03863\n",
      "  MSR  - Gross: -0.06857 | Turnover: 3.9853 | Net: -0.07228\n",
      "\n",
      "[41/52] Date: 2023-05-31 | Year: 2023\n",
      "  Window: 2008-05-31 to 2023-04-30\n",
      " Analyst: 67 |  | Assets w/ data: 32\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.02888 | Turnover: 3.6260 | Net:  0.02515\n",
      "  MV   - Gross:  0.02897 | Turnover: 3.7035 | Net:  0.02515\n",
      "  MSR  - Gross:  0.02736 | Turnover: 5.2285 | Net:  0.02199\n",
      "\n",
      "[42/52] Date: 2023-06-30 | Year: 2023\n",
      "  Window: 2008-06-30 to 2023-05-31\n",
      " Analyst: 68 |  | Assets w/ data: 28\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.00575 | Turnover: 3.5686 | Net: -0.00930\n",
      "  MV   - Gross: -0.00558 | Turnover: 3.5912 | Net: -0.00915\n",
      "  MSR  - Gross: -0.00259 | Turnover: 5.1238 | Net: -0.00770\n",
      "\n",
      "[43/52] Date: 2023-07-31 | Year: 2023\n",
      "  Window: 2008-07-31 to 2023-06-30\n",
      " Analyst: 82 |  | Assets w/ data: 44\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.04037 | Turnover: 2.3193 | Net: -0.04259\n",
      "  MV   - Gross: -0.04302 | Turnover: 2.3444 | Net: -0.04526\n",
      "  MSR  - Gross: -0.00117 | Turnover: 3.6215 | Net: -0.00478\n",
      "\n",
      "[44/52] Date: 2023-08-31 | Year: 2023\n",
      "  Window: 2008-08-31 to 2023-07-31\n",
      " Analyst: 93 |  | Assets w/ data: 44\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.04570 | Turnover: 2.4277 | Net: -0.04802\n",
      "  MV   - Gross: -0.05245 | Turnover: 2.6053 | Net: -0.05492\n",
      "  MSR  - Gross: -0.08781 | Turnover: 5.2118 | Net: -0.09256\n",
      "\n",
      "[45/52] Date: 2023-09-30 | Year: 2023\n",
      "  Window: 2008-09-30 to 2023-08-31\n",
      " Analyst: 83 |  | Assets w/ data: 36\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.02238 | Turnover: 3.3165 | Net: -0.02562\n",
      "  MV   - Gross: -0.02887 | Turnover: 3.4731 | Net: -0.03224\n",
      "  MSR  - Gross:  0.03347 | Turnover: 5.4991 | Net:  0.02778\n",
      "\n",
      "[46/52] Date: 2023-10-31 | Year: 2023\n",
      "  Window: 2008-10-31 to 2023-09-30\n",
      " Analyst: 112 |  | Assets w/ data: 51\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.03651 | Turnover: 3.6608 | Net:  0.03272\n",
      "  MV   - Gross:  0.03597 | Turnover: 3.7054 | Net:  0.03213\n",
      "  MSR  - Gross:  0.03216 | Turnover: 5.3508 | Net:  0.02664\n",
      "\n",
      "[47/52] Date: 2023-11-30 | Year: 2023\n",
      "  Window: 2008-11-30 to 2023-10-31\n",
      " Analyst: 91 |  | Assets w/ data: 37\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.00758 | Turnover: 2.9540 | Net:  0.00460\n",
      "  MV   - Gross:  0.00725 | Turnover: 2.8852 | Net:  0.00435\n",
      "  MSR  - Gross: -0.02347 | Turnover: 4.6610 | Net: -0.02802\n",
      "\n",
      "[48/52] Date: 2023-12-31 | Year: 2023\n",
      "  Window: 2008-12-31 to 2023-11-30\n",
      " Analyst: 87 |  | Assets w/ data: 40\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.00846 | Turnover: 3.4774 | Net:  0.00495\n",
      "  MV   - Gross:  0.00421 | Turnover: 3.5166 | Net:  0.00068\n",
      "  MSR  - Gross:  0.04115 | Turnover: 5.5913 | Net:  0.03533\n",
      "\n",
      "[49/52] Date: 2024-01-31 | Year: 2024\n",
      "  Window: 2009-01-31 to 2023-12-31\n",
      " Analyst: 106 |  | Assets w/ data: 60\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.00199 | Turnover: 3.1490 | Net: -0.00117\n",
      "  MV   - Gross:  0.00696 | Turnover: 3.2121 | Net:  0.00372\n",
      "  MSR  - Gross:  0.08033 | Turnover: 5.4842 | Net:  0.07441\n",
      "\n",
      "[50/52] Date: 2024-02-29 | Year: 2024\n",
      "  Window: 2009-02-28 to 2024-01-31\n",
      " Analyst: 114 |  | Assets w/ data: 57\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.03110 | Turnover: 2.5979 | Net:  0.02842\n",
      "  MV   - Gross:  0.03309 | Turnover: 2.5970 | Net:  0.03041\n",
      "  MSR  - Gross:  0.04718 | Turnover: 5.2308 | Net:  0.04170\n",
      "\n",
      "[51/52] Date: 2024-03-31 | Year: 2024\n",
      "  Window: 2009-03-31 to 2024-02-29\n",
      " Analyst: 71 |  | Assets w/ data: 45\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross: -0.01832 | Turnover: 2.6222 | Net: -0.02089\n",
      "  MV   - Gross: -0.01843 | Turnover: 2.7086 | Net: -0.02109\n",
      "  MSR  - Gross: -0.01653 | Turnover: 4.3545 | Net: -0.02081\n",
      "\n",
      "[52/52] Date: 2024-04-30 | Year: 2024\n",
      "  Window: 2009-04-30 to 2024-03-31\n",
      " Analyst: 94 |  | Assets w/ data: 45\n",
      "  Running Residual Nodewise Regression...\n",
      "  Computing portfolio weights...\n",
      "  GMV  - Gross:  0.04333 | Turnover: 3.2355 | Net:  0.03995\n",
      "  MV   - Gross:  0.04401 | Turnover: 3.2446 | Net:  0.04063\n",
      "  MSR  - Gross:  0.09243 | Turnover: 5.1242 | Net:  0.08683\n",
      "\n",
      "============================================================\n",
      "BACKTEST COMPLETE\n",
      "============================================================\n",
      "GMV Sharpe: -0.132\n",
      "MV Sharpe: -0.189\n",
      "MSR Sharpe: -0.044\n"
     ]
    }
   ],
   "source": [
    "# Run backtest with factor-based nodewise regression\n",
    "results = backtest_factor_nodewise_gmv_analyst(\n",
    "    df,\n",
    "    factors_path='../AI Portfolio Selection/factors_ff_monthly_raw.csv',\n",
    "    test_start_date='2020-01-31',\n",
    "    test_end_date='2024-04-30',\n",
    "    lookback_window=180,\n",
    "    transaction_cost=0.001,\n",
    "    rec_changes_path='monthly_mean_recommendations_decay.csv',  # Required!\n",
    "    ic='GIC',  # or 'BIC', 'WIC', 'AIC', 'cv'\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Access individual results\n",
    "gmv_df, gmv_metrics = results['gmv']\n",
    "mv_df, mv_metrics = results['mv']\n",
    "msr_df, msr_metrics = results['msr']\n",
    "\n",
    "# Compare Sharpe ratios\n",
    "print(f\"GMV Sharpe: {gmv_metrics['annual_sharpe_ratio']:.3f}\")\n",
    "print(f\"MV Sharpe: {mv_metrics['annual_sharpe_ratio']:.3f}\")\n",
    "print(f\"MSR Sharpe: {msr_metrics['annual_sharpe_ratio']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3954585e-e8f6-4347-b6a3-78f6a1acd570",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
