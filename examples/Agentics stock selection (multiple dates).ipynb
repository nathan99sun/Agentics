{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1fce1ad-660e-4e1c-ad46-b393d22e93d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables = ['datadate', 'ticker', 'agr', 'bm', 'mom12m', 'mve', 'operprof', 'roeq', 'absacc', 'acc', 'aeavol', 'age', 'baspread', 'BETA', 'bm_ia', \n",
    "#              'cash', 'cashdebt', 'cashpr', 'cfp', 'cfp_ia', 'chatoia', 'chcsho', 'chempia', 'chfeps', 'chinv', 'chmom', 'chnanalyst', \n",
    "#              'chpmia', 'chtx', 'cinvest', 'convind', 'currat', 'depr', 'disp', 'divi', 'divo', 'dy', 'ear', 'egr', 'ep', 'fgr5yr', \n",
    "#              'gma', 'grcapx', 'grltnoa', 'herf', 'hire', 'idiovol', 'ill', 'indmom', 'invest', 'IPO', 'lev', 'mom1m', 'mom36m', 'ms', \n",
    "#              'mve_ia', 'nanalyst', 'nincr', 'orgcap', 'pchcapx_ia', 'pchcurrat', 'pchdepr', 'pchgm_pchsale', 'pchsale_pchinvt', \n",
    "#              'pchsale_pchrect', 'pchsale_pchxsga', 'pchsaleinv', 'pctacc', 'pricedelay', 'ps', 'rd', 'rd_mve', 'rd_sale', 'realestate', \n",
    "#              'retvol', 'roaq', 'roavol', 'roic', 'rsup', 'salecash', 'saleinv', 'salerec', 'secured', 'securedind', 'sfe', 'sgr', 'sin', \n",
    "#              'sp', 'std_dolvol', 'std_turn', 'stdcf', 'sue', 'tang', 'tb', 'turn', 'zerotrade']\n",
    "variables = ['datadate', 'ticker', 'bm', 'mom12m', 'mve', 'ret_fwd_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46bffce4-f576-42f1-bbe9-42feaab675bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w3/6myr5tjs6ls3zn1g3ywbc29r0000gn/T/ipykernel_8294/2012901010.py:4: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  green_cleaned = pd.read_csv('../green cleaned.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "green_cleaned = pd.read_csv('../green cleaned.csv')\n",
    "green_cleaned['ret_fwd_1'] = (green_cleaned.groupby('permno')['ret_excess'].shift(-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2d5c6da-7929-41c6-b54d-5428d22998c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cleaned = green_cleaned[green_cleaned['datadate'] < '2020-01-31']\n",
    "green_cleaned.loc[green_cleaned['datadate'] == '2019-12-31', 'ret_fwd_1'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cb83b05-6081-4eb2-b88c-de02da3558d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cleaned.to_csv('green_cleaned_pre_2020.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4387ac5c-b84e-4a37-846a-c213f5b520a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from agentics import AG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "066ca67c-1e8a-4226-8e19-dc0f88e28b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#green_cleaned = AG.from_csv('../green cleaned.csv', max_rows = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfc282d2-247e-4835-abdb-5171e5042119",
   "metadata": {},
   "outputs": [],
   "source": [
    "#green_cleaned[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "490758f7-4b2a-4350-804c-f0d80501c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in green_cleaned:\n",
    "#     print(x.bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b31bf6-6439-405d-8801-079b2b7e7266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #green_cleaned = green_cleaned.add_attribute('recommendation', description='Buy, hold, or sell recommendation for given ticker')\n",
    "# from pydantic import BaseModel\n",
    "\n",
    "# class Recommendation(BaseModel):\n",
    "#     recommendation: str | None = None\n",
    "\n",
    "# target = AG(atype = Recommendation, instructions='Determine a buy, hold, or sell for given ticker.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a171469-3ef1-4614-bc74-fff30f167f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = await (target << green_cleaned)\n",
    "# output.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf15d82-8de2-42d8-a1b8-2364ab588cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#green_cleaned = await green_cleaned.self_transduction(['bm', 'mve', 'mom12m', 'ticker'], ['recommendation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cddfad-1b90-43d8-8822-765eb4321c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50df8c33-46ab-4c05-a052-9d2e4073315f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your GEMINI_API_KEY: Â·Â·Â·Â·Â·Â·Â·Â·\n"
     ]
    }
   ],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "#load_dotenv(find_dotenv())\n",
    "\n",
    "if not os.getenv(\"GEMINI_API_KEY\"):\n",
    "    os.environ[\"GEMINI_API_KEY\"] = getpass(\"Enter your GEMINI_API_KEY:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab25f5e-2da8-470a-9ffd-72d61af0d656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EMPIRICAL STRATEGY DEVELOPER\n",
      "======================================================================\n",
      "\n",
      "Learns from historical data (1990-2019) to develop trading rules\n",
      "Uses 30 years of characteristic-return relationships\n",
      "\n",
      "The agent will:\n",
      "  1. Analyze which characteristics predicted returns historically\n",
      "  2. Test different threshold combinations\n",
      "  3. Validate strategy with historical backtests\n",
      "  4. Output evidence-based rules for December 2019\n",
      "======================================================================\n",
      "\n",
      "âš  WARNING: 'ret_fwd_1' column not found in database!\n",
      "The agent needs forward returns to learn from historical data.\n",
      "Please ensure your CSV includes a 'ret_fwd_1' column with future returns.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 833\u001b[39m\n\u001b[32m    830\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m    831\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43mPress Enter to start empirical strategy development...\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    836\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mðŸš€ Starting empirical analysis...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/agentics/lib/python3.12/site-packages/ipykernel/kernelbase.py:1473\u001b[39m, in \u001b[36mKernel.raw_input\u001b[39m\u001b[34m(self, prompt)\u001b[39m\n\u001b[32m   1471\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1472\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1473\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1474\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1475\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_shell_parent_ident\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1476\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mshell\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1477\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1478\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/opt/anaconda3/envs/agentics/lib/python3.12/site-packages/ipykernel/kernelbase.py:1518\u001b[39m, in \u001b[36mKernel._input_request\u001b[39m\u001b[34m(self, prompt, ident, parent, password)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1516\u001b[39m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[32m   1517\u001b[39m     msg = \u001b[33m\"\u001b[39m\u001b[33mInterrupted by user\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1518\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1519\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1520\u001b[39m     \u001b[38;5;28mself\u001b[39m.log.warning(\u001b[33m\"\u001b[39m\u001b[33mInvalid Message:\u001b[39m\u001b[33m\"\u001b[39m, exc_info=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from crewai.tools import tool\n",
    "from crewai import Agent, Task, Crew, Process\n",
    "from agentics import AG\n",
    "import time\n",
    "from functools import wraps\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "\n",
    "# ============================================\n",
    "# Rate Limiting Setup\n",
    "# ============================================\n",
    "class RateLimiter:\n",
    "    def __init__(self, calls_per_minute=5):\n",
    "        self.calls_per_minute = calls_per_minute\n",
    "        self.interval = 60.0 / calls_per_minute\n",
    "        self.last_call = 0\n",
    "        self.call_count = 0\n",
    "        \n",
    "    def wait_if_needed(self):\n",
    "        \"\"\"Wait if necessary to respect rate limit.\"\"\"\n",
    "        current_time = time.time()\n",
    "        time_since_last = current_time - self.last_call\n",
    "        \n",
    "        if time_since_last < self.interval:\n",
    "            sleep_time = self.interval - time_since_last\n",
    "            print(f\"[Rate Limit] Waiting {sleep_time:.2f}s (Call #{self.call_count + 1})\")\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "        self.last_call = time.time()\n",
    "        self.call_count += 1\n",
    "\n",
    "rate_limiter = RateLimiter(calls_per_minute=5)\n",
    "\n",
    "def rate_limit(func):\n",
    "    \"\"\"Decorator with retry logic for rate limiting.\"\"\"\n",
    "    @wraps(func)\n",
    "    @retry(\n",
    "        retry=retry_if_exception_type((Exception,)),\n",
    "        wait=wait_exponential(multiplier=1, min=4, max=60),\n",
    "        stop=stop_after_attempt(5)\n",
    "    )\n",
    "    def wrapper(*args, **kwargs):\n",
    "        rate_limiter.wait_if_needed()\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"[Error] {func.__name__} failed: {str(e)}\")\n",
    "            raise\n",
    "    return wrapper\n",
    "\n",
    "# ============================================\n",
    "# Database Setup\n",
    "# ============================================\n",
    "def setup_firm_database(csv_path, db_path='firm_data.db', selected_columns=None):\n",
    "    \"\"\"\n",
    "    Load your CSV into SQLite database (run this once).\n",
    "    \n",
    "    IMPORTANT: CSV must include a 'ret' column for forward returns\n",
    "    (i.e., the return in the NEXT period after the characteristics)\n",
    "    \"\"\"\n",
    "    print(f\"Loading CSV from {csv_path}...\")\n",
    "    \n",
    "    sample_df = pd.read_csv(csv_path, nrows=5)\n",
    "    \n",
    "    if selected_columns is None:\n",
    "        print(f\"\\nAvailable columns ({len(sample_df.columns)} total):\")\n",
    "        for i, col in enumerate(sample_df.columns, 1):\n",
    "            print(f\"  {i}. {col}\")\n",
    "        \n",
    "        response = input(\"\\nPress Enter to use ALL columns, or type 'stop' to exit: \").strip()\n",
    "        if response.lower() == 'stop':\n",
    "            print(\"Exiting.\")\n",
    "            return\n",
    "        selected_columns = sample_df.columns.tolist()\n",
    "    else:\n",
    "        missing = [col for col in selected_columns if col not in sample_df.columns]\n",
    "        if missing:\n",
    "            print(f\"\\nâŒ Error: These columns don't exist: {missing}\")\n",
    "            return\n",
    "    \n",
    "    # Ensure 'ret_fwd_1' column is included for return analysis\n",
    "    if 'ret_fwd_1' not in selected_columns:\n",
    "        print(\"âš  Warning: 'ret_fwd_1' column not found. Adding it for return analysis.\")\n",
    "        if 'ret_fwd_1' in sample_df.columns:\n",
    "            selected_columns.append('ret_fwd_1')\n",
    "    \n",
    "    clean_columns = [col.replace(' ', '_').replace('-', '_').replace('.', '_')\n",
    "                    .replace('(', '').replace(')', '').replace('/', '_') \n",
    "                    for col in selected_columns]\n",
    "    \n",
    "    import os\n",
    "    if os.path.exists(db_path):\n",
    "        os.remove(db_path)\n",
    "    \n",
    "    chunk_size = 50000\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    first_chunk = True\n",
    "    chunk_num = 0\n",
    "    total_rows = 0\n",
    "    \n",
    "    print(\"\\nLoading data...\")\n",
    "    for chunk in pd.read_csv(csv_path, chunksize=chunk_size, usecols=selected_columns):\n",
    "        chunk.columns = clean_columns\n",
    "        chunk_num += 1\n",
    "        total_rows += len(chunk)\n",
    "        \n",
    "        if first_chunk:\n",
    "            chunk.to_sql('firms', conn, if_exists='replace', index=False)\n",
    "            first_chunk = False\n",
    "        else:\n",
    "            chunk.to_sql('firms', conn, if_exists='append', index=False)\n",
    "        \n",
    "        print(f\"  Chunk {chunk_num}: {total_rows:,} rows\")\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_ticker ON firms(ticker)\")\n",
    "    cursor.execute(\"CREATE INDEX IF NOT EXISTS idx_date ON firms(datadate)\")\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"\\nâœ“ Database created: {db_path} ({total_rows:,} rows)\")\n",
    "    return clean_columns\n",
    "\n",
    "# ============================================\n",
    "# Database Query Tools - WITH HISTORICAL RETURNS\n",
    "# ============================================\n",
    "@tool(\"query_firm_database\")\n",
    "@rate_limit\n",
    "def query_firm_database(sql_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Execute SQL queries on the S&P 500 firm characteristics database.\n",
    "    \n",
    "    Available table: 'firms' (contains firm characteristics AND forward returns)\n",
    "    \n",
    "    IMPORTANT DATA NOTES:\n",
    "    - 'mve' = log(market value of equity), i.e., log size\n",
    "    - 'bm' = log(book to market)\n",
    "    - 'mom12m' = 12-month momentum\n",
    "    - 'ret_fwd_1' = forward return (return in NEXT period after characteristics measured)\n",
    "    - ALL features (except ret_fwd_1) are standardized: mean = 0, standard deviation = 1\n",
    "    - Date range: Jan 1990 - Dec 2019\n",
    "    \n",
    "    Example queries:\n",
    "    - SELECT * FROM firms WHERE datadate < '2019-12-31' LIMIT 10\n",
    "    - SELECT AVG(ret) FROM firms WHERE bm < -1 AND datadate < '2019-12-31'\n",
    "    - SELECT ticker, bm, mom12m, ret FROM firms WHERE datadate BETWEEN '2015-01-01' AND '2019-11-30'\n",
    "    \n",
    "    Args:\n",
    "        sql_query: A valid SQL SELECT query\n",
    "    \n",
    "    Returns:\n",
    "        Query results as a formatted string\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect('firm_data.db')\n",
    "        df = pd.read_sql_query(sql_query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "        if df.empty:\n",
    "            return \"Query returned no results.\"\n",
    "        \n",
    "        result = f\"Query returned {len(df)} rows:\\n\\n\"\n",
    "        result += df.to_string(index=False)\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error executing query: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool(\"explore_threshold_sensitivity\")\n",
    "@rate_limit\n",
    "def explore_threshold_sensitivity(base_condition: str, char_to_vary: str, \n",
    "                                  threshold_range: str, start_date: str = '1990-01-01', \n",
    "                                  end_date: str = '2019-11-30') -> str:\n",
    "    \"\"\"\n",
    "    Test how returns vary as you change a specific threshold.\n",
    "    \n",
    "    This helps find optimal thresholds by showing performance across a range.\n",
    "    \n",
    "    Args:\n",
    "        base_condition: The base SQL condition template with PLACEHOLDER for the threshold\n",
    "                       Example: \"bm < PLACEHOLDER AND mom12m > 0.5\"\n",
    "        char_to_vary: The characteristic being varied (e.g., 'bm')\n",
    "        threshold_range: Comma-separated thresholds to test (e.g., \"-1.5,-1.2,-1.0,-0.8,-0.5\")\n",
    "        start_date: Start of analysis\n",
    "        end_date: End of analysis\n",
    "    \n",
    "    Returns:\n",
    "        Performance across different threshold values\n",
    "    \n",
    "    Example usage:\n",
    "    explore_threshold_sensitivity(\n",
    "        base_condition=\"bm < PLACEHOLDER AND mom12m > 0.5\",\n",
    "        char_to_vary=\"bm\",\n",
    "        threshold_range=\"-1.5,-1.2,-1.0,-0.8,-0.5\"\n",
    "    )\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect('firm_data.db')\n",
    "        \n",
    "        thresholds = [float(t.strip()) for t in threshold_range.split(',')]\n",
    "        \n",
    "        results = []\n",
    "        for threshold in thresholds:\n",
    "            condition = base_condition.replace('PLACEHOLDER', str(threshold))\n",
    "            \n",
    "            query = f\"\"\"\n",
    "            SELECT \n",
    "                COUNT(*) as n_obs,\n",
    "                AVG(ret_fwd_1) as avg_return,\n",
    "                STDEV(ret_fwd_1) as std_return\n",
    "            FROM firms\n",
    "            WHERE datadate >= '{start_date}' AND datadate <= '{end_date}'\n",
    "            AND ({condition})\n",
    "            AND mve IS NOT NULL AND bm IS NOT NULL AND mom12m IS NOT NULL AND ret_fwd_1 IS NOT NULL\n",
    "            \"\"\"\n",
    "            \n",
    "            df = pd.read_sql_query(query, conn)\n",
    "            if not df.empty and df['n_obs'].values[0] > 0:\n",
    "                results.append({\n",
    "                    'threshold': threshold,\n",
    "                    'n_obs': int(df['n_obs'].values[0]),\n",
    "                    'avg_return': df['avg_return'].values[0],\n",
    "                    'std_return': df['std_return'].values[0] if df['std_return'].values[0] else 0\n",
    "                })\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        if not results:\n",
    "            return \"No results found for threshold exploration\"\n",
    "        \n",
    "        result = f\"\"\"Threshold Sensitivity Analysis ({start_date} to {end_date}):\n",
    "\n",
    "Base Condition: {base_condition}\n",
    "Varying: {char_to_vary}\n",
    "\n",
    "\"\"\"\n",
    "        for r in results:\n",
    "            sharpe = r['avg_return'] / r['std_return'] if r['std_return'] > 0 else 0\n",
    "            result += f\"\\nThreshold = {r['threshold']:>6.2f}:\"\n",
    "            result += f\"\\n  Observations: {r['n_obs']:>8,}\"\n",
    "            result += f\"\\n  Avg Return:   {r['avg_return']*100:>7.3f}%\"\n",
    "            result += f\"\\n  Sharpe:       {sharpe:>7.3f}\\n\"\n",
    "        \n",
    "        # Find best threshold\n",
    "        best = max(results, key=lambda x: x['avg_return'])\n",
    "        result += f\"\\nBest threshold: {best['threshold']:.2f} with {best['avg_return']*100:.3f}% return\"\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error in threshold sensitivity: {str(e)}\"\n",
    "\n",
    "@tool(\"get_database_schema\")\n",
    "@rate_limit\n",
    "def get_database_schema() -> str:\n",
    "    \"\"\"\n",
    "    Get the schema of the firms database including all column names and types.\n",
    "    \n",
    "    CRITICAL DATA INFORMATION:\n",
    "    - 'mve' = log(market value of equity), represents log firm size\n",
    "    - 'bm' = log(book to market) - value factor\n",
    "    - 'mom12m' = 12-month momentum\n",
    "    - 'ret_fwd_1' = forward return (return AFTER characteristics measured)\n",
    "    - ALL features (except ret_fwd_1) are standardized to mean=0, std=1\n",
    "    - Values represent standard deviations from mean (z-scores)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect('firm_data.db')\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        cursor.execute(\"PRAGMA table_info(firms)\")\n",
    "        columns = cursor.fetchall()\n",
    "        \n",
    "        cursor.execute(\"SELECT COUNT(*) FROM firms\")\n",
    "        row_count = cursor.fetchone()[0]\n",
    "        \n",
    "        cursor.execute(\"SELECT MIN(datadate), MAX(datadate) FROM firms\")\n",
    "        date_range = cursor.fetchone()\n",
    "        \n",
    "        conn.close()\n",
    "        \n",
    "        schema = f\"\"\"Database: firm_data.db\n",
    "Table: firms\n",
    "Total rows: {row_count:,}\n",
    "Date range: {date_range[0]} to {date_range[1]}\n",
    "\n",
    "DATA STANDARDIZATION:\n",
    "- 'mve' = log(market value of equity) - log firm size (STANDARDIZED z-score)\n",
    "- 'bm' = log(book to market) - value factor (STANDARDIZED z-score)\n",
    "- 'mom12m' = 12-month momentum (STANDARDIZED z-score)\n",
    "- 'ret_fwd_1' = forward return - NOT standardized, raw return in decimal (e.g., 0.05 = 5% return)\n",
    "- Firm characteristics are z-scores (mean=0, std=1)\n",
    "- Returns are raw decimal returns\n",
    "\n",
    "Columns ({len(columns)} total):\n",
    "\"\"\"\n",
    "        for col in columns:\n",
    "            schema += f\"  - {col[1]} ({col[2]})\\n\"\n",
    "        \n",
    "        return schema\n",
    "    except Exception as e:\n",
    "        return f\"Error retrieving schema: {str(e)}\"\n",
    "\n",
    "@tool(\"analyze_characteristic_returns\")\n",
    "@rate_limit\n",
    "def analyze_characteristic_returns(characteristic: str, start_date: str = '1990-01-01', end_date: str = '2019-11-30') -> str:\n",
    "    \"\"\"\n",
    "    Analyze the relationship between a characteristic and future returns.\n",
    "    \n",
    "    This tool divides firms into portfolios based on characteristic values and\n",
    "    shows average returns for each portfolio across the historical period.\n",
    "    \n",
    "    Args:\n",
    "        characteristic: Column name ('bm', 'mom12m', 'mve')\n",
    "        start_date: Start of analysis period (default: 1990-01-01)\n",
    "        end_date: End of analysis period (default: 2019-11-30, BEFORE prediction date)\n",
    "    \n",
    "    Returns:\n",
    "        Average returns by characteristic quintiles (portfolios sorted by characteristic)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect('firm_data.db')\n",
    "        \n",
    "        # Get data for the period\n",
    "        query = f\"\"\"\n",
    "        SELECT {characteristic}, ret_fwd_1\n",
    "        FROM firms\n",
    "        WHERE datadate >= '{start_date}' AND datadate <= '{end_date}'\n",
    "        AND {characteristic} IS NOT NULL AND ret_fwd_1 IS NOT NULL\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "        if df.empty:\n",
    "            return f\"No data found for {characteristic} between {start_date} and {end_date}\"\n",
    "        \n",
    "        # Create quintile portfolios\n",
    "        df['quintile'] = pd.qcut(df[characteristic], q=5, labels=['Q1_Low', 'Q2', 'Q3', 'Q4', 'Q5_High'])\n",
    "        \n",
    "        # Calculate average returns by quintile\n",
    "        quintile_returns = df.groupby('quintile')['ret_fwd_1'].agg(['mean', 'median', 'count'])\n",
    "        quintile_returns.columns = ['avg_return', 'median_return', 'n_obs']\n",
    "        \n",
    "        # Calculate characteristic ranges for each quintile\n",
    "        char_ranges = df.groupby('quintile')[characteristic].agg(['min', 'max'])\n",
    "        \n",
    "        result = f\"\"\"Historical Return Analysis for {characteristic} ({start_date} to {end_date}):\n",
    "\n",
    "Portfolio Performance (sorted by {characteristic}):\n",
    "\"\"\"\n",
    "        for idx in quintile_returns.index:\n",
    "            result += f\"\\n{idx}: {characteristic} range [{char_ranges.loc[idx, 'min']:.2f}, {char_ranges.loc[idx, 'max']:.2f}]\"\n",
    "            result += f\"\\n  Avg Return: {quintile_returns.loc[idx, 'avg_return']*100:.2f}%\"\n",
    "            result += f\"\\n  Median Return: {quintile_returns.loc[idx, 'median_return']*100:.2f}%\"\n",
    "            result += f\"\\n  Observations: {int(quintile_returns.loc[idx, 'n_obs']):,}\\n\"\n",
    "        \n",
    "        # Calculate spread (Q5 - Q1)\n",
    "        spread = (quintile_returns.loc['Q5_High', 'avg_return'] - quintile_returns.loc['Q1_Low', 'avg_return']) * 100\n",
    "        result += f\"\\nSpread (Q5_High - Q1_Low): {spread:.2f}%\"\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error analyzing returns: {str(e)}\"\n",
    "\n",
    "@tool(\"analyze_combined_characteristics\")\n",
    "@rate_limit\n",
    "def analyze_combined_characteristics(sql_condition: str, start_date: str = '1990-01-01', end_date: str = '2019-11-30') -> str:\n",
    "    \"\"\"\n",
    "    Analyze returns for firms meeting ANY arbitrary SQL condition.\n",
    "    \n",
    "    This is the most flexible tool - you can test ANY combination of characteristics.\n",
    "    \n",
    "    Examples:\n",
    "    - \"bm < -1.0 AND mom12m > 0.5\" (value + momentum)\n",
    "    - \"bm > 1.5 OR mom12m < -1.0\" (expensive OR poor momentum)\n",
    "    - \"(bm < -0.8 AND mve > 0.5) OR mom12m > 1.5\" (large value stocks OR strong momentum)\n",
    "    - \"bm < -1.0 AND mom12m > 0.5 AND mve > 0\" (value + momentum + large cap)\n",
    "    - \"NOT (bm > 1.0 OR mom12m < -0.5)\" (exclude expensive or negative momentum)\n",
    "    \n",
    "    Args:\n",
    "        sql_condition: Any valid SQL WHERE clause using mve, bm, mom12m\n",
    "        start_date: Start of analysis period\n",
    "        end_date: End of analysis period (BEFORE prediction date)\n",
    "    \n",
    "    Returns:\n",
    "        Average returns for firms meeting the condition vs. all others\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect('firm_data.db')\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            CASE \n",
    "                WHEN {sql_condition} THEN 'Target_Group'\n",
    "                ELSE 'Other'\n",
    "            END as group_type,\n",
    "            COUNT(*) as n_obs,\n",
    "            AVG(ret_fwd_1) as avg_return,\n",
    "            AVG(ret_fwd_1) * 100 as avg_return_pct,\n",
    "            STDEV(ret_fwd_1) as std_return,\n",
    "            MIN(ret_fwd_1) as min_return,\n",
    "            MAX(ret_fwd_1) as max_return\n",
    "        FROM firms\n",
    "        WHERE datadate >= '{start_date}' AND datadate <= '{end_date}'\n",
    "        AND mve IS NOT NULL AND bm IS NOT NULL AND mom12m IS NOT NULL AND ret_fwd_1 IS NOT NULL\n",
    "        GROUP BY group_type\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "        if df.empty:\n",
    "            return f\"No data found for condition: {sql_condition}\"\n",
    "        \n",
    "        result = f\"\"\"Combined Characteristic Analysis ({start_date} to {end_date}):\n",
    "\n",
    "Condition: {sql_condition}\n",
    "\n",
    "\"\"\"\n",
    "        for _, row in df.iterrows():\n",
    "            result += f\"{row['group_type']}:\\n\"\n",
    "            result += f\"  Observations: {int(row['n_obs']):,}\\n\"\n",
    "            result += f\"  Avg Return: {row['avg_return']*100:.3f}%\\n\"\n",
    "            if row['std_return'] is not None:\n",
    "                sharpe = row['avg_return'] / row['std_return'] if row['std_return'] > 0 else 0\n",
    "                result += f\"  Std Dev: {row['std_return']*100:.3f}%\\n\"\n",
    "                result += f\"  Sharpe (approx): {sharpe:.3f}\\n\"\n",
    "            result += f\"  Min Return: {row['min_return']*100:.2f}%\\n\"\n",
    "            result += f\"  Max Return: {row['max_return']*100:.2f}%\\n\\n\"\n",
    "        \n",
    "        if len(df) == 2:\n",
    "            target = df[df['group_type'] == 'Target_Group']['avg_return'].values[0]\n",
    "            other = df[df['group_type'] == 'Other']['avg_return'].values[0]\n",
    "            spread = (target - other) * 100\n",
    "            result += f\"Spread (Target - Other): {spread:.3f}%\\n\"\n",
    "            \n",
    "            # Statistical significance (t-test approximation)\n",
    "            target_n = df[df['group_type'] == 'Target_Group']['n_obs'].values[0]\n",
    "            other_n = df[df['group_type'] == 'Other']['n_obs'].values[0]\n",
    "            result += f\"\\nSignal strength: {spread:.3f}% spread with {int(target_n):,} target observations\"\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error in combined analysis: {str(e)}\\nMake sure your SQL condition is valid.\"\n",
    "\n",
    "@tool(\"test_strategy_historically\")\n",
    "@rate_limit\n",
    "def test_strategy_historically(buy_condition: str, sell_condition: str,\n",
    "                                start_date: str = '1990-01-01', end_date: str = '2019-11-30') -> str:\n",
    "    \"\"\"\n",
    "    Test a proposed strategy on historical data to see if it would have worked.\n",
    "    \n",
    "    This allows you to test ANY buy and sell conditions with complete flexibility.\n",
    "    \n",
    "    Example buy_conditions:\n",
    "    - \"bm < -1.0 AND mom12m > 0.5\" (value + momentum)\n",
    "    - \"(bm < -0.8 AND mve > 0.5) OR mom12m > 1.5\" (large value OR strong momentum)\n",
    "    - \"bm < -1.2 AND mom12m > 0.7 AND mve > 0\" (value + momentum + large cap)\n",
    "    - \"mom12m > 1.0 OR (bm < -1.5 AND mve > 0)\" (momentum OR extreme value in large caps)\n",
    "    \n",
    "    Example sell_conditions:\n",
    "    - \"bm > 1.5 OR mom12m < -1.0\" (expensive OR negative momentum)\n",
    "    - \"bm > 1.5 AND mom12m < -0.5\" (expensive AND weak momentum)\n",
    "    - \"(bm > 1.0 AND mom12m < 0) OR mve < -1.5\" (expensive with no momentum OR very small)\n",
    "    \n",
    "    Args:\n",
    "        buy_condition: SQL WHERE clause for BUY signals\n",
    "        sell_condition: SQL WHERE clause for SELL signals\n",
    "        start_date: Start of backtest period\n",
    "        end_date: End of backtest period (BEFORE prediction date)\n",
    "    \n",
    "    Returns:\n",
    "        Historical performance of the strategy (avg returns for BUY vs SELL vs HOLD)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect('firm_data.db')\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            CASE \n",
    "                WHEN {buy_condition} THEN 'BUY'\n",
    "                WHEN {sell_condition} THEN 'SELL'\n",
    "                ELSE 'HOLD'\n",
    "            END as signal,\n",
    "            COUNT(*) as n_obs,\n",
    "            AVG(ret_fwd_1) as avg_return,\n",
    "            STDEV(ret_fwd_1) as std_return,\n",
    "            MIN(ret_fwd_1) as min_return,\n",
    "            MAX(ret_fwd_1) as max_return\n",
    "        FROM firms\n",
    "        WHERE datadate >= '{start_date}' AND datadate <= '{end_date}'\n",
    "        AND mve IS NOT NULL AND bm IS NOT NULL AND mom12m IS NOT NULL AND ret_fwd_1 IS NOT NULL\n",
    "        GROUP BY signal\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "        if df.empty:\n",
    "            return \"No data found for strategy test\"\n",
    "        \n",
    "        result = f\"\"\"Historical Strategy Backtest ({start_date} to {end_date}):\n",
    "\n",
    "BUY Condition: {buy_condition}\n",
    "SELL Condition: {sell_condition}\n",
    "\n",
    "Results:\n",
    "\"\"\"\n",
    "        for _, row in df.iterrows():\n",
    "            result += f\"\\n{row['signal']} Signal:\"\n",
    "            result += f\"\\n  Count: {int(row['n_obs']):,} observations\"\n",
    "            result += f\"\\n  Avg Return: {row['avg_return']*100:.3f}%\"\n",
    "            if row['std_return'] is not None and row['std_return'] > 0:\n",
    "                sharpe = row['avg_return'] / row['std_return']\n",
    "                result += f\"\\n  Std Dev: {row['std_return']*100:.3f}%\"\n",
    "                result += f\"\\n  Sharpe (approx): {sharpe:.3f}\"\n",
    "            result += f\"\\n  Min Return: {row['min_return']*100:.2f}%\"\n",
    "            result += f\"\\n  Max Return: {row['max_return']*100:.2f}%\"\n",
    "            result += \"\\n\"\n",
    "        \n",
    "        # Calculate spreads\n",
    "        if len(df) >= 2:\n",
    "            result += \"\\nPerformance Spreads:\"\n",
    "            buy_ret = df[df['signal'] == 'BUY']['avg_return'].values\n",
    "            sell_ret = df[df['signal'] == 'SELL']['avg_return'].values\n",
    "            hold_ret = df[df['signal'] == 'HOLD']['avg_return'].values\n",
    "            \n",
    "            if len(buy_ret) > 0 and len(sell_ret) > 0:\n",
    "                spread_buy_sell = (buy_ret[0] - sell_ret[0]) * 100\n",
    "                result += f\"\\n  BUY vs SELL: {spread_buy_sell:.3f}%\"\n",
    "            \n",
    "            if len(buy_ret) > 0 and len(hold_ret) > 0:\n",
    "                spread_buy_hold = (buy_ret[0] - hold_ret[0]) * 100\n",
    "                result += f\"\\n  BUY vs HOLD: {spread_buy_hold:.3f}%\"\n",
    "            \n",
    "            if len(sell_ret) > 0 and len(hold_ret) > 0:\n",
    "                spread_sell_hold = (sell_ret[0] - hold_ret[0]) * 100\n",
    "                result += f\"\\n  SELL vs HOLD: {spread_sell_hold:.3f}%\"\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error testing strategy: {str(e)}\\nMake sure your SQL conditions are valid.\"\n",
    "\n",
    "@tool(\"get_distribution_stats\")\n",
    "@rate_limit\n",
    "def get_distribution_stats(date: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Get statistical distribution of firm characteristics at a specific date.\n",
    "    \n",
    "    Args:\n",
    "        date: Date in format 'YYYY-MM-DD' (if None, uses latest date)\n",
    "    \n",
    "    Returns:\n",
    "        Distribution statistics for all characteristics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect('firm_data.db')\n",
    "        \n",
    "        if date is None:\n",
    "            cursor = conn.cursor()\n",
    "            cursor.execute(\"SELECT MAX(datadate) FROM firms\")\n",
    "            date = cursor.fetchone()[0]\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        SELECT \n",
    "            COUNT(*) as n_firms,\n",
    "            AVG(mve) as avg_mve, MIN(mve) as min_mve, MAX(mve) as max_mve,\n",
    "            AVG(bm) as avg_bm, MIN(bm) as min_bm, MAX(bm) as max_bm,\n",
    "            AVG(mom12m) as avg_mom12m, MIN(mom12m) as min_mom12m, MAX(mom12m) as max_mom12m\n",
    "        FROM firms\n",
    "        WHERE datadate = '{date}'\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql_query(query, conn)\n",
    "        conn.close()\n",
    "        \n",
    "        if df.empty:\n",
    "            return f\"No data found for date: {date}\"\n",
    "        \n",
    "        result = f\"Distribution statistics at {date}:\\n\\n\"\n",
    "        result += df.to_string(index=False)\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error getting distribution: {str(e)}\"\n",
    "\n",
    "# ============================================\n",
    "# Configure LLM\n",
    "# ============================================\n",
    "def get_rate_limited_llm():\n",
    "    \"\"\"Get LLM provider with rate limiting configured.\"\"\"\n",
    "    llm = AG.get_llm_provider()\n",
    "    \n",
    "    try:\n",
    "        llm.max_retries = 5\n",
    "        llm.timeout = 60\n",
    "    except Exception as e:\n",
    "        print(f\"[Warning] Could not set LLM parameters: {e}\")\n",
    "    \n",
    "    return llm\n",
    "\n",
    "# ============================================\n",
    "# Strategy Development Agent - WITH HISTORICAL LEARNING\n",
    "# ============================================\n",
    "strategy_agent = Agent(\n",
    "    role=\"Empirical Quantitative Researcher\",\n",
    "    goal=\"Learn from 30 years of historical data (1990-2019) to develop systematic BUY/HOLD/SELL rules that predict future returns at December 2019\",\n",
    "    backstory=\"\"\"\n",
    "    You are an expert empirical quantitative researcher who discovers investment strategies through rigorous historical analysis.\n",
    "    \n",
    "    CRITICAL DATA UNDERSTANDING:\n",
    "    - You have access to 30 YEARS of firm characteristics AND their subsequent returns (Jan 1990 - Nov 2019)\n",
    "    - 'mve' = log(market value of equity), represents log firm size (STANDARDIZED z-score)\n",
    "    - 'bm' = log(book to market) - value factor (STANDARDIZED z-score)\n",
    "    - 'mom12m' = 12-month momentum (STANDARDIZED z-score)\n",
    "    - 'ret_fwd_1' = forward return (the return AFTER characteristics were measured) - RAW return, NOT standardized\n",
    "    - ALL characteristics are z-scores (mean=0, std=1)\n",
    "    \n",
    "    YOUR RESEARCH PROCESS:\n",
    "    \n",
    "    1. EXPLORE HISTORICAL PATTERNS (1990- November 2019):\n",
    "       - Which characteristics predicted positive returns historically?\n",
    "       - Do high momentum stocks outperform? Do value stocks outperform?\n",
    "       - Are there combinations that work better (value + momentum)?\n",
    "       - What z-score thresholds historically separated good from bad performers?\n",
    "       - Has the relationship changed over time or been stable?\n",
    "    \n",
    "    2. EMPIRICAL ANALYSIS:\n",
    "       - Analyze quintile returns: Do Q5 (high characteristic) stocks beat Q1 (low)?\n",
    "       - Test ANY combination using flexible SQL conditions\n",
    "       - Examples to explore:\n",
    "         * \"bm < -1.0 AND mom12m > 0.5\" (value + positive momentum)\n",
    "         * \"(bm < -0.8 OR mom12m > 1.0) AND mve > 0\" (value OR momentum, large caps only)\n",
    "         * \"bm < -1.2 AND mom12m > 0.7 AND mve > 0.3\" (strong value + momentum + size)\n",
    "         * \"mom12m > 1.5 OR (bm < -1.5 AND mve > 0)\" (strong momentum OR extreme value in large caps)\n",
    "       - Look at spreads: How much better do good signals perform vs bad?\n",
    "       - Test threshold sensitivity: Is -1.0 better than -1.2?\n",
    "       - Consider statistical significance: Are patterns strong and consistent?\n",
    "    \n",
    "    3. DEVELOP EVIDENCE-BASED RULES:\n",
    "       - Your rules must be JUSTIFIED by historical evidence\n",
    "       - You have COMPLETE FLEXIBILITY in rule structure:\n",
    "         * Simple: \"bm < -1.2\" (just value)\n",
    "         * Compound AND: \"bm < -1.2 AND mom12m > 0.7\" (value AND momentum)\n",
    "         * Compound OR: \"bm < -1.5 OR mom12m > 1.5\" (strong value OR strong momentum)\n",
    "         * Complex: \"(bm < -1.0 AND mom12m > 0.5) OR (mve > 1.0 AND mom12m > 1.2)\" (value+momentum OR large+strong momentum)\n",
    "         * Nested: \"bm < -0.8 AND (mom12m > 0.7 OR mve > 1.0)\" (value with momentum OR size)\n",
    "       - Do NOT use arbitrary thresholds - let the data guide you\n",
    "       - Use explore_threshold_sensitivity to find optimal cut-points\n",
    "       - Consider: What thresholds maximize the spread between winners and losers?\n",
    "    \n",
    "    4. VALIDATE YOUR STRATEGY:\n",
    "       - Test your proposed rules on historical data\n",
    "       - Does your BUY signal historically produce positive returns?\n",
    "       - Does your SELL signal historically produce negative returns?\n",
    "       - Is the spread between BUY and SELL signals economically significant?\n",
    "    \n",
    "    5. SPECIFIC THRESHOLD SELECTION:\n",
    "       - Be PRECISE in thresholds (not just round numbers like -1.0, use -1.17 if data supports it)\n",
    "       - Consider market conditions at Dec 2019 \n",
    "       - Balance between signal strength (fewer, stronger signals) and diversification (more signals)\n",
    "       - Better to have too many signals than too few signals\n",
    "    \n",
    "    CRITICAL REQUIREMENTS:\n",
    "    - Rules must be based on EMPIRICAL EVIDENCE from historical returns\n",
    "    - Use tools to analyze characteristic-return relationships\n",
    "    - Test your proposed strategy before finalizing\n",
    "    - Provide evidence: \"I choose this threshold because historically...\"\n",
    "    - Rules must be deterministic and implementable\n",
    "    - Consider both individual characteristics AND combinations\n",
    "    \n",
    "    OUTPUT FORMAT:\n",
    "    ===========================================\n",
    "    EMPIRICAL TRADING STRATEGY\n",
    "    ===========================================\n",
    "    \n",
    "    Historical Analysis Summary:\n",
    "    - [What you learned from 30 years of data]\n",
    "    - [Which characteristics predicted returns]\n",
    "    - [Evidence for your threshold choices]\n",
    "    \n",
    "    BUY RULE:\n",
    "    if [ANY complex z-score condition using AND/OR/NOT]:\n",
    "        signal = BUY\n",
    "    \n",
    "    Examples of valid BUY rules:\n",
    "    - \"bm < -1.15 AND mom12m > 0.73\" (simple AND)\n",
    "    - \"bm < -1.5 OR mom12m > 1.2\" (simple OR)\n",
    "    - \"(bm < -1.0 AND mom12m > 0.5) OR mve > 1.5\" (combination)\n",
    "    - \"bm < -0.8 AND (mom12m > 0.7 OR mve > 1.0)\" (nested conditions)\n",
    "    \n",
    "    Historical Evidence for BUY:\n",
    "    - [Average return of stocks meeting BUY condition: X%]\n",
    "    - [Number of observations: N]\n",
    "    - [Why these thresholds work]\n",
    "    \n",
    "    SELL RULE:\n",
    "    if [exact z-score conditions]:\n",
    "        signal = SELL\n",
    "    \n",
    "    Historical Evidence for SELL:\n",
    "    - [Average return of stocks meeting SELL condition: Y%]\n",
    "    - [Number of observations: N]\n",
    "    - [Why these thresholds work]\n",
    "    \n",
    "    HOLD RULE:\n",
    "    else:\n",
    "        signal = HOLD\n",
    "    \n",
    "    Strategy Validation:\n",
    "    - [BUY vs SELL spread: Z%]\n",
    "    - [Expected signal distribution at Dec 2019]\n",
    "    \n",
    "    Rationale:\n",
    "    - [Economic intuition supported by data]\n",
    "    - [Why this strategy should work going forward]\n",
    "    - [Market conditions at Dec 2019]\n",
    "    \n",
    "    ===========================================\n",
    "    \n",
    "    Be rigorous, empirical, and data-driven. Let the 30 years of historical evidence guide your rules.\n",
    "    \"\"\",\n",
    "    llm=get_rate_limited_llm(),\n",
    "    memory=True,\n",
    "    verbose=True,\n",
    "    max_iter=20,  # More iterations for thorough analysis\n",
    "    max_rpm=10\n",
    ")\n",
    "\n",
    "strategy_task = Task(\n",
    "    description=\"\"\"\n",
    "    Learn from historical data (1990-2019) to develop systematic trading rules for December 2019.\n",
    "    \n",
    "    Available data:\n",
    "    - 30 years of firm characteristics (mve, bm, mom12m) AND their forward returns\n",
    "    - All data BEFORE Dec 2019 (training period)\n",
    "    - Need to generate signals FOR Dec 2019 (out-of-sample)\n",
    "    \n",
    "    Your research process:\n",
    "    1. Understand the data structure and available history\n",
    "    2. Analyze which characteristics predicted returns historically\n",
    "    3. Test different threshold combinations\n",
    "    4. Develop final rules with empirical justification\n",
    "    \n",
    "    CRITICAL: \n",
    "    - Use historical returns to LEARN which characteristics work\n",
    "    - Your rules must be justified by empirical evidence\n",
    "    - Test your strategy before finalizing\n",
    "    - Be precise with thresholds based on what data shows\n",
    "    - Consider Dec 2019 market context\n",
    "    \n",
    "    Focus on:\n",
    "    - Empirical evidence from 30 years of data\n",
    "    - Characteristic-return relationships\n",
    "    - Strategy backtesting and validation\n",
    "    - Economically and statistically significant patterns\n",
    "    \n",
    "    Output: Evidence-based systematic rules for Dec 2019 trading.\n",
    "    \"\"\",\n",
    "    expected_output=\"\"\"\n",
    "    Complete empirical strategy with:\n",
    "    1. Historical analysis summary (what predicts returns)\n",
    "    2. Evidence-based BUY rule with specific thresholds\n",
    "    3. Evidence-based SELL rule with specific thresholds\n",
    "    4. HOLD rule (default)\n",
    "    5. Rationale grounded in empirical evidence\n",
    "    6. Expected performance at Dec 2019\n",
    "    \n",
    "    All rules must be justified by historical return analysis.\n",
    "    \"\"\",\n",
    "    agent=strategy_agent,\n",
    "    tools=[\n",
    "        get_database_schema,\n",
    "        query_firm_database,\n",
    "        get_distribution_stats,\n",
    "        analyze_characteristic_returns,\n",
    "        analyze_combined_characteristics,\n",
    "        explore_threshold_sensitivity,\n",
    "        test_strategy_historically\n",
    "    ]\n",
    ")\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[strategy_agent],\n",
    "    tasks=[strategy_task],\n",
    "    process=Process.sequential,\n",
    "    memory=False,\n",
    "    verbose=True,\n",
    "    max_rpm=10\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# Main Execution\n",
    "# ============================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    selected_cols = variables  # Add your columns\n",
    "    setup_firm_database('green_cleaned_pre_2020.csv', selected_columns=selected_cols)\n",
    "    \n",
    "    print(\"=\" * 70)\n",
    "    print(\"EMPIRICAL STRATEGY DEVELOPER\")\n",
    "    print(\"=\" * 70)\n",
    "    print(\"\\nLearns from historical data (1990-2019) to develop trading rules\")\n",
    "    print(\"Uses 30 years of characteristic-return relationships\")\n",
    "    print(\"\\nThe agent will:\")\n",
    "    print(\"  1. Analyze which characteristics predicted returns historically\")\n",
    "    print(\"  2. Test different threshold combinations\")\n",
    "    print(\"  3. Validate strategy with historical backtests\")\n",
    "    print(\"  4. Output evidence-based rules for December 2019\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Check if return column exists\n",
    "    try:\n",
    "        conn = sqlite3.connect('firm_data.db')\n",
    "        cursor = conn.cursor()\n",
    "        cursor.execute(\"PRAGMA table_info(firms)\")\n",
    "        columns = [col[1] for col in cursor.fetchall()]\n",
    "        conn.close()\n",
    "        \n",
    "        if 'ret_fwd_1' not in columns:\n",
    "            print(\"\\nâš  WARNING: 'ret_fwd_1' column not found in database!\")\n",
    "            print(\"The agent needs forward returns to learn from historical data.\")\n",
    "            print(\"Please ensure your CSV includes a 'ret_fwd_1' column with future returns.\")\n",
    "            response = input(\"\\nContinue anyway? (yes/no): \")\n",
    "            if response.lower() != 'yes':\n",
    "                exit()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    input(\"\\nPress Enter to start empirical strategy development...\")\n",
    "    \n",
    "    try:\n",
    "        print(\"\\nðŸš€ Starting empirical analysis...\\n\")\n",
    "        print(\"This may take longer as the agent analyzes 30 years of data...\")\n",
    "        \n",
    "        # Record metadata\n",
    "        import json\n",
    "        metadata = {\n",
    "            \"timestamp\": time.time(),\n",
    "            \"date\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"training_period\": \"1990-01-01 to 2019-11-30\",\n",
    "            \"prediction_date\": \"2019-12-31\",\n",
    "            \"method\": \"empirical_learning_from_historical_returns\"\n",
    "        }\n",
    "        \n",
    "        result = crew.kickoff()\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"EMPIRICAL STRATEGY OUTPUT\")\n",
    "        print(\"=\" * 70)\n",
    "        print(result)\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Save with metadata\n",
    "        with open('empirical_strategy.txt', 'w') as f:\n",
    "            f.write(\"=\" * 70 + \"\\n\")\n",
    "            f.write(\"EMPIRICAL STRATEGY - LEARNED FROM HISTORICAL DATA\\n\")\n",
    "            f.write(\"=\" * 70 + \"\\n\")\n",
    "            f.write(json.dumps(metadata, indent=2))\n",
    "            f.write(\"\\n\\n\" + \"=\" * 70 + \"\\n\")\n",
    "            f.write(\"STRATEGY OUTPUT\\n\")\n",
    "            f.write(\"=\" * 70 + \"\\n\\n\")\n",
    "            f.write(str(result))\n",
    "        \n",
    "        print(\"\\nâœ“ Strategy saved to 'empirical_strategy.txt'\")\n",
    "        print(\"\\nThis strategy is based on 30 years of empirical evidence!\")\n",
    "        print(\"\\nNext steps:\")\n",
    "        print(\"  1. Review the historical evidence and backtest results\")\n",
    "        print(\"  2. Implement the rules in Python\")\n",
    "        print(\"  3. Apply to December 2019 firms\")\n",
    "        print(\"  4. Track actual performance going forward\")\n",
    "        \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nâ¸ Interrupted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Error: {e}\")\n",
    "        if \"429\" in str(e) or \"RateLimitError\" in str(e):\n",
    "            print(\"\\nðŸš¨ Rate limit hit. Wait 60 seconds and try again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464791a-4d59-4b71-b1be-35cd325574a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
