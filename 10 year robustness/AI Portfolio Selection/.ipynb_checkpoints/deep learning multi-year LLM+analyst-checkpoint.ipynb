{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84482766-9f65-4cb5-9309-e8bd125501f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 14:01:01.936109: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from multiprocessing import get_context\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "from DNNFM_functions import *\n",
    "from comp_m_functions import static_factor_obs, cov_e_poet\n",
    "\n",
    "def round(x):\n",
    "    return int(Decimal(x).to_integral_value(rounding=ROUND_HALF_UP))\n",
    "\n",
    "#---------------- Main ----------------\n",
    "\n",
    "def DNN_FM_main(data, data_factor, architecture=1, const_err_cov=2.5, use_CV_err=False, eval_type='frob'):\n",
    "\n",
    "    data_dm = data\n",
    "    data_factor_dm = data_factor\n",
    "    \n",
    "    # Obtain optimal tuning parameter based on cross-validation or pre-specified values\n",
    "    opt = opt_hyper_parameters(data=data, data_F=data_factor, architecture=architecture, const_err_cov=const_err_cov, \n",
    "                               use_CV_err=use_CV_err, eval_type=eval_type)\n",
    "    # Compute DNN-FM based on optimal hyper-parameters\n",
    "    res_DNN_FM = DNN_FM_core(data=data_dm, data_factor=data_factor_dm, architecture=architecture, opt=opt)\n",
    "\n",
    "    # c_err_min = DNN_FM_cov_e_cmin(data=data_dm, data_factor=data_factor_dm, DNN_model=res_DNN_FM['neural_net'])\n",
    "\n",
    "    print(opt['const_err_cov'])\n",
    "    res_DNN_FM_cov = DNN_FM_cov(data=data_dm, data_factor=data_factor_dm, DNN_model=res_DNN_FM['neural_net'], \n",
    "                                c_err_cov=opt['const_err_cov'], check_eig=False)\n",
    "    \n",
    "    res_DNN_FM.update(res_DNN_FM_cov)\n",
    "\n",
    "    return res_DNN_FM\n",
    "\n",
    "\n",
    "#---------------- Functions ----------------\n",
    "\n",
    "# Core function for creating Neural Network\n",
    "\n",
    "def DNN_FM_core(data, data_factor, architecture, opt):\n",
    "\n",
    "    num_n, num_s = data.shape\n",
    "    num_f = data_factor.shape[1]\n",
    "\n",
    "    # Create neural network specifications\n",
    "\n",
    "    if architecture == 1:\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 1\n",
    "        d_rate = 0.2\n",
    "\n",
    "        if inter_layer:\n",
    "            c_temp = 2\n",
    "        else:\n",
    "            c_temp = 1\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+c_temp)\n",
    "        activation_functions = [np.nan] * (n_layers+c_temp)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            hidden_layer_s[mm] = 512\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        if inter_layer:\n",
    "            dropout_rates_tr[len(dropout_rates_tr)-1] = d_rate\n",
    "            activation_functions[len(activation_functions)-2] = 'relu'\n",
    "            activation_functions[len(activation_functions)-1] = 'relu'\n",
    "        else:\n",
    "            activation_functions[len(activation_functions)-1] = None\n",
    "\n",
    "    elif architecture == 2:\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.1\n",
    "\n",
    "        if inter_layer:\n",
    "            c_temp = 2\n",
    "        else:\n",
    "            c_temp = 1\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+c_temp)\n",
    "        activation_functions = [np.nan] * (n_layers+c_temp)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            hidden_layer_s[mm] = 256\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        if inter_layer:\n",
    "            dropout_rates_tr[len(dropout_rates_tr)-1] = d_rate\n",
    "            activation_functions[len(activation_functions)-2] = 'relu'\n",
    "            activation_functions[len(activation_functions)-1] = 'relu'\n",
    "        else:\n",
    "            activation_functions[len(activation_functions)-1] = None\n",
    "        \n",
    "    elif architecture == 3:\n",
    "        \n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 1\n",
    "        d_rate = 0.0\n",
    "\n",
    "        if inter_layer:\n",
    "            c_temp = 2\n",
    "        else:\n",
    "            c_temp = 1\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+c_temp)\n",
    "        activation_functions = [np.nan] * (n_layers+c_temp)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            hidden_layer_s[mm] = 512\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        if inter_layer:\n",
    "            dropout_rates_tr[len(dropout_rates_tr)-1] = d_rate\n",
    "            activation_functions[len(activation_functions)-2] = 'relu'\n",
    "            activation_functions[len(activation_functions)-1] = 'relu'\n",
    "        else:\n",
    "            activation_functions[len(activation_functions)-1] = None\n",
    "    \n",
    "    elif architecture == 4:\n",
    "\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.0\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+1)\n",
    "        activation_functions = [np.nan] * (n_layers+1)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            if mm == 0:\n",
    "                hidden_layer_s[mm] = 256\n",
    "            elif mm == 1:\n",
    "                hidden_layer_s[mm] = 128\n",
    "            elif mm == 2:\n",
    "                hidden_layer_s[mm] = 64\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        activation_functions[len(activation_functions)-1] = None\n",
    "    \n",
    "    elif architecture == 5:\n",
    "\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.2\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+1)\n",
    "        activation_functions = [np.nan] * (n_layers+1)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            if mm == 0:\n",
    "                hidden_layer_s[mm] = 256\n",
    "            elif mm == 1:\n",
    "                hidden_layer_s[mm] = 128\n",
    "            elif mm == 2:\n",
    "                hidden_layer_s[mm] = 64\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        activation_functions[len(activation_functions)-1] = None\n",
    "\n",
    "\n",
    "    elif architecture == 6:\n",
    "\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.0\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+1)\n",
    "        activation_functions = [np.nan] * (n_layers+1)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            if mm == 0:\n",
    "                hidden_layer_s[mm] = 32\n",
    "            elif mm == 1:\n",
    "                hidden_layer_s[mm] = 16\n",
    "            elif mm == 2:\n",
    "                hidden_layer_s[mm] = 8\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        activation_functions[len(activation_functions)-1] = None\n",
    "\n",
    "    elif architecture == 7:\n",
    "\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.2\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+1)\n",
    "        activation_functions = [np.nan] * (n_layers+1)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            if mm == 0:\n",
    "                hidden_layer_s[mm] = 32\n",
    "            elif mm == 1:\n",
    "                hidden_layer_s[mm] = 16\n",
    "            elif mm == 2:\n",
    "                hidden_layer_s[mm] = 8\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        activation_functions[len(activation_functions)-1] = None\n",
    "\n",
    "    elif architecture == 8:\n",
    "\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.2\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+1)\n",
    "        activation_functions = [np.nan] * (n_layers+1)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            if mm == 0:\n",
    "                hidden_layer_s[mm] = 32\n",
    "            elif mm == 1:\n",
    "                hidden_layer_s[mm] = 16\n",
    "            elif mm == 2:\n",
    "                hidden_layer_s[mm] = 8\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        activation_functions[len(activation_functions)-1] = None\n",
    "\n",
    "    elif architecture == 9:\n",
    "\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.2\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+1)\n",
    "        activation_functions = [np.nan] * (n_layers+1)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            if mm == 0:\n",
    "                hidden_layer_s[mm] = 32\n",
    "            elif mm == 1:\n",
    "                hidden_layer_s[mm] = 16\n",
    "            elif mm == 2:\n",
    "                hidden_layer_s[mm] = 8\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        activation_functions[len(activation_functions)-1] = None\n",
    "\n",
    "    elif architecture == 10:\n",
    "\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.2\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+1)\n",
    "        activation_functions = [np.nan] * (n_layers+1)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            if mm == 0:\n",
    "                hidden_layer_s[mm] = 256\n",
    "            elif mm == 1:\n",
    "                hidden_layer_s[mm] = 128\n",
    "            elif mm == 2:\n",
    "                hidden_layer_s[mm] = 64\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        activation_functions[len(activation_functions)-1] = None\n",
    "\n",
    "\n",
    "    # Optimization options\n",
    "    optimizer = 'Adam'\n",
    "    max_iter = 2000                 # maximum number of iterations\n",
    "    max_iter_nc = 50                # maximum number of iterations early stopping\n",
    "    \n",
    "    split_ratio = 0.3               # split ratio for training and validation set\n",
    "    batch_s = 256                   # batch size\n",
    "    use_bias = False                # include bias in neural net, if true\n",
    "\n",
    "    # Define early stopping criterion\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=max_iter_nc, mode='min')\n",
    "\n",
    "    learning_rate = opt['learning_rate']\n",
    "    reg_par_w = opt['reg_par_w']          # regularization parameter for weights\n",
    "    reg_par_b = opt['reg_par_b']          # regularization parameter for bias\n",
    "    el_r_pro = opt['el_r_pro']            # split between elastic net and lasso: 1 - only l1 norm\n",
    "\n",
    "    \"\"\"\n",
    "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    learning_rate,\n",
    "    decay_steps=1,\n",
    "    decay_rate=1,\n",
    "    staircase=False)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create sparse neural network and compile it\n",
    "    neural_net = sparse_nn(hidden_layer_s, activation_functions, dropout_rates_tr, num_s, num_f,\n",
    "                reg_par_w, reg_par_b, el_r_pro, max_iter_nc, max_iter, optimizer, learning_rate, use_bias, inter_layer)\n",
    "\n",
    "    neural_net.build_neural_network()\n",
    "    # Compile and fit model\n",
    "    neural_net.compile_nn()\n",
    "\n",
    "    fit_nn = neural_net.model.fit(data_factor, data, epochs=max_iter,\n",
    "                        validation_split=split_ratio, shuffle=True, batch_size=batch_s,\n",
    "                        callbacks=early_stopping, verbose=0)\n",
    "    \n",
    "    # Compute market sensitivity\n",
    "    with tf.GradientTape() as tape:\n",
    "        data_factor_ts = tf.convert_to_tensor(data_factor[-1,:].reshape(1,-1), dtype=tf.float32)\n",
    "        tape.watch(data_factor_ts)\n",
    "        y_pred = neural_net.model(data_factor_ts)\n",
    "\n",
    "    market_sens = tape.jacobian(y_pred, data_factor_ts)[-1,:,-1,:].numpy() \n",
    "\n",
    "    # Store for analysis\n",
    "    market_return_t = data_factor_ts.numpy()[-1, :].reshape(1,-1)\n",
    "    market_sensitivity = (market_sens, market_return_t)\n",
    "\n",
    "    res = {'neural_net': neural_net, 'opt': opt, 'market_sensitivity': market_sensitivity}\n",
    "    return res\n",
    "\n",
    "#-------------------------------------------\n",
    "\n",
    "def DNN_FM_cov(data, data_factor, DNN_model, c_err_cov, check_eig=False):\n",
    "\n",
    "    num_n, num_s = data.shape\n",
    "\n",
    "    y_hat_nn = DNN_model.model(data_factor).numpy()\n",
    "    resd_nn = data - y_hat_nn\n",
    "\n",
    "    sig_hat_e = thres_resd_new(resd_nn, c_err_cov, num_s, num_n)\n",
    "    cov_f_nnet = np.cov(y_hat_nn.T)\n",
    "\n",
    "    if not check_eig:\n",
    "                \n",
    "        sigma_y_nnet = cov_f_nnet + sig_hat_e\n",
    "    else:\n",
    "\n",
    "        cond = True\n",
    "        const_c = 0\n",
    "        while cond:\n",
    "\n",
    "            sig_hat_e = thres_resd_new(resd_nn, c_err_cov+const_c, num_s, num_n)\n",
    "\n",
    "            cond = (round(min(np.linalg.eig(sig_hat_e)[0]),2) < 0.01) or (np.linalg.cond(sig_hat_e) > num_s*10)\n",
    "            const_c+=0.01\n",
    "        \n",
    "        sigma_y_nnet = cov_f_nnet + sig_hat_e\n",
    "\n",
    "    inv_sigma_y_nnet = sig_inv_f_nnet(cov_f_nnet, sig_hat_e)\n",
    "\n",
    "    res = {'sigma_hat': sigma_y_nnet, 'sigma_f_hat': cov_f_nnet, 'sigma_e_hat': sig_hat_e, \n",
    "           'inv_sigma_hat': inv_sigma_y_nnet}\n",
    "\n",
    "    return res\n",
    "\n",
    "def DNN_FM_cov_e_cmin(data, data_factor, DNN_model):\n",
    "\n",
    "    num_n, num_s = data.shape\n",
    "\n",
    "    y_hat_nn = DNN_model.model(data_factor).numpy()\n",
    "    resd_nn = data - y_hat_nn\n",
    "\n",
    "    num_n, num_s = resd_nn.shape\n",
    "\n",
    "    f = lambda c: mineig_cov_e(resd=resd_nn, c_err_cov=c, num_s=num_s, num_n=num_n)\n",
    "\n",
    "    if (f(50) * f(-50) < 0):\n",
    "        r = brentq(f, -50, 50)\n",
    "        return max(0, r)\n",
    "    else:\n",
    "        c = 0\n",
    "        return c\n",
    "\n",
    "def mineig_cov_e(resd, c_err_cov, num_s, num_n):\n",
    "\n",
    "    return min(np.linalg.eig(thres_resd_new(resd, c_err_cov, num_s, num_n))[0])\n",
    "\n",
    "\n",
    "#-------------------------------------------\n",
    "\n",
    "# Function for determining optimal regularization and learning rate based on cross-validation or fixed\n",
    "def opt_hyper_parameters(data, data_F, architecture, const_err_cov, use_CV_err, eval_type):\n",
    "    \n",
    "    parallel = False\n",
    "\n",
    "    if architecture == 1 or architecture == 5 or architecture == 7:\n",
    "        reg_par_w = 0.0005           # regularization parameter for weights\n",
    "        reg_par_b = 0.0005           # regularization parameter for bias\n",
    "    elif architecture == 9 or architecture == 10:\n",
    "        reg_par_w = 0.005           # regularization parameter for weights\n",
    "        reg_par_b = 0.005           # regularization parameter for bias\n",
    "    else:\n",
    "        reg_par_w = 0.0             # regularization parameter for weights\n",
    "        reg_par_b = 0.0             # regularization parameter for bias\n",
    "    el_r_pro = 1                    # split between elastic net and lasso: 1 - only l1 norm\n",
    "    # Alternative specification for the learning rate\n",
    "    learning_rate = 0.0005\n",
    "\n",
    "    if use_CV_err:\n",
    "\n",
    "        range_cov_err = np.arange(0, const_err_cov+0.6, 0.1)\n",
    "\n",
    "        \"\"\"\n",
    "        opt = block_cv(data=data, data_F=data_F, architecture=architecture, \n",
    "                       reg_par=reg_par_w, lr=learning_rate, range_cov_err=range_cov_err, \n",
    "                       eval_type=eval_type, test_size=10, parallel=parallel)\n",
    "        \"\"\"\n",
    "        \n",
    "        opt = cv_split(data=data, data_F=data_F, architecture=architecture, \n",
    "                       reg_par=reg_par_w, lr=learning_rate, range_cov_err=range_cov_err, \n",
    "                       eval_type=eval_type)\n",
    "\n",
    "    else:\n",
    "\n",
    "        opt = {'learning_rate': learning_rate, 'reg_par_w': reg_par_w, \n",
    "            'reg_par_b': reg_par_b, 'el_r_pro': el_r_pro, 'const_err_cov': const_err_cov}\n",
    "    \n",
    "    return opt\n",
    "        \n",
    "#-------------------------------------------\n",
    "\n",
    "# Function that determines hyperparameters based on block cross-validation\n",
    "\n",
    "def block_cv(data, data_F, architecture, reg_par, lr, range_cov_err, eval_type, min_train_ratio=0.8, test_size=5, parallel=False):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    T, p = data.shape\n",
    "    train_size = int(np.floor(min_train_ratio * T)) # Get training size\n",
    "    numBlocks = int(np.floor((T - train_size) / test_size)) # Compute number of blocks\n",
    "    \n",
    "    # Show error message if test size is too large\n",
    "    assert numBlocks > 1, f\"Test size is too large\"\n",
    "\n",
    "    # Predefine dictionary for options\n",
    "    opt = {'learning_rate': lr, 'reg_par_w': reg_par, 'reg_par_b': reg_par, 'el_r_pro': 1}\n",
    "    \n",
    "    res_mat = np.empty((numBlocks,len(range_cov_err)))\n",
    "    res_mat[:] = np.nan\n",
    "\n",
    "    for bl in range(1, numBlocks+1):\n",
    "        idxTrainX = list(range((bl-1)*test_size,train_size+(bl-1)*test_size))\n",
    "\n",
    "        if bl == numBlocks:\n",
    "            idxTestX = list(range(train_size+(bl-1)*test_size,T))\n",
    "        else:\n",
    "            idxTestX = list(range(train_size+(bl-1)*test_size,train_size+bl*test_size))\n",
    "\n",
    "        \n",
    "        data_ntrain, data_mean, data_std = normalize_dat(data[idxTrainX,:])\n",
    "        data_F_ntrain, data_F_mean, data_F_std = normalize_dat(data_F[idxTrainX,:])    \n",
    "\n",
    "        test_res = np.empty((len(idxTestX),len(range_cov_err)))\n",
    "        test_res[:] = np.nan\n",
    "        \n",
    "        # if bl == 1:\n",
    "        res_DNN_FM = DNN_FM_core(data_ntrain, data_F_ntrain, architecture, opt)\n",
    "        neural_net = res_DNN_FM['neural_net']\n",
    "\n",
    "\n",
    "        for idx_t in range(1, len(idxTestX)+1):\n",
    "\n",
    "            ind_test_temp = idxTrainX[idx_t:]+idxTestX[:idx_t]\n",
    "\n",
    "            data_ntest, data_mean, data_std = normalize_dat(data[ind_test_temp,:])\n",
    "            data_F_ntest, data_F_mean, data_F_std = normalize_dat(data_F[ind_test_temp,:])\n",
    "\n",
    "            y_hat = neural_net.model(data_F_ntrain).numpy()\n",
    "            resd_nn = data_ntrain - y_hat\n",
    "\n",
    "            num_n, num_s = resd_nn.shape\n",
    "\n",
    "            sigma_test = cov_sfm(data_ntest - neural_net.model(data_F_ntest).numpy())\n",
    "\n",
    "            \"\"\"\n",
    "            # define the number of worker processes to use\n",
    "            num_processes = 2\n",
    "\n",
    "            combined_list = [(resd_nn, sigma_test, eval_type, const_err_item) for const_err_item in range_cov_err]\n",
    "\n",
    "            if parallel:\n",
    "                # create a pool of worker processes\n",
    "                with get_context(\"spawn\").Pool(processes=num_processes) as pool:\n",
    "                    ret = pool.imap(err_cv_core, combined_list)\n",
    "                    pool.close()\n",
    "                    pool.join()\n",
    "            else:\n",
    "                ret = map(err_cv_core, combined_list)\n",
    "\n",
    "            for indx, err_measure in enumerate(ret):\n",
    "                test_res[idx_t-1,indx] = err_measure\n",
    "            \"\"\"\n",
    "\n",
    "            # sigma_test = cov_sfm(data_ntest - neural_net.model(data_F_ntest).numpy())\n",
    "\n",
    "            rate_thres = np.sqrt((np.log(num_s))/num_n)\n",
    "            sig_e_samp = np.cov(resd_nn.T)\n",
    "            thet_par = np.empty((num_s, num_s))\n",
    "            thet_par[:] = np.nan\n",
    "\n",
    "            for ii in range(0, num_s):\n",
    "                for jj in range(0, num_s):\n",
    "                    thet_par[ii, jj] = np.mean(np.abs(resd_nn[:, ii] * resd_nn[:, jj] - sig_e_samp[ii, jj]))\n",
    "\n",
    "            sig_e_diag = np.diag(sig_e_samp)\n",
    "            \n",
    "            \"\"\"\n",
    "            sig_e_diag = np.diag(np.diag(sig_e_samp)**(0.5))\n",
    "            R = np.linalg.inv(sig_e_diag) @ sig_e_samp @ np.linalg.inv(sig_e_diag)\n",
    "            \"\"\"\n",
    "            \n",
    "            for c_idx in range(0,len(range_cov_err)):\n",
    "                lam = rate_thres * range_cov_err[c_idx] * thet_par\n",
    "                \n",
    "                \"\"\"\n",
    "                M = soft_t(R, lam)\n",
    "                M = M - np.diag(np.diag(M)) + np.eye(num_s)\n",
    "                sig_hat_e = sig_e_diag @ M @ sig_e_diag\n",
    "                \"\"\"\n",
    "                \n",
    "                sig_hat_e = soft_t(sig_e_samp, lam)\n",
    "                np.fill_diagonal(sig_hat_e, sig_e_diag)\n",
    "                \n",
    "                # sig_hat_e = thres_resd_new(resd_nn, range_cov_err[c_idx], num_s, num_n)\n",
    "\n",
    "                if min(np.linalg.eig(sig_hat_e)[0]) < 0:\n",
    "                    test_res[idx_t-1,c_idx] = np.inf\n",
    "                else:\n",
    "                    if eval_type == 'frob':\n",
    "                        test_res[idx_t-1,c_idx] = np.linalg.norm(sig_hat_e - sigma_test, ord='fro')**2\n",
    "                    elif eval_type == 'spec':\n",
    "                        test_res[idx_t-1,c_idx] = np.linalg.norm(sig_hat_e - sigma_test, ord=2)**2\n",
    "\n",
    "            \n",
    "        res_mat[bl-1,:] = np.mean(test_res, axis=0)\n",
    "\n",
    "\n",
    "     \n",
    "    idx_opt = np.where(res_mat.mean(axis=0) == np.nanmin(res_mat.mean(axis=0)))\n",
    "\n",
    "    opt.update({'const_err_cov': range_cov_err[idx_opt][0]})\n",
    "    end = time.time()\n",
    "\n",
    "    print(end - start)\n",
    "    return opt\n",
    "\n",
    "def err_cv_core(tuple_in):\n",
    "\n",
    "    resd_nn, sigma_test, eval_type, const_err_cov = tuple_in[0], tuple_in[1], tuple_in[2], tuple_in[3]\n",
    "\n",
    "    num_n, num_s = resd_nn.shape\n",
    "\n",
    "    st = time.time()\n",
    "    sig_hat_e = thres_resd_new(resd_nn, const_err_cov, num_s, num_n)\n",
    "    print(time.time()-st)\n",
    "\n",
    "    if min(np.linalg.eig(sig_hat_e)[0]) < 0:\n",
    "        test_res = np.inf\n",
    "    else:\n",
    "        if eval_type == 'frob':\n",
    "            test_res = np.linalg.norm(sig_hat_e - sigma_test, ord='fro')\n",
    "        elif eval_type == 'spec':\n",
    "            st1 = time.time()\n",
    "            test_res = np.linalg.norm(sig_hat_e - sigma_test, ord=2)\n",
    "            print(time.time()-st1)\n",
    "\n",
    "    return test_res\n",
    "\n",
    "def cv_split(data, data_F, architecture, reg_par, lr, range_cov_err, eval_type):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Predefine dictionary for options\n",
    "    opt = {'learning_rate': lr, 'reg_par_w': reg_par, 'reg_par_b': reg_par, 'el_r_pro': 1}\n",
    "\n",
    "    data_dm, _, _ = normalize_dat_sim(data)\n",
    "    data_F_dm, _, _ = normalize_dat_sim(data_F)    \n",
    "\n",
    "    res_DNN_FM = DNN_FM_core(data_dm, data_F_dm, architecture, opt)\n",
    "    neural_net = res_DNN_FM['neural_net']\n",
    "\n",
    "    y_hat = neural_net.model(data_F_dm).numpy()\n",
    "    resd_nn = data_dm - y_hat\n",
    "\n",
    "    n_folds = 10\n",
    "\n",
    "    res_mat = np.empty((n_folds,len(range_cov_err)))\n",
    "    res_mat[:] = np.nan\n",
    "\n",
    "    split_sample, _ = ts_train_test_split(resd_nn, n_folds, train_size=0.5)\n",
    "\n",
    "    for m_idx in range(0, n_folds):\n",
    "\n",
    "\n",
    "            resd_nn_s1 = split_sample[m_idx][0]\n",
    "            resd_nn_s2 = split_sample[m_idx][1]\n",
    "\n",
    "            num_n, num_s = resd_nn_s1.shape\n",
    "\n",
    "            sigma_test = cov_sfm(resd_nn_s2) # np.cov(resd_nn_s2.T) # \n",
    "\n",
    "            sig_e_samp, thet_par = thres_cov_resd_aux(resd_nn_s1, num_s)\n",
    "\n",
    "            for c_idx in range(0,len(range_cov_err)):\n",
    "                \n",
    "                sig_hat_e = thres_cov_resd(sig_e_samp, thet_par, range_cov_err[c_idx], num_s, num_n)\n",
    "\n",
    "                if min(np.linalg.eig(sig_hat_e)[0]) < 0:\n",
    "                    res_mat[m_idx,c_idx] = np.inf\n",
    "                else:\n",
    "                    if eval_type == 'frob':\n",
    "                        res_mat[m_idx,c_idx] = np.linalg.norm(sig_hat_e - sigma_test, ord='fro')**2\n",
    "                    elif eval_type == 'spec':\n",
    "                        res_mat[m_idx,c_idx] = np.linalg.norm(sig_hat_e - sigma_test, ord=2)**2\n",
    "\n",
    "    idx_opt = np.where(res_mat.mean(axis=0) == np.nanmin(res_mat.mean(axis=0)))\n",
    "\n",
    "    opt.update({'const_err_cov': range_cov_err[idx_opt][0]})\n",
    "    end = time.time()\n",
    "\n",
    "    print(end - start)\n",
    "\n",
    "    return opt\n",
    "\n",
    "def ts_train_test_split(X, n_folds = 5, train_size=0.5):\n",
    "\n",
    "    test_size = 1 - train_size\n",
    "    n_obs = X.shape[0]\n",
    "\n",
    "    size_split = n_obs - n_folds\n",
    "\n",
    "    n_train = round(size_split * train_size)\n",
    "    n_test = round(size_split * test_size)\n",
    "\n",
    "    split_t = (list(range(0, n_train)), list(range(n_train, n_train+n_test)))\n",
    "\n",
    "    split_sample = []\n",
    "    split_index = []\n",
    "\n",
    "    for jj in range(0, n_folds):\n",
    "        split_index.append(([el1 + jj for el1 in split_t[0]], [el2 + jj for el2 in split_t[1]]))\n",
    "        split_sample.append((X[split_index[jj][0],:], X[split_index[jj][1],:]))\n",
    "\n",
    "    return split_sample, split_index\n",
    "\n",
    "\n",
    "def gmv_weights(Theta_hat):\n",
    "    \"\"\"\n",
    "    Compute Global Minimum Variance (GMV) portfolio weights (Section 6.1).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # w* = (Θ 1_p) / (1_p' Θ 1_p)\n",
    "    numerator = Theta_hat @ ones_p\n",
    "    denominator = ones_p @ Theta_hat @ ones_p\n",
    "    \n",
    "    if np.abs(denominator) < 1e-10:\n",
    "        # Fallback to equal weights if precision matrix is near-singular\n",
    "        return ones_p / p\n",
    "    \n",
    "    w_star = numerator / denominator\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "def mv_weights(Theta_hat, mu, target_return=0.01):\n",
    "    \"\"\"\n",
    "    Compute Mean-Variance portfolio weights with target return.\n",
    "    \n",
    "    Solves the constrained optimization:\n",
    "    min w' Sigma w  subject to  w' mu = target_return  and  w' 1 = 1\n",
    "    \n",
    "    Solution uses Lagrange multipliers with two constraints.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix (Sigma^{-1})\n",
    "    mu : np.ndarray, shape (p,)\n",
    "        Expected returns\n",
    "    target_return : float\n",
    "        Target portfolio return (default: 0.01 = 1% monthly)\n",
    "    long_only : bool\n",
    "        If True, falls back to GMV if MV produces negative weights\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # Compute key quantities\n",
    "    A = ones_p @ Theta_hat @ ones_p  # 1' Theta 1\n",
    "    B = ones_p @ Theta_hat @ mu       # 1' Theta mu  \n",
    "    C = mu @ Theta_hat @ mu           # mu' Theta mu\n",
    "    D = A * C - B * B                  # Determinant\n",
    "    \n",
    "    # Check for singularity\n",
    "    if np.abs(D) < 1e-10:\n",
    "        print('SINGULARITY')\n",
    "        # System is singular, use GMV instead\n",
    "        if np.abs(A) > 1e-10:\n",
    "            w_star = (Theta_hat @ ones_p) / A\n",
    "            return w_star\n",
    "        else:\n",
    "            return ones_p / p\n",
    "    \n",
    "    \n",
    "    # Compute Lagrange multipliers\n",
    "    lambda1 = (C - B * target_return) / D\n",
    "    lambda2 = (A * target_return - B) / D\n",
    "    \n",
    "    # Compute weights: w = lambda1 * Theta^{-1} 1 + lambda2 * Theta^{-1} mu\n",
    "    w_star = lambda1 * (Theta_hat @ ones_p) + lambda2 * (Theta_hat @ mu)\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "def msr_weights(Theta_hat, mu):\n",
    "    \"\"\"\n",
    "    Compute Maximum Sharpe Ratio portfolio weights.\n",
    "    \n",
    "    The maximum Sharpe ratio portfolio solves:\n",
    "    max (w' mu) / sqrt(w' Sigma w)\n",
    "    \n",
    "    Solution (when mu represents excess returns):\n",
    "    w ∝ Sigma^{-1} mu = Theta mu\n",
    "    \n",
    "    Then normalize so that sum(w) = 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix (Sigma^{-1})\n",
    "    mu : np.ndarray, shape (p,)\n",
    "        Expected excess returns\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights (sum to 1)\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # Compute unnormalized weights: w ∝ Theta mu\n",
    "    w_unnorm = Theta_hat @ mu\n",
    "    \n",
    "    # Normalize to sum to 1\n",
    "    weight_sum = np.sum(w_unnorm)\n",
    "    \n",
    "    if np.abs(weight_sum) < 1e-10:\n",
    "        print('WARNING: Weight sum near zero, returning equal weights')\n",
    "        return ones_p / p\n",
    "    \n",
    "    w_star = w_unnorm / weight_sum\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "\n",
    "def load_yearly_signals(year, buys_path_template='buys_{}.csv', sells_path_template='sells_{}.csv'):\n",
    "    \"\"\"\n",
    "    Load buy and sell signals for a specific year.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    year : int\n",
    "        Year to load signals for\n",
    "    buys_path_template : str\n",
    "        Template for buys file path (use {} for year placeholder)\n",
    "    sells_path_template : str\n",
    "        Template for sells file path (use {} for year placeholder)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    permno_set : set\n",
    "        Set of permnos in the buy and sell signals for this year\n",
    "    \"\"\"\n",
    "    try:\n",
    "        buys = pd.read_csv(buys_path_template.format(year), index_col=1)\n",
    "        sells = pd.read_csv(sells_path_template.format(year), index_col=1)\n",
    "        \n",
    "        buys.index.name = 'permno'\n",
    "        sells.index.name = 'permno'\n",
    "        \n",
    "        buys_index = buys.index.astype(int)\n",
    "        sells_index = sells.index.astype(int)\n",
    "        \n",
    "        return set(buys_index.union(sells_index))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  ⚠ Warning: Could not load signals for year {year}: {e}\")\n",
    "        return set()\n",
    "\n",
    "def load_analyst_recommendations(rec_changes_path):\n",
    "    \"\"\"\n",
    "    Load significant recommendation changes from CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rec_changes_path : str\n",
    "        Path to significant_recommendation_changes.csv file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    rec_changes_df : pd.DataFrame\n",
    "        DataFrame with columns: permno, date, ticker, mean_recommendation, \n",
    "        recommendation_change, num_recommendations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rec_changes_df = pd.read_csv(rec_changes_path)\n",
    "        rec_changes_df['date'] = pd.to_datetime(rec_changes_df['date'])\n",
    "        rec_changes_df['permno'] = rec_changes_df['permno'].astype(int)\n",
    "        return rec_changes_df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  ⚠ Warning: Could not load recommendation changes: {e}\")\n",
    "        return pd.DataFrame(columns=['permno', 'date', 'ticker', 'mean_recommendation', \n",
    "                                    'recommendation_change', 'num_recommendations'])\n",
    "\n",
    "\n",
    "def get_signal_permnos_for_date(rec_changes_df, date, buy_threshold=-0.5, sell_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Get sets of permnos with buy/sell signals based on recommendation changes.\n",
    "    \n",
    "    Note: Negative change = upgrade (moving toward Strong Buy) = BUY signal\n",
    "          Positive change = downgrade (moving toward Sell) = SELL signal\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rec_changes_df : pd.DataFrame\n",
    "        Recommendation changes dataframe\n",
    "    date : pd.Timestamp\n",
    "        Date to get signals for\n",
    "    buy_threshold : float\n",
    "        Threshold for buy signals (default: -0.5)\n",
    "    sell_threshold : float\n",
    "        Threshold for sell signals (default: 0.5)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    buy_permnos : set\n",
    "        Set of permnos with buy signals\n",
    "    sell_permnos : set\n",
    "        Set of permnos with sell signals\n",
    "    \"\"\"\n",
    "    date_changes = rec_changes_df[rec_changes_df['date'] == date]\n",
    "    \n",
    "    # Buy signals: negative changes (recommendations getting better)\n",
    "    buys = date_changes[date_changes['recommendation_change'] <= buy_threshold]\n",
    "    buy_permnos = set(buys['permno'].values)\n",
    "    \n",
    "    # Sell signals: positive changes (recommendations getting worse)\n",
    "    sells = date_changes[date_changes['recommendation_change'] >= sell_threshold]\n",
    "    sell_permnos = set(sells['permno'].values)\n",
    "    \n",
    "    return buy_permnos | sell_permnos\n",
    "\n",
    "\n",
    "def calculate_exit_transaction_cost(prev_weights_dict, prev_oos_returns_dict, \n",
    "                                    prev_gross_return, transaction_cost, verbose=False):\n",
    "    \"\"\"Calculate transaction cost when exiting the market (liquidating all positions).\"\"\"\n",
    "    if len(prev_weights_dict) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    \n",
    "    adjusted_prev = {}\n",
    "    for asset, prev_w in prev_weights_dict.items():\n",
    "        if asset in prev_oos_returns_dict:\n",
    "            prev_r = prev_oos_returns_dict[asset]\n",
    "            if abs(1 + prev_gross_return) > 1e-6:\n",
    "                adjusted_prev[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return)\n",
    "            else:\n",
    "                adjusted_prev[asset] = 0.0\n",
    "        else:\n",
    "            if abs(1 + prev_gross_return) > 1e-6:\n",
    "                adjusted_prev[asset] = prev_w / (1 + prev_gross_return)\n",
    "            else:\n",
    "                adjusted_prev[asset] = 0.0\n",
    "    \n",
    "    turnover = sum(abs(w) for w in adjusted_prev.values())\n",
    "    tc = transaction_cost * 1.0 * turnover\n",
    "    net_return = -tc\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  Liquidating positions | Turnover: {turnover:>6.4f} | TC: {tc:>8.6f}\")\n",
    "    \n",
    "    return turnover, tc, net_return\n",
    "\n",
    "\n",
    "\n",
    "def backtest_dnn_yearly(df, \n",
    "                          test_start_date='2020-01-31', \n",
    "                          test_end_date='2024-11-30',\n",
    "                          lookback_window=180,\n",
    "                          transaction_cost=0.001,\n",
    "                          buys_path_template='buys_{}.csv',\n",
    "                          sells_path_template='sells_{}.csv',\n",
    "                          analyst_rec_path=None,\n",
    "                          data_factor=None,\n",
    "                          verbose=True):\n",
    "    \"\"\"\n",
    "    Backtest DNN-FM with FinBERT + LLM signals using GMV/MV/MSR strategies.\n",
    "    \n",
    "    KEY CHANGES:\n",
    "    1. Added finbert_signals_path parameter\n",
    "    2. Added ticker to permno mapping creation\n",
    "    3. Added FinBERT signal loading and processing\n",
    "    4. Combined yearly and FinBERT signals using union/intersection logic\n",
    "    5. Added calculate_exit_transaction_cost for proper liquidation handling\n",
    "    \"\"\"\n",
    "    \n",
    "    # [Keep all existing setup code]\n",
    "    df = df.copy()\n",
    "    if 'datadate' not in df.columns or 'permno' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have 'datadate' and 'permno' columns\")\n",
    "    df['datadate'] = pd.to_datetime(df['datadate'])\n",
    "    \n",
    "    # Load analyst recommendations if provided\n",
    "    analyst_df = None\n",
    "    if analyst_rec_path is not None:\n",
    "        analyst_df = load_analyst_recommendations(analyst_rec_path)\n",
    "        if verbose and len(analyst_df) > 0:\n",
    "            print(f\"Loaded analyst recommendations: {len(analyst_df)} records\")\n",
    "    \n",
    "    \n",
    "    # [Keep all existing date and storage setup]\n",
    "    all_dates = sorted(df['datadate'].unique())\n",
    "    test_start_dt = pd.to_datetime(test_start_date)\n",
    "    test_end_dt = pd.to_datetime(test_end_date)\n",
    "    \n",
    "    try:\n",
    "        test_start_idx = all_dates.index(test_start_dt)\n",
    "        test_end_idx = all_dates.index(test_end_dt)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Date not found in DataFrame: {e}\")\n",
    "    \n",
    "    # Storage for results - GMV\n",
    "    portfolio_returns = []\n",
    "    portfolio_dates = []\n",
    "    portfolio_weights_list = []\n",
    "    portfolio_turnover_list = []\n",
    "    portfolio_gross_returns = []\n",
    "    \n",
    "    # Storage for results - MV\n",
    "    portfolio_returns_2 = []\n",
    "    portfolio_dates_2 = []\n",
    "    portfolio_weights_list_2 = []\n",
    "    portfolio_turnover_list_2 = []\n",
    "    portfolio_gross_returns_2 = []\n",
    "    \n",
    "    # Storage for results - MSR\n",
    "    portfolio_returns_3 = []\n",
    "    portfolio_dates_3 = []\n",
    "    portfolio_weights_list_3 = []\n",
    "    portfolio_turnover_list_3 = []\n",
    "    portfolio_gross_returns_3 = []\n",
    "    \n",
    "    # Track weights by permno - GMV\n",
    "    prev_weights_dict = {}\n",
    "    prev_oos_returns_dict = {}\n",
    "    prev_gross_return = 0.0\n",
    "    \n",
    "    # Track weights by permno - MV\n",
    "    prev_weights_dict_2 = {}\n",
    "    prev_oos_returns_dict_2 = {}\n",
    "    prev_gross_return_2 = 0.0\n",
    "    \n",
    "    # Track weights by permno - MSR\n",
    "    prev_weights_dict_3 = {}\n",
    "    prev_oos_returns_dict_3 = {}\n",
    "    prev_gross_return_3 = 0.0\n",
    "    \n",
    "    # Cache for yearly signals\n",
    "    yearly_signals_cache = {}\n",
    "    \n",
    "    # --- 2. Rolling Window Backtest ---\n",
    "    if verbose:\n",
    "        print(\"=\"*60)\n",
    "        print(\"STARTING BACKTEST WITH DNN-FM + YEARLY + ANALYST SIGNALS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "    for t in range(test_start_idx, test_end_idx + 1):\n",
    "        current_date = all_dates[t]\n",
    "        current_year = current_date.year\n",
    "        \n",
    "        # Load yearly signals\n",
    "        if current_year not in yearly_signals_cache:\n",
    "            yearly_signals_cache[current_year] = load_yearly_signals(\n",
    "                current_year, buys_path_template, sells_path_template\n",
    "            )\n",
    "        \n",
    "        yearly_permnos = yearly_signals_cache[current_year]\n",
    "        \n",
    "        # Get analyst recommendations for current date\n",
    "        analyst_permnos = set()\n",
    "        if analyst_df is not None and len(analyst_df) > 0:\n",
    "            analyst_permnos = get_signal_permnos_for_date(analyst_df, current_date)\n",
    "        \n",
    "        # UNION of buy/sell signals and analyst recommendations\n",
    "        allowed_permnos = yearly_permnos.intersection(analyst_permnos)\n",
    "        if len(allowed_permnos) <= 1:\n",
    "            allowed_permnos = yearly_permnos.union(analyst_permnos)\n",
    "        \n",
    "        # NEW: Get OOS returns FIRST (critical for exit transaction cost calculation)\n",
    "        oos_data = df[(df['datadate'] == current_date) & (df['permno'].isin(allowed_permnos))]\n",
    "        oos_returns_series = oos_data.set_index('permno')['ret_fwd_1']\n",
    "        oos_returns_series = oos_returns_series.dropna()\n",
    "        oos_returns_dict = oos_returns_series.to_dict()\n",
    "        \n",
    "        # NEW: Handle no signals case with proper liquidation\n",
    "        if len(allowed_permnos) == 0:\n",
    "            if verbose:\n",
    "                print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                      f\"Date: {current_date.strftime('%Y-%m-%d')}\")\n",
    "                print(f\"  ⚠ No signals, recording zero return for all strategies\")\n",
    "            \n",
    "            # Liquidate all three strategies\n",
    "            for idx, (pw, po, pg) in enumerate([\n",
    "                (prev_weights_dict, prev_oos_returns_dict, prev_gross_return),\n",
    "                (prev_weights_dict_2, prev_oos_returns_dict_2, prev_gross_return_2),\n",
    "                (prev_weights_dict_3, prev_oos_returns_dict_3, prev_gross_return_3)\n",
    "            ]):\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    pw, po, pg, transaction_cost, verbose=verbose\n",
    "                )\n",
    "                \n",
    "                if idx == 0:  # GMV\n",
    "                    portfolio_returns.append(net_return)\n",
    "                    portfolio_dates.append(current_date)\n",
    "                    portfolio_weights_list.append({})\n",
    "                    portfolio_turnover_list.append(turnover)\n",
    "                    portfolio_gross_returns.append(0.0)\n",
    "                elif idx == 1:  # MV\n",
    "                    portfolio_returns_2.append(net_return)\n",
    "                    portfolio_dates_2.append(current_date)\n",
    "                    portfolio_weights_list_2.append({})\n",
    "                    portfolio_turnover_list_2.append(turnover)\n",
    "                    portfolio_gross_returns_2.append(0.0)\n",
    "                else:  # MSR\n",
    "                    portfolio_returns_3.append(net_return)\n",
    "                    portfolio_dates_3.append(current_date)\n",
    "                    portfolio_weights_list_3.append({})\n",
    "                    portfolio_turnover_list_3.append(turnover)\n",
    "                    portfolio_gross_returns_3.append(0.0)\n",
    "            \n",
    "            # Reset all state\n",
    "            prev_weights_dict = {}\n",
    "            prev_oos_returns_dict = {}\n",
    "            prev_gross_return = 0.0\n",
    "            prev_weights_dict_2 = {}\n",
    "            prev_oos_returns_dict_2 = {}\n",
    "            prev_gross_return_2 = 0.0\n",
    "            prev_weights_dict_3 = {}\n",
    "            prev_oos_returns_dict_3 = {}\n",
    "            prev_gross_return_3 = 0.0\n",
    "            continue\n",
    "        \n",
    "        # Define the lookback window\n",
    "        window_start_date = all_dates[t - lookback_window]\n",
    "        window_end_date = all_dates[t - 1]\n",
    "        \n",
    "        train_data = df[(df['datadate'] >= window_start_date) & \n",
    "                        (df['datadate'] <= window_end_date) &\n",
    "                        (df['permno'].isin(allowed_permnos))]\n",
    "        train_factor = data_factor.loc[window_start_date : window_end_date]\n",
    "        \n",
    "        returns_pivot = train_data.pivot(index='datadate', columns='permno', values='ret_fwd_1')\n",
    "        window_dates = all_dates[t - lookback_window : t]\n",
    "        returns_pivot = returns_pivot.reindex(index=window_dates)\n",
    "        \n",
    "        nan_assets = returns_pivot.columns[returns_pivot.isna().any()]\n",
    "        filtered_pivot = returns_pivot.drop(columns=nan_assets)\n",
    "        \n",
    "        current_assets = filtered_pivot.columns.tolist()\n",
    "        Y = filtered_pivot.values\n",
    "        n_train, p_current = Y.shape\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                  f\"Date: {current_date.strftime('%Y-%m-%d')} | Year: {current_year}\")\n",
    "            print(f\"  Window: {window_start_date.strftime('%Y-%m-%d')} to \"\n",
    "                  f\"{window_end_date.strftime('%Y-%m-%d')}\")\n",
    "            # NEW: Show both signal types\n",
    "            print(f\"  Yearly: {len(yearly_permnos)} | Analyst: {len(analyst_permnos)} | \"\n",
    "                  f\"Union/Intersection: {len(allowed_permnos)} | Assets w/ data: {p_current}\")\n",
    "\n",
    "        # Check for valid data\n",
    "        if n_train < lookback_window or p_current < 2:\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ Insufficient data (n={n_train}, p={p_current}), recording 0 return\")\n",
    "            # Liquidate all three strategies\n",
    "            for idx, (pw, po, pg) in enumerate([\n",
    "                (prev_weights_dict, prev_oos_returns_dict, prev_gross_return),\n",
    "                (prev_weights_dict_2, prev_oos_returns_dict_2, prev_gross_return_2),\n",
    "                (prev_weights_dict_3, prev_oos_returns_dict_3, prev_gross_return_3)\n",
    "            ]):\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    pw, po, pg, transaction_cost, verbose=verbose\n",
    "                )\n",
    "                \n",
    "                if idx == 0:  # GMV\n",
    "                    portfolio_returns.append(net_return)\n",
    "                    portfolio_dates.append(current_date)\n",
    "                    portfolio_weights_list.append({})\n",
    "                    portfolio_turnover_list.append(turnover)\n",
    "                    portfolio_gross_returns.append(0.0)\n",
    "                elif idx == 1:  # MV\n",
    "                    portfolio_returns_2.append(net_return)\n",
    "                    portfolio_dates_2.append(current_date)\n",
    "                    portfolio_weights_list_2.append({})\n",
    "                    portfolio_turnover_list_2.append(turnover)\n",
    "                    portfolio_gross_returns_2.append(0.0)\n",
    "                else:  # MSR\n",
    "                    portfolio_returns_3.append(net_return)\n",
    "                    portfolio_dates_3.append(current_date)\n",
    "                    portfolio_weights_list_3.append({})\n",
    "                    portfolio_turnover_list_3.append(turnover)\n",
    "                    portfolio_gross_returns_3.append(0.0)\n",
    "            \n",
    "            # Reset all state\n",
    "            prev_weights_dict = {}\n",
    "            prev_oos_returns_dict = {}\n",
    "            prev_gross_return = 0.0\n",
    "            prev_weights_dict_2 = {}\n",
    "            prev_oos_returns_dict_2 = {}\n",
    "            prev_gross_return_2 = 0.0\n",
    "            prev_weights_dict_3 = {}\n",
    "            prev_oos_returns_dict_3 = {}\n",
    "            prev_gross_return_3 = 0.0\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                # Demean the returns\n",
    "                Y_bar = Y.mean(axis=0)\n",
    "                Y_star = Y - Y_bar\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Running Deep Learning Regression...\")\n",
    "                F = train_factor.values.astype(float)\n",
    "                res_nnet_fm = DNN_FM_main(Y_star, F, architecture=5, const_err_cov=2.5, \n",
    "                                         use_CV_err=False, eval_type='frob')\n",
    "                Theta_hat = res_nnet_fm['inv_sigma_hat']\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Computing GMV weights...\")\n",
    "                w_star = gmv_weights(Theta_hat)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Computing MV weights...\")\n",
    "                w_star_2 = mv_weights(Theta_hat, Y_bar, target_return=0.01)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Computing MSR weights...\")\n",
    "                w_star_3 = msr_weights(Theta_hat, Y_bar)\n",
    "                \n",
    "                # Create weights dictionaries\n",
    "                new_weights_dict = {asset: w_star[i] for i, asset in enumerate(current_assets)}\n",
    "                new_weights_dict_2 = {asset: w_star_2[i] for i, asset in enumerate(current_assets)}\n",
    "                new_weights_dict_3 = {asset: w_star_3[i] for i, asset in enumerate(current_assets)}\n",
    "                \n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"  ✗ Error: {e}\")\n",
    "                    print(f\"  Using previous weights\")\n",
    "                new_weights_dict = prev_weights_dict.copy()\n",
    "                new_weights_dict_2 = prev_weights_dict_2.copy()\n",
    "                new_weights_dict_3 = prev_weights_dict_3.copy()\n",
    "\n",
    "        # Normalize weights to sum to 1 - GMV\n",
    "        weight_sum = sum(new_weights_dict.values())\n",
    "        if weight_sum > 1e-10:\n",
    "            new_weights_dict = {k: v/weight_sum for k, v in new_weights_dict.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ GMV: Zero weight sum, using previous weights\")\n",
    "            new_weights_dict = prev_weights_dict.copy()\n",
    "            weight_sum = sum(new_weights_dict.values())\n",
    "            if weight_sum > 1e-10:\n",
    "                new_weights_dict = {k: v/weight_sum for k, v in new_weights_dict.items()}\n",
    "        \n",
    "        # Normalize weights to sum to 1 - MV\n",
    "        weight_sum_2 = sum(new_weights_dict_2.values())\n",
    "        if weight_sum_2 > 1e-10:\n",
    "            new_weights_dict_2 = {k: v/weight_sum_2 for k, v in new_weights_dict_2.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ MV: Zero weight sum, using previous weights\")\n",
    "            new_weights_dict_2 = prev_weights_dict_2.copy()\n",
    "            weight_sum_2 = sum(new_weights_dict_2.values())\n",
    "            if weight_sum_2 > 1e-10:\n",
    "                new_weights_dict_2 = {k: v/weight_sum_2 for k, v in new_weights_dict_2.items()}\n",
    "        \n",
    "        # Normalize weights to sum to 1 - MSR\n",
    "        weight_sum_3 = sum(new_weights_dict_3.values())\n",
    "        if weight_sum_3 > 1e-10:\n",
    "            new_weights_dict_3 = {k: v/weight_sum_3 for k, v in new_weights_dict_3.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ MSR: Zero weight sum, using previous weights\")\n",
    "            new_weights_dict_3 = prev_weights_dict_3.copy()\n",
    "            weight_sum_3 = sum(new_weights_dict_3.values())\n",
    "            if weight_sum_3 > 1e-10:\n",
    "                new_weights_dict_3 = {k: v/weight_sum_3 for k, v in new_weights_dict_3.items()}\n",
    "        \n",
    "        # --- 3. OOS Returns & Transaction Costs ---\n",
    "        \n",
    "        # Get out-of-sample returns for current month (only for allowed permnos)\n",
    "        oos_data = df[(df['datadate'] == current_date) & (df['permno'].isin(allowed_permnos))]\n",
    "        oos_returns_series = oos_data.set_index('permno')['ret_fwd_1']\n",
    "        \n",
    "        # Filter out NaN returns\n",
    "        oos_returns_series = oos_returns_series.dropna()\n",
    "        oos_returns_dict = oos_returns_series.to_dict()\n",
    "        \n",
    "        # Find common assets between weights and returns\n",
    "        common_assets = set(new_weights_dict.keys()) & set(oos_returns_dict.keys())\n",
    "        common_assets_2 = set(new_weights_dict_2.keys()) & set(oos_returns_dict.keys())\n",
    "        common_assets_3 = set(new_weights_dict_3.keys()) & set(oos_returns_dict.keys())\n",
    "        \n",
    "        if len(common_assets) == 0 or len(common_assets_2) == 0 or len(common_assets_3) == 0:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ No common assets with valid returns, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Filter to common assets and renormalize - GMV\n",
    "        common_weights = {a: new_weights_dict[a] for a in common_assets}\n",
    "        common_weight_sum = sum(common_weights.values())\n",
    "        if common_weight_sum > 1e-10:\n",
    "            common_weights = {k: v/common_weight_sum for k, v in common_weights.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ GMV: Zero weight sum after filtering, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Filter to common assets and renormalize - MV\n",
    "        common_weights_2 = {a: new_weights_dict_2[a] for a in common_assets_2}\n",
    "        common_weight_sum_2 = sum(common_weights_2.values())\n",
    "        if common_weight_sum_2 > 1e-10:\n",
    "            common_weights_2 = {k: v/common_weight_sum_2 for k, v in common_weights_2.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ MV: Zero weight sum after filtering, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Filter to common assets and renormalize - MSR\n",
    "        common_weights_3 = {a: new_weights_dict_3[a] for a in common_assets_3}\n",
    "        common_weight_sum_3 = sum(common_weights_3.values())\n",
    "        if common_weight_sum_3 > 1e-10:\n",
    "            common_weights_3 = {k: v/common_weight_sum_3 for k, v in common_weights_3.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ MSR: Zero weight sum after filtering, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Compute gross portfolio returns\n",
    "        gross_return = sum(common_weights[a] * oos_returns_dict[a] for a in common_assets)\n",
    "        gross_return_2 = sum(common_weights_2[a] * oos_returns_dict[a] for a in common_assets_2)\n",
    "        gross_return_3 = sum(common_weights_3[a] * oos_returns_dict[a] for a in common_assets_3)\n",
    "        \n",
    "        # Sanity checks\n",
    "        if np.isnan(gross_return) or np.isinf(gross_return):\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ GMV: Invalid gross return: {gross_return}, skipping period\")\n",
    "            continue\n",
    "        if np.isnan(gross_return_2) or np.isinf(gross_return_2):\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ MV: Invalid gross return: {gross_return_2}, skipping period\")\n",
    "            continue\n",
    "        if np.isnan(gross_return_3) or np.isinf(gross_return_3):\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ MSR: Invalid gross return: {gross_return_3}, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # === IMPROVED TRANSACTION COST CALCULATION - GMV ===\n",
    "        if len(prev_weights_dict) > 0:\n",
    "            # Step 1: Adjust ALL previous weights for their returns\n",
    "            adjusted_prev = {}\n",
    "            \n",
    "            for asset, prev_w in prev_weights_dict.items():\n",
    "                if asset in prev_oos_returns_dict:\n",
    "                    prev_r = prev_oos_returns_dict[asset]\n",
    "                    if abs(1 + prev_gross_return) > 1e-6:\n",
    "                        adjusted_prev[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return)\n",
    "                    else:\n",
    "                        adjusted_prev[asset] = 0.0\n",
    "                else:\n",
    "                    # Asset had weight but no return data (exited)\n",
    "                    if abs(1 + prev_gross_return) > 1e-6:\n",
    "                        adjusted_prev[asset] = prev_w / (1 + prev_gross_return)\n",
    "                    else:\n",
    "                        adjusted_prev[asset] = 0.0\n",
    "            \n",
    "            # Step 2: Calculate turnover across all assets (old and new)\n",
    "            all_assets = set(adjusted_prev.keys()) | set(common_weights.keys())\n",
    "            \n",
    "            turnover = 0.0\n",
    "            for asset in all_assets:\n",
    "                old_w = adjusted_prev.get(asset, 0.0)\n",
    "                new_w = common_weights.get(asset, 0.0)\n",
    "                turnover += abs(new_w - old_w)\n",
    "            \n",
    "            # Transaction cost on end-of-period portfolio value\n",
    "            tc = transaction_cost * (1 + gross_return) * turnover\n",
    "        else:\n",
    "            # First period: buying into everything\n",
    "            turnover = sum(abs(w) for w in common_weights.values())\n",
    "            tc = transaction_cost * (1 + gross_return) * turnover\n",
    "        \n",
    "        # === IMPROVED TRANSACTION COST CALCULATION - MV ===\n",
    "        if len(prev_weights_dict_2) > 0:\n",
    "            adjusted_prev_2 = {}\n",
    "            \n",
    "            for asset, prev_w in prev_weights_dict_2.items():\n",
    "                if asset in prev_oos_returns_dict_2:\n",
    "                    prev_r = prev_oos_returns_dict_2[asset]\n",
    "                    if abs(1 + prev_gross_return_2) > 1e-6:\n",
    "                        adjusted_prev_2[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return_2)\n",
    "                    else:\n",
    "                        adjusted_prev_2[asset] = 0.0\n",
    "                else:\n",
    "                    if abs(1 + prev_gross_return_2) > 1e-6:\n",
    "                        adjusted_prev_2[asset] = prev_w / (1 + prev_gross_return_2)\n",
    "                    else:\n",
    "                        adjusted_prev_2[asset] = 0.0\n",
    "            \n",
    "            all_assets_2 = set(adjusted_prev_2.keys()) | set(common_weights_2.keys())\n",
    "            \n",
    "            turnover_2 = 0.0\n",
    "            for asset in all_assets_2:\n",
    "                old_w = adjusted_prev_2.get(asset, 0.0)\n",
    "                new_w = common_weights_2.get(asset, 0.0)\n",
    "                turnover_2 += abs(new_w - old_w)\n",
    "            \n",
    "            tc_2 = transaction_cost * (1 + gross_return_2) * turnover_2\n",
    "        else:\n",
    "            turnover_2 = sum(abs(w) for w in common_weights_2.values())\n",
    "            tc_2 = transaction_cost * (1 + gross_return_2) * turnover_2\n",
    "        \n",
    "        # === IMPROVED TRANSACTION COST CALCULATION - MSR ===\n",
    "        if len(prev_weights_dict_3) > 0:\n",
    "            adjusted_prev_3 = {}\n",
    "            \n",
    "            for asset, prev_w in prev_weights_dict_3.items():\n",
    "                if asset in prev_oos_returns_dict_3:\n",
    "                    prev_r = prev_oos_returns_dict_3[asset]\n",
    "                    if abs(1 + prev_gross_return_3) > 1e-6:\n",
    "                        adjusted_prev_3[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return_3)\n",
    "                    else:\n",
    "                        adjusted_prev_3[asset] = 0.0\n",
    "                else:\n",
    "                    if abs(1 + prev_gross_return_3) > 1e-6:\n",
    "                        adjusted_prev_3[asset] = prev_w / (1 + prev_gross_return_3)\n",
    "                    else:\n",
    "                        adjusted_prev_3[asset] = 0.0\n",
    "            \n",
    "            all_assets_3 = set(adjusted_prev_3.keys()) | set(common_weights_3.keys())\n",
    "            \n",
    "            turnover_3 = 0.0\n",
    "            for asset in all_assets_3:\n",
    "                old_w = adjusted_prev_3.get(asset, 0.0)\n",
    "                new_w = common_weights_3.get(asset, 0.0)\n",
    "                turnover_3 += abs(new_w - old_w)\n",
    "            \n",
    "            tc_3 = transaction_cost * (1 + gross_return_3) * turnover_3\n",
    "        else:\n",
    "            turnover_3 = sum(abs(w) for w in common_weights_3.values())\n",
    "            tc_3 = transaction_cost * (1 + gross_return_3) * turnover_3\n",
    "        \n",
    "        # Net returns\n",
    "        net_return = gross_return - tc\n",
    "        net_return_2 = gross_return_2 - tc_2\n",
    "        net_return_3 = gross_return_3 - tc_3\n",
    "        \n",
    "        # Store results - GMV\n",
    "        portfolio_returns.append(net_return)\n",
    "        portfolio_dates.append(current_date)\n",
    "        portfolio_weights_list.append(common_weights.copy())\n",
    "        portfolio_turnover_list.append(turnover)\n",
    "        portfolio_gross_returns.append(gross_return)\n",
    "        \n",
    "        # Store results - MV\n",
    "        portfolio_returns_2.append(net_return_2)\n",
    "        portfolio_dates_2.append(current_date)\n",
    "        portfolio_weights_list_2.append(common_weights_2.copy())\n",
    "        portfolio_turnover_list_2.append(turnover_2)\n",
    "        portfolio_gross_returns_2.append(gross_return_2)\n",
    "        \n",
    "        # Store results - MSR\n",
    "        portfolio_returns_3.append(net_return_3)\n",
    "        portfolio_dates_3.append(current_date)\n",
    "        portfolio_weights_list_3.append(common_weights_3.copy())\n",
    "        portfolio_turnover_list_3.append(turnover_3)\n",
    "        portfolio_gross_returns_3.append(gross_return_3)\n",
    "        \n",
    "        # Update previous values for next iteration\n",
    "        prev_weights_dict = common_weights.copy()\n",
    "        prev_oos_returns_dict = {a: oos_returns_dict[a] for a in common_assets}\n",
    "        prev_gross_return = gross_return\n",
    "        \n",
    "        prev_weights_dict_2 = common_weights_2.copy()\n",
    "        prev_oos_returns_dict_2 = {a: oos_returns_dict[a] for a in common_assets_2}\n",
    "        prev_gross_return_2 = gross_return_2\n",
    "        \n",
    "        prev_weights_dict_3 = common_weights_3.copy()\n",
    "        prev_oos_returns_dict_3 = {a: oos_returns_dict[a] for a in common_assets_3}\n",
    "        prev_gross_return_3 = gross_return_3\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  GMV  - Gross: {gross_return:>8.5f} | Turnover: {turnover:>6.4f} | \"\n",
    "                  f\"TC: {tc:>8.6f} | Net: {net_return:>8.5f}\")\n",
    "            print(f\"  MV   - Gross: {gross_return_2:>8.5f} | Turnover: {turnover_2:>6.4f} | \"\n",
    "                  f\"TC: {tc_2:>8.6f} | Net: {net_return_2:>8.5f}\")\n",
    "            print(f\"  MSR  - Gross: {gross_return_3:>8.5f} | Turnover: {turnover_3:>6.4f} | \"\n",
    "                  f\"TC: {tc_3:>8.6f} | Net: {net_return_3:>8.5f}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BACKTEST COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    # --- 4. Compile Results ---\n",
    "    results_df = pd.DataFrame({\n",
    "        'date': portfolio_dates,\n",
    "        'portfolio_return': portfolio_returns,\n",
    "        'portfolio_gross_return': portfolio_gross_returns,\n",
    "        'portfolio_weights': portfolio_weights_list,\n",
    "        'portfolio_turnover': portfolio_turnover_list\n",
    "    })\n",
    "    results_df['cumulative_return'] = (1 + results_df['portfolio_return']).cumprod() - 1\n",
    "    \n",
    "    results_df_2 = pd.DataFrame({\n",
    "        'date': portfolio_dates_2,\n",
    "        'portfolio_return': portfolio_returns_2,\n",
    "        'portfolio_gross_return': portfolio_gross_returns_2,\n",
    "        'portfolio_weights': portfolio_weights_list_2,\n",
    "        'portfolio_turnover': portfolio_turnover_list_2\n",
    "    })\n",
    "    results_df_2['cumulative_return'] = (1 + results_df_2['portfolio_return']).cumprod() - 1\n",
    "    \n",
    "    results_df_3 = pd.DataFrame({\n",
    "        'date': portfolio_dates_3,\n",
    "        'portfolio_return': portfolio_returns_3,\n",
    "        'portfolio_gross_return': portfolio_gross_returns_3,\n",
    "        'portfolio_weights': portfolio_weights_list_3,\n",
    "        'portfolio_turnover': portfolio_turnover_list_3\n",
    "    })\n",
    "    results_df_3['cumulative_return'] = (1 + results_df_3['portfolio_return']).cumprod() - 1\n",
    "    \n",
    "    # Helper function to compute metrics\n",
    "    def compute_metrics(returns_list, turnover_list, results_df):\n",
    "        if len(returns_list) > 0:\n",
    "            mean_return = np.mean(returns_list)\n",
    "            variance = np.var(returns_list, ddof=1)\n",
    "            sharpe_ratio = mean_return / np.sqrt(variance) if variance > 0 else 0\n",
    "            \n",
    "            # Annualized metrics (monthly data)\n",
    "            annual_return = mean_return * 12\n",
    "            annual_volatility = np.sqrt(variance * 12)\n",
    "            annual_sharpe = annual_return / annual_volatility if annual_volatility > 0 else 0\n",
    "            \n",
    "            return {\n",
    "                'mean_return': mean_return,\n",
    "                'variance': variance,\n",
    "                'sharpe_ratio': sharpe_ratio,\n",
    "                'annual_return': annual_return,\n",
    "                'annual_volatility': annual_volatility,\n",
    "                'annual_sharpe_ratio': annual_sharpe,\n",
    "                'total_return': results_df['cumulative_return'].iloc[-1],\n",
    "                'avg_turnover': np.mean(turnover_list),\n",
    "                'n_periods': len(returns_list)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'mean_return': 0, 'variance': 0, 'sharpe_ratio': 0,\n",
    "                'annual_return': 0, 'annual_volatility': 0, 'annual_sharpe_ratio': 0,\n",
    "                'total_return': 0, 'avg_turnover': 0, 'n_periods': 0\n",
    "            }\n",
    "    \n",
    "    # Compute metrics for all three strategies\n",
    "    metrics = compute_metrics(portfolio_returns, portfolio_turnover_list, results_df)\n",
    "    metrics_2 = compute_metrics(portfolio_returns_2, portfolio_turnover_list_2, results_df_2)\n",
    "    metrics_3 = compute_metrics(portfolio_returns_3, portfolio_turnover_list_3, results_df_3)\n",
    "    \n",
    "    return results_df, metrics, results_df_2, metrics_2, results_df_3, metrics_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f77cbae-5233-4cbe-8d95-7d8e0a1a7e1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded analyst recommendations: 37527 records\n",
      "============================================================\n",
      "STARTING BACKTEST WITH DNN-FM + YEARLY + ANALYST SIGNALS\n",
      "============================================================\n",
      "\n",
      "[1/112] Date: 2015-01-31 | Year: 2015\n",
      "  Window: 2000-01-31 to 2014-12-31\n",
      "  Yearly: 54 | Analyst: 69 | Union/Intersection: 5 | Assets w/ data: 3\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01795 | Turnover: 1.0000 | TC: 0.001018 | Net:  0.01694\n",
      "  MV   - Gross:  0.07123 | Turnover: 1.2766 | TC: 0.001368 | Net:  0.06987\n",
      "  MSR  - Gross:  0.04294 | Turnover: 1.0000 | TC: 0.001043 | Net:  0.04189\n",
      "\n",
      "[2/112] Date: 2015-02-28 | Year: 2015\n",
      "  Window: 2000-02-29 to 2015-01-31\n",
      "  Yearly: 54 | Analyst: 91 | Union/Intersection: 6 | Assets w/ data: 3\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.06991 | Turnover: 1.0745 | TC: 0.000999 | Net: -0.07091\n",
      "  MV   - Gross: -0.06921 | Turnover: 0.3907 | TC: 0.000364 | Net: -0.06957\n",
      "  MSR  - Gross: -0.06974 | Turnover: 0.4809 | TC: 0.000447 | Net: -0.07019\n",
      "\n",
      "[3/112] Date: 2015-03-31 | Year: 2015\n",
      "  Window: 2000-03-31 to 2015-02-28\n",
      "  Yearly: 54 | Analyst: 101 | Union/Intersection: 8 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03841 | Turnover: 2.0000 | TC: 0.002077 | Net:  0.03633\n",
      "  MV   - Gross:  0.06293 | Turnover: 2.2487 | TC: 0.002390 | Net:  0.06054\n",
      "  MSR  - Gross:  0.05209 | Turnover: 2.0024 | TC: 0.002107 | Net:  0.04998\n",
      "\n",
      "[4/112] Date: 2015-04-30 | Year: 2015\n",
      "  Window: 2000-04-30 to 2015-03-31\n",
      "  Yearly: 54 | Analyst: 143 | Union/Intersection: 15 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00016 | Turnover: 1.4544 | TC: 0.001454 | Net: -0.00162\n",
      "  MV   - Gross: -0.00154 | Turnover: 1.5594 | TC: 0.001557 | Net: -0.00310\n",
      "  MSR  - Gross: -0.00220 | Turnover: 1.5779 | TC: 0.001574 | Net: -0.00377\n",
      "\n",
      "[5/112] Date: 2015-05-31 | Year: 2015\n",
      "  Window: 2000-05-31 to 2015-04-30\n",
      "  Yearly: 54 | Analyst: 121 | Union/Intersection: 8 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x13d4e72e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.07079 | Turnover: 1.8144 | TC: 0.001686 | Net: -0.07248\n",
      "  MV   - Gross: -0.04372 | Turnover: 1.9325 | TC: 0.001848 | Net: -0.04556\n",
      "  MSR  - Gross: -0.04230 | Turnover: 2.0082 | TC: 0.001923 | Net: -0.04422\n",
      "\n",
      "[6/112] Date: 2015-06-30 | Year: 2015\n",
      "  Window: 2000-06-30 to 2015-05-31\n",
      "  Yearly: 54 | Analyst: 105 | Union/Intersection: 17 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x13eb98d60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00715 | Turnover: 1.0067 | TC: 0.001000 | Net: -0.00815\n",
      "  MV   - Gross: -0.01278 | Turnover: 1.0769 | TC: 0.001063 | Net: -0.01384\n",
      "  MSR  - Gross: -0.01690 | Turnover: 1.0342 | TC: 0.001017 | Net: -0.01791\n",
      "\n",
      "[7/112] Date: 2015-07-31 | Year: 2015\n",
      "  Window: 2000-07-31 to 2015-06-30\n",
      "  Yearly: 54 | Analyst: 135 | Union/Intersection: 11 | Assets w/ data: 8\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.05699 | Turnover: 1.3987 | TC: 0.001319 | Net: -0.05831\n",
      "  MV   - Gross: -0.05083 | Turnover: 1.6836 | TC: 0.001598 | Net: -0.05242\n",
      "  MSR  - Gross: -0.04902 | Turnover: 1.8751 | TC: 0.001783 | Net: -0.05080\n",
      "\n",
      "[8/112] Date: 2015-08-31 | Year: 2015\n",
      "  Window: 2000-08-31 to 2015-07-31\n",
      "  Yearly: 54 | Analyst: 122 | Union/Intersection: 14 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02672 | Turnover: 1.3482 | TC: 0.001312 | Net: -0.02804\n",
      "  MV   - Gross: -0.02241 | Turnover: 1.5291 | TC: 0.001495 | Net: -0.02390\n",
      "  MSR  - Gross: -0.01880 | Turnover: 1.7583 | TC: 0.001725 | Net: -0.02053\n",
      "\n",
      "[9/112] Date: 2015-09-30 | Year: 2015\n",
      "  Window: 2000-09-30 to 2015-08-31\n",
      "  Yearly: 54 | Analyst: 139 | Union/Intersection: 16 | Assets w/ data: 12\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03477 | Turnover: 1.1894 | TC: 0.001231 | Net:  0.03354\n",
      "  MV   - Gross:  0.04880 | Turnover: 1.4265 | TC: 0.001496 | Net:  0.04730\n",
      "  MSR  - Gross:  0.07239 | Turnover: 1.8386 | TC: 0.001972 | Net:  0.07042\n",
      "\n",
      "[10/112] Date: 2015-10-31 | Year: 2015\n",
      "  Window: 2000-10-31 to 2015-09-30\n",
      "  Yearly: 54 | Analyst: 143 | Union/Intersection: 16 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01913 | Turnover: 1.3862 | TC: 0.001360 | Net: -0.02049\n",
      "  MV   - Gross: -0.01938 | Turnover: 1.4691 | TC: 0.001441 | Net: -0.02082\n",
      "  MSR  - Gross: -0.02117 | Turnover: 1.6028 | TC: 0.001569 | Net: -0.02274\n",
      "\n",
      "[11/112] Date: 2015-11-30 | Year: 2015\n",
      "  Window: 2000-11-30 to 2015-10-31\n",
      "  Yearly: 54 | Analyst: 121 | Union/Intersection: 9 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01552 | Turnover: 1.6836 | TC: 0.001658 | Net: -0.01717\n",
      "  MV   - Gross: -0.02523 | Turnover: 1.6995 | TC: 0.001657 | Net: -0.02688\n",
      "  MSR  - Gross: -0.03032 | Turnover: 2.1541 | TC: 0.002089 | Net: -0.03241\n",
      "\n",
      "[12/112] Date: 2015-12-31 | Year: 2015\n",
      "  Window: 2000-12-31 to 2015-11-30\n",
      "  Yearly: 54 | Analyst: 74 | Union/Intersection: 4 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.07766 | Turnover: 1.7771 | TC: 0.001639 | Net: -0.07930\n",
      "  MV   - Gross: -0.11000 | Turnover: 4.3118 | TC: 0.003838 | Net: -0.11384\n",
      "  MSR  - Gross: -0.07980 | Turnover: 2.1232 | TC: 0.001954 | Net: -0.08175\n",
      "\n",
      "[13/112] Date: 2016-01-31 | Year: 2016\n",
      "  Window: 2001-01-31 to 2015-12-31\n",
      "  Yearly: 81 | Analyst: 111 | Union/Intersection: 13 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04692 | Turnover: 1.9197 | TC: 0.002010 | Net:  0.04491\n",
      "  MV   - Gross:  0.07609 | Turnover: 4.6544 | TC: 0.005009 | Net:  0.07108\n",
      "  MSR  - Gross:  0.07385 | Turnover: 2.0236 | TC: 0.002173 | Net:  0.07167\n",
      "\n",
      "[14/112] Date: 2016-02-29 | Year: 2016\n",
      "  Window: 2001-02-28 to 2016-01-31\n",
      "  Yearly: 81 | Analyst: 117 | Union/Intersection: 16 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07956 | Turnover: 1.7787 | TC: 0.001920 | Net:  0.07764\n",
      "  MV   - Gross:  0.06202 | Turnover: 2.2638 | TC: 0.002404 | Net:  0.05961\n",
      "  MSR  - Gross:  0.07058 | Turnover: 1.8936 | TC: 0.002027 | Net:  0.06855\n",
      "\n",
      "[15/112] Date: 2016-03-31 | Year: 2016\n",
      "  Window: 2001-03-31 to 2016-02-29\n",
      "  Yearly: 81 | Analyst: 113 | Union/Intersection: 14 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02476 | Turnover: 1.0398 | TC: 0.001014 | Net: -0.02577\n",
      "  MV   - Gross: -0.09720 | Turnover: 7.2747 | TC: 0.006568 | Net: -0.10377\n",
      "  MSR  - Gross: -0.02873 | Turnover: 1.7111 | TC: 0.001662 | Net: -0.03039\n",
      "\n",
      "[16/112] Date: 2016-04-30 | Year: 2016\n",
      "  Window: 2001-04-30 to 2016-03-31\n",
      "  Yearly: 81 | Analyst: 115 | Union/Intersection: 20 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03516 | Turnover: 1.9338 | TC: 0.002002 | Net:  0.03316\n",
      "  MV   - Gross:  0.02713 | Turnover: 7.2335 | TC: 0.007430 | Net:  0.01970\n",
      "  MSR  - Gross:  0.02065 | Turnover: 2.0331 | TC: 0.002075 | Net:  0.01858\n",
      "\n",
      "[17/112] Date: 2016-05-31 | Year: 2016\n",
      "  Window: 2001-05-31 to 2016-04-30\n",
      "  Yearly: 81 | Analyst: 99 | Union/Intersection: 17 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00616 | Turnover: 1.4550 | TC: 0.001464 | Net:  0.00470\n",
      "  MV   - Gross:  0.01294 | Turnover: 1.3593 | TC: 0.001377 | Net:  0.01156\n",
      "  MSR  - Gross:  0.01920 | Turnover: 1.2968 | TC: 0.001322 | Net:  0.01787\n",
      "\n",
      "[18/112] Date: 2016-06-30 | Year: 2016\n",
      "  Window: 2001-06-30 to 2016-05-31\n",
      "  Yearly: 81 | Analyst: 114 | Union/Intersection: 14 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03132 | Turnover: 2.0392 | TC: 0.002103 | Net:  0.02922\n",
      "  MV   - Gross: -0.00044 | Turnover: 2.4227 | TC: 0.002422 | Net: -0.00286\n",
      "  MSR  - Gross:  0.00724 | Turnover: 2.2423 | TC: 0.002259 | Net:  0.00498\n",
      "\n",
      "[19/112] Date: 2016-07-31 | Year: 2016\n",
      "  Window: 2001-07-31 to 2016-06-30\n",
      "  Yearly: 81 | Analyst: 101 | Union/Intersection: 20 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00235 | Turnover: 1.6063 | TC: 0.001603 | Net: -0.00395\n",
      "  MV   - Gross: -0.14923 | Turnover: 4.8619 | TC: 0.004136 | Net: -0.15336\n",
      "  MSR  - Gross: -0.03153 | Turnover: 2.3942 | TC: 0.002319 | Net: -0.03385\n",
      "\n",
      "[20/112] Date: 2016-08-31 | Year: 2016\n",
      "  Window: 2001-08-31 to 2016-07-31\n",
      "  Yearly: 81 | Analyst: 98 | Union/Intersection: 17 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01189 | Turnover: 1.3231 | TC: 0.001307 | Net: -0.01320\n",
      "  MV   - Gross: -0.01455 | Turnover: 5.0394 | TC: 0.004966 | Net: -0.01952\n",
      "  MSR  - Gross: -0.01362 | Turnover: 1.8972 | TC: 0.001871 | Net: -0.01549\n",
      "\n",
      "[21/112] Date: 2016-09-30 | Year: 2016\n",
      "  Window: 2001-09-30 to 2016-08-31\n",
      "  Yearly: 81 | Analyst: 137 | Union/Intersection: 17 | Assets w/ data: 8\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00621 | Turnover: 1.0421 | TC: 0.001036 | Net: -0.00725\n",
      "  MV   - Gross: -0.00059 | Turnover: 1.0624 | TC: 0.001062 | Net: -0.00165\n",
      "  MSR  - Gross:  0.00109 | Turnover: 0.9264 | TC: 0.000927 | Net:  0.00017\n",
      "\n",
      "[22/112] Date: 2016-10-31 | Year: 2016\n",
      "  Window: 2001-10-31 to 2016-09-30\n",
      "  Yearly: 81 | Analyst: 178 | Union/Intersection: 23 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04421 | Turnover: 1.3351 | TC: 0.001394 | Net:  0.04281\n",
      "  MV   - Gross:  0.02399 | Turnover: 2.0676 | TC: 0.002117 | Net:  0.02187\n",
      "  MSR  - Gross:  0.03328 | Turnover: 1.7717 | TC: 0.001831 | Net:  0.03145\n",
      "\n",
      "[23/112] Date: 2016-11-30 | Year: 2016\n",
      "  Window: 2001-11-30 to 2016-10-31\n",
      "  Yearly: 81 | Analyst: 151 | Union/Intersection: 23 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01889 | Turnover: 1.7331 | TC: 0.001766 | Net:  0.01712\n",
      "  MV   - Gross: -0.00811 | Turnover: 1.9173 | TC: 0.001902 | Net: -0.01001\n",
      "  MSR  - Gross: -0.01066 | Turnover: 1.7444 | TC: 0.001726 | Net: -0.01239\n",
      "\n",
      "[24/112] Date: 2016-12-31 | Year: 2016\n",
      "  Window: 2001-12-31 to 2016-11-30\n",
      "  Yearly: 81 | Analyst: 88 | Union/Intersection: 12 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00578 | Turnover: 1.3427 | TC: 0.001335 | Net: -0.00711\n",
      "  MV   - Gross: -0.00292 | Turnover: 1.7896 | TC: 0.001784 | Net: -0.00470\n",
      "  MSR  - Gross: -0.00463 | Turnover: 1.4082 | TC: 0.001402 | Net: -0.00603\n",
      "\n",
      "[25/112] Date: 2017-01-31 | Year: 2017\n",
      "  Window: 2002-01-31 to 2016-12-31\n",
      "  Yearly: 35 | Analyst: 109 | Union/Intersection: 6 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03373 | Turnover: 1.8364 | TC: 0.001898 | Net:  0.03183\n",
      "  MV   - Gross:  0.03318 | Turnover: 2.2065 | TC: 0.002280 | Net:  0.03090\n",
      "  MSR  - Gross:  0.03357 | Turnover: 1.8794 | TC: 0.001942 | Net:  0.03163\n",
      "\n",
      "[26/112] Date: 2017-02-28 | Year: 2017\n",
      "  Window: 2002-02-28 to 2017-01-31\n",
      "  Yearly: 35 | Analyst: 105 | Union/Intersection: 7 | Assets w/ data: 2\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02778 | Turnover: 1.8472 | TC: 0.001796 | Net: -0.02957\n",
      "  MV   - Gross: -0.02790 | Turnover: 1.8584 | TC: 0.001807 | Net: -0.02971\n",
      "  MSR  - Gross: -0.01512 | Turnover: 1.8505 | TC: 0.001823 | Net: -0.01694\n",
      "\n",
      "[27/112] Date: 2017-03-31 | Year: 2017\n",
      "  Window: 2002-03-31 to 2017-02-28\n",
      "  Yearly: 35 | Analyst: 136 | Union/Intersection: 5 | Assets w/ data: 3\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00574 | Turnover: 1.8063 | TC: 0.001796 | Net: -0.00753\n",
      "  MV   - Gross: -0.04545 | Turnover: 1.9839 | TC: 0.001894 | Net: -0.04734\n",
      "  MSR  - Gross: -0.01450 | Turnover: 1.8455 | TC: 0.001819 | Net: -0.01632\n",
      "\n",
      "[28/112] Date: 2017-04-30 | Year: 2017\n",
      "  Window: 2002-04-30 to 2017-03-31\n",
      "  Yearly: 35 | Analyst: 106 | Union/Intersection: 4 | Assets w/ data: 1\n",
      "  ⚠ Insufficient data (n=180, p=1), recording 0 return\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "\n",
      "[29/112] Date: 2017-05-31 | Year: 2017\n",
      "  Window: 2002-05-31 to 2017-04-30\n",
      "  Yearly: 35 | Analyst: 89 | Union/Intersection: 4 | Assets w/ data: 1\n",
      "  ⚠ Insufficient data (n=180, p=1), recording 0 return\n",
      "\n",
      "[30/112] Date: 2017-06-30 | Year: 2017\n",
      "  Window: 2002-06-30 to 2017-05-31\n",
      "  Yearly: 35 | Analyst: 129 | Union/Intersection: 11 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02924 | Turnover: 1.0000 | TC: 0.001029 | Net:  0.02821\n",
      "  MV   - Gross:  0.03268 | Turnover: 1.3816 | TC: 0.001427 | Net:  0.03126\n",
      "  MSR  - Gross:  0.03095 | Turnover: 1.0583 | TC: 0.001091 | Net:  0.02985\n",
      "\n",
      "[31/112] Date: 2017-07-31 | Year: 2017\n",
      "  Window: 2002-07-31 to 2017-06-30\n",
      "  Yearly: 35 | Analyst: 110 | Union/Intersection: 6 | Assets w/ data: 3\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00195 | Turnover: 2.0000 | TC: 0.002004 | Net: -0.00006\n",
      "  MV   - Gross:  0.00384 | Turnover: 2.3753 | TC: 0.002384 | Net:  0.00146\n",
      "  MSR  - Gross:  0.00292 | Turnover: 2.0574 | TC: 0.002063 | Net:  0.00086\n",
      "\n",
      "[32/112] Date: 2017-08-31 | Year: 2017\n",
      "  Window: 2002-08-31 to 2017-07-31\n",
      "  Yearly: 35 | Analyst: 89 | Union/Intersection: 9 | Assets w/ data: 3\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.06661 | Turnover: 1.5573 | TC: 0.001661 | Net:  0.06495\n",
      "  MV   - Gross:  0.06226 | Turnover: 1.7848 | TC: 0.001896 | Net:  0.06036\n",
      "  MSR  - Gross:  0.07290 | Turnover: 1.3312 | TC: 0.001428 | Net:  0.07147\n",
      "\n",
      "[33/112] Date: 2017-09-30 | Year: 2017\n",
      "  Window: 2002-09-30 to 2017-08-31\n",
      "  Yearly: 35 | Analyst: 111 | Union/Intersection: 6 | Assets w/ data: 3\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.03112 | Turnover: 1.6527 | TC: 0.001601 | Net: -0.03272\n",
      "  MV   - Gross:  0.03330 | Turnover: 1.7781 | TC: 0.001837 | Net:  0.03147\n",
      "  MSR  - Gross: -0.07181 | Turnover: 1.5735 | TC: 0.001460 | Net: -0.07327\n",
      "\n",
      "[34/112] Date: 2017-10-31 | Year: 2017\n",
      "  Window: 2002-10-31 to 2017-09-30\n",
      "  Yearly: 35 | Analyst: 137 | Union/Intersection: 10 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.05655 | Turnover: 1.4776 | TC: 0.001561 | Net:  0.05499\n",
      "  MV   - Gross:  0.06015 | Turnover: 1.4169 | TC: 0.001502 | Net:  0.05865\n",
      "  MSR  - Gross:  0.06532 | Turnover: 1.3295 | TC: 0.001416 | Net:  0.06391\n",
      "\n",
      "[35/112] Date: 2017-11-30 | Year: 2017\n",
      "  Window: 2002-11-30 to 2017-10-31\n",
      "  Yearly: 35 | Analyst: 92 | Union/Intersection: 3 | Assets w/ data: 1\n",
      "  ⚠ Insufficient data (n=180, p=1), recording 0 return\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "\n",
      "[36/112] Date: 2017-12-31 | Year: 2017\n",
      "  Window: 2002-12-31 to 2017-11-30\n",
      "  Yearly: 35 | Analyst: 96 | Union/Intersection: 7 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00357 | Turnover: 1.0000 | TC: 0.000996 | Net: -0.00457\n",
      "  MV   - Gross: -0.00379 | Turnover: 1.0000 | TC: 0.000996 | Net: -0.00478\n",
      "  MSR  - Gross:  0.00293 | Turnover: 1.0000 | TC: 0.001003 | Net:  0.00193\n",
      "\n",
      "[37/112] Date: 2018-01-31 | Year: 2018\n",
      "  Window: 2003-01-31 to 2017-12-31\n",
      "  Yearly: 75 | Analyst: 161 | Union/Intersection: 23 | Assets w/ data: 8\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.07017 | Turnover: 2.0000 | TC: 0.001860 | Net: -0.07203\n",
      "  MV   - Gross: -0.07263 | Turnover: 2.0000 | TC: 0.001855 | Net: -0.07449\n",
      "  MSR  - Gross: -0.05178 | Turnover: 2.0000 | TC: 0.001896 | Net: -0.05368\n",
      "\n",
      "[38/112] Date: 2018-02-28 | Year: 2018\n",
      "  Window: 2003-02-28 to 2018-01-31\n",
      "  Yearly: 75 | Analyst: 160 | Union/Intersection: 20 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02574 | Turnover: 0.9224 | TC: 0.000899 | Net: -0.02664\n",
      "  MV   - Gross: -0.02376 | Turnover: 1.0113 | TC: 0.000987 | Net: -0.02475\n",
      "  MSR  - Gross: -0.03244 | Turnover: 0.6525 | TC: 0.000631 | Net: -0.03307\n",
      "\n",
      "[39/112] Date: 2018-03-31 | Year: 2018\n",
      "  Window: 2003-03-31 to 2018-02-28\n",
      "  Yearly: 75 | Analyst: 100 | Union/Intersection: 13 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07032 | Turnover: 1.4231 | TC: 0.001523 | Net:  0.06880\n",
      "  MV   - Gross:  0.07213 | Turnover: 1.4149 | TC: 0.001517 | Net:  0.07061\n",
      "  MSR  - Gross:  0.03510 | Turnover: 1.5902 | TC: 0.001646 | Net:  0.03345\n",
      "\n",
      "[40/112] Date: 2018-04-30 | Year: 2018\n",
      "  Window: 2003-04-30 to 2018-03-31\n",
      "  Yearly: 75 | Analyst: 106 | Union/Intersection: 16 | Assets w/ data: 10\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02169 | Turnover: 1.8779 | TC: 0.001919 | Net:  0.01977\n",
      "  MV   - Gross: -0.00396 | Turnover: 2.0035 | TC: 0.001996 | Net: -0.00595\n",
      "  MSR  - Gross:  0.05790 | Turnover: 2.0369 | TC: 0.002155 | Net:  0.05575\n",
      "\n",
      "[41/112] Date: 2018-05-31 | Year: 2018\n",
      "  Window: 2003-05-31 to 2018-04-30\n",
      "  Yearly: 75 | Analyst: 85 | Union/Intersection: 10 | Assets w/ data: 3\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00303 | Turnover: 1.0492 | TC: 0.001052 | Net:  0.00198\n",
      "  MV   - Gross:  0.00628 | Turnover: 1.3922 | TC: 0.001401 | Net:  0.00487\n",
      "  MSR  - Gross: -0.00044 | Turnover: 0.9450 | TC: 0.000945 | Net: -0.00139\n",
      "\n",
      "[42/112] Date: 2018-06-30 | Year: 2018\n",
      "  Window: 2003-06-30 to 2018-05-31\n",
      "  Yearly: 75 | Analyst: 133 | Union/Intersection: 17 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03249 | Turnover: 1.6030 | TC: 0.001655 | Net:  0.03084\n",
      "  MV   - Gross:  0.03084 | Turnover: 1.6526 | TC: 0.001704 | Net:  0.02914\n",
      "  MSR  - Gross:  0.02478 | Turnover: 1.2860 | TC: 0.001318 | Net:  0.02346\n",
      "\n",
      "[43/112] Date: 2018-07-31 | Year: 2018\n",
      "  Window: 2003-07-31 to 2018-06-30\n",
      "  Yearly: 75 | Analyst: 125 | Union/Intersection: 14 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01666 | Turnover: 1.5289 | TC: 0.001554 | Net:  0.01511\n",
      "  MV   - Gross:  0.01743 | Turnover: 1.5640 | TC: 0.001591 | Net:  0.01584\n",
      "  MSR  - Gross:  0.01339 | Turnover: 1.6941 | TC: 0.001717 | Net:  0.01168\n",
      "\n",
      "[44/112] Date: 2018-08-31 | Year: 2018\n",
      "  Window: 2003-08-31 to 2018-07-31\n",
      "  Yearly: 75 | Analyst: 73 | Union/Intersection: 8 | Assets w/ data: 3\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00383 | Turnover: 1.6237 | TC: 0.001630 | Net:  0.00220\n",
      "  MV   - Gross:  0.01048 | Turnover: 1.6047 | TC: 0.001622 | Net:  0.00886\n",
      "  MSR  - Gross: -0.00648 | Turnover: 1.8586 | TC: 0.001847 | Net: -0.00833\n",
      "\n",
      "[45/112] Date: 2018-09-30 | Year: 2018\n",
      "  Window: 2003-09-30 to 2018-08-31\n",
      "  Yearly: 75 | Analyst: 116 | Union/Intersection: 21 | Assets w/ data: 8\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.03948 | Turnover: 1.4946 | TC: 0.001436 | Net: -0.04092\n",
      "  MV   - Gross: -0.03213 | Turnover: 1.6022 | TC: 0.001551 | Net: -0.03368\n",
      "  MSR  - Gross: -0.07323 | Turnover: 1.2350 | TC: 0.001145 | Net: -0.07437\n",
      "\n",
      "[46/112] Date: 2018-10-31 | Year: 2018\n",
      "  Window: 2003-10-31 to 2018-09-30\n",
      "  Yearly: 75 | Analyst: 172 | Union/Intersection: 26 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01764 | Turnover: 0.5130 | TC: 0.000522 | Net:  0.01711\n",
      "  MV   - Gross:  0.03068 | Turnover: 0.5926 | TC: 0.000611 | Net:  0.03007\n",
      "  MSR  - Gross: -0.06721 | Turnover: 0.3130 | TC: 0.000292 | Net: -0.06751\n",
      "\n",
      "[47/112] Date: 2018-11-30 | Year: 2018\n",
      "  Window: 2003-11-30 to 2018-10-31\n",
      "  Yearly: 75 | Analyst: 99 | Union/Intersection: 14 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.09054 | Turnover: 1.9924 | TC: 0.001812 | Net: -0.09235\n",
      "  MV   - Gross: -0.09395 | Turnover: 2.2451 | TC: 0.002034 | Net: -0.09599\n",
      "  MSR  - Gross: -0.08437 | Turnover: 1.5942 | TC: 0.001460 | Net: -0.08583\n",
      "\n",
      "[48/112] Date: 2018-12-31 | Year: 2018\n",
      "  Window: 2003-12-31 to 2018-11-30\n",
      "  Yearly: 75 | Analyst: 89 | Union/Intersection: 10 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.12728 | Turnover: 1.7598 | TC: 0.001984 | Net:  0.12530\n",
      "  MV   - Gross:  0.13542 | Turnover: 2.1126 | TC: 0.002399 | Net:  0.13302\n",
      "  MSR  - Gross:  0.12375 | Turnover: 1.9524 | TC: 0.002194 | Net:  0.12155\n",
      "\n",
      "[49/112] Date: 2019-01-31 | Year: 2019\n",
      "  Window: 2004-01-31 to 2018-12-31\n",
      "  Yearly: 269 | Analyst: 137 | Union/Intersection: 65 | Assets w/ data: 31\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04332 | Turnover: 2.1798 | TC: 0.002274 | Net:  0.04104\n",
      "  MV   - Gross:  0.04454 | Turnover: 2.5342 | TC: 0.002647 | Net:  0.04189\n",
      "  MSR  - Gross:  0.04755 | Turnover: 2.3781 | TC: 0.002491 | Net:  0.04506\n",
      "\n",
      "[50/112] Date: 2019-02-28 | Year: 2019\n",
      "  Window: 2004-02-29 to 2019-01-31\n",
      "  Yearly: 269 | Analyst: 103 | Union/Intersection: 42 | Assets w/ data: 18\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00116 | Turnover: 1.7351 | TC: 0.001733 | Net: -0.00289\n",
      "  MV   - Gross: -0.00515 | Turnover: 1.8028 | TC: 0.001793 | Net: -0.00695\n",
      "  MSR  - Gross:  0.01605 | Turnover: 1.7600 | TC: 0.001788 | Net:  0.01426\n",
      "\n",
      "[51/112] Date: 2019-03-31 | Year: 2019\n",
      "  Window: 2004-03-31 to 2019-02-28\n",
      "  Yearly: 269 | Analyst: 255 | Union/Intersection: 111 | Assets w/ data: 55\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02360 | Turnover: 2.1323 | TC: 0.002183 | Net:  0.02142\n",
      "  MV   - Gross:  0.02356 | Turnover: 2.1904 | TC: 0.002242 | Net:  0.02132\n",
      "  MSR  - Gross:  0.02634 | Turnover: 2.4689 | TC: 0.002534 | Net:  0.02381\n",
      "\n",
      "[52/112] Date: 2019-04-30 | Year: 2019\n",
      "  Window: 2004-04-30 to 2019-03-31\n",
      "  Yearly: 269 | Analyst: 160 | Union/Intersection: 58 | Assets w/ data: 29\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.03720 | Turnover: 1.8639 | TC: 0.001795 | Net: -0.03900\n",
      "  MV   - Gross: -0.03836 | Turnover: 1.8701 | TC: 0.001798 | Net: -0.04016\n",
      "  MSR  - Gross: -0.04758 | Turnover: 2.1689 | TC: 0.002066 | Net: -0.04965\n",
      "\n",
      "[53/112] Date: 2019-05-31 | Year: 2019\n",
      "  Window: 2004-05-31 to 2019-04-30\n",
      "  Yearly: 269 | Analyst: 99 | Union/Intersection: 39 | Assets w/ data: 13\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.05320 | Turnover: 2.0119 | TC: 0.002119 | Net:  0.05108\n",
      "  MV   - Gross:  0.05752 | Turnover: 1.9954 | TC: 0.002110 | Net:  0.05541\n",
      "  MSR  - Gross:  0.06943 | Turnover: 2.0524 | TC: 0.002195 | Net:  0.06724\n",
      "\n",
      "[54/112] Date: 2019-06-30 | Year: 2019\n",
      "  Window: 2004-06-30 to 2019-05-31\n",
      "  Yearly: 269 | Analyst: 104 | Union/Intersection: 38 | Assets w/ data: 19\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03425 | Turnover: 1.4911 | TC: 0.001542 | Net:  0.03270\n",
      "  MV   - Gross:  0.03705 | Turnover: 1.4628 | TC: 0.001517 | Net:  0.03553\n",
      "  MSR  - Gross:  0.04729 | Turnover: 1.4692 | TC: 0.001539 | Net:  0.04575\n",
      "\n",
      "[55/112] Date: 2019-07-31 | Year: 2019\n",
      "  Window: 2004-07-31 to 2019-06-30\n",
      "  Yearly: 269 | Analyst: 101 | Union/Intersection: 45 | Assets w/ data: 24\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01078 | Turnover: 1.7813 | TC: 0.001801 | Net:  0.00898\n",
      "  MV   - Gross:  0.01085 | Turnover: 1.7637 | TC: 0.001783 | Net:  0.00906\n",
      "  MSR  - Gross:  0.01133 | Turnover: 1.7980 | TC: 0.001818 | Net:  0.00951\n",
      "\n",
      "[56/112] Date: 2019-08-31 | Year: 2019\n",
      "  Window: 2004-08-31 to 2019-07-31\n",
      "  Yearly: 269 | Analyst: 86 | Union/Intersection: 34 | Assets w/ data: 17\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02922 | Turnover: 1.7720 | TC: 0.001824 | Net:  0.02739\n",
      "  MV   - Gross:  0.03076 | Turnover: 1.7497 | TC: 0.001804 | Net:  0.02895\n",
      "  MSR  - Gross:  0.02393 | Turnover: 2.0326 | TC: 0.002081 | Net:  0.02185\n",
      "\n",
      "[57/112] Date: 2019-09-30 | Year: 2019\n",
      "  Window: 2004-09-30 to 2019-08-31\n",
      "  Yearly: 269 | Analyst: 104 | Union/Intersection: 46 | Assets w/ data: 19\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02160 | Turnover: 2.0838 | TC: 0.002039 | Net: -0.02363\n",
      "  MV   - Gross: -0.02022 | Turnover: 2.0974 | TC: 0.002055 | Net: -0.02228\n",
      "  MSR  - Gross:  0.01211 | Turnover: 2.4400 | TC: 0.002470 | Net:  0.00964\n",
      "\n",
      "[58/112] Date: 2019-10-31 | Year: 2019\n",
      "  Window: 2004-10-31 to 2019-09-30\n",
      "  Yearly: 269 | Analyst: 90 | Union/Intersection: 38 | Assets w/ data: 22\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01533 | Turnover: 1.5443 | TC: 0.001568 | Net:  0.01377\n",
      "  MV   - Gross:  0.01468 | Turnover: 1.5377 | TC: 0.001560 | Net:  0.01312\n",
      "  MSR  - Gross:  0.01344 | Turnover: 1.5937 | TC: 0.001615 | Net:  0.01182\n",
      "\n",
      "[59/112] Date: 2019-11-30 | Year: 2019\n",
      "  Window: 2004-11-30 to 2019-10-31\n",
      "  Yearly: 269 | Analyst: 81 | Union/Intersection: 41 | Assets w/ data: 21\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02997 | Turnover: 1.9801 | TC: 0.002039 | Net:  0.02793\n",
      "  MV   - Gross:  0.02824 | Turnover: 2.0216 | TC: 0.002079 | Net:  0.02617\n",
      "  MSR  - Gross:  0.03767 | Turnover: 1.9603 | TC: 0.002034 | Net:  0.03564\n",
      "\n",
      "[60/112] Date: 2019-12-31 | Year: 2019\n",
      "  Window: 2004-12-31 to 2019-11-30\n",
      "  Yearly: 269 | Analyst: 97 | Union/Intersection: 43 | Assets w/ data: 24\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00394 | Turnover: 1.9278 | TC: 0.001935 | Net:  0.00200\n",
      "  MV   - Gross:  0.00805 | Turnover: 1.9673 | TC: 0.001983 | Net:  0.00607\n",
      "  MSR  - Gross:  0.03149 | Turnover: 2.1310 | TC: 0.002198 | Net:  0.02929\n",
      "\n",
      "[61/112] Date: 2020-01-31 | Year: 2020\n",
      "  Window: 2005-01-31 to 2019-12-31\n",
      "  Yearly: 40 | Analyst: 94 | Union/Intersection: 9 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.08906 | Turnover: 2.1270 | TC: 0.001938 | Net: -0.09100\n",
      "  MV   - Gross: -0.11257 | Turnover: 2.6712 | TC: 0.002371 | Net: -0.11494\n",
      "  MSR  - Gross: -0.09214 | Turnover: 2.3268 | TC: 0.002112 | Net: -0.09426\n",
      "\n",
      "[62/112] Date: 2020-02-29 | Year: 2020\n",
      "  Window: 2005-02-28 to 2020-01-31\n",
      "  Yearly: 40 | Analyst: 81 | Union/Intersection: 5 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.19806 | Turnover: 1.7055 | TC: 0.001368 | Net: -0.19943\n",
      "  MV   - Gross: -0.22405 | Turnover: 2.3088 | TC: 0.001792 | Net: -0.22585\n",
      "  MSR  - Gross: -0.20062 | Turnover: 1.6630 | TC: 0.001329 | Net: -0.20195\n",
      "\n",
      "[63/112] Date: 2020-03-31 | Year: 2020\n",
      "  Window: 2005-03-31 to 2020-02-29\n",
      "  Yearly: 40 | Analyst: 202 | Union/Intersection: 17 | Assets w/ data: 14\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.09714 | Turnover: 1.2215 | TC: 0.001340 | Net:  0.09580\n",
      "  MV   - Gross:  0.01787 | Turnover: 2.1272 | TC: 0.002165 | Net:  0.01570\n",
      "  MSR  - Gross:  0.06769 | Turnover: 1.2853 | TC: 0.001372 | Net:  0.06632\n",
      "\n",
      "[64/112] Date: 2020-04-30 | Year: 2020\n",
      "  Window: 2005-04-30 to 2020-03-31\n",
      "  Yearly: 40 | Analyst: 220 | Union/Intersection: 17 | Assets w/ data: 14\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01296 | Turnover: 1.1524 | TC: 0.001167 | Net:  0.01179\n",
      "  MV   - Gross:  0.01932 | Turnover: 1.9682 | TC: 0.002006 | Net:  0.01732\n",
      "  MSR  - Gross:  0.01716 | Turnover: 1.3866 | TC: 0.001410 | Net:  0.01575\n",
      "\n",
      "[65/112] Date: 2020-05-31 | Year: 2020\n",
      "  Window: 2005-05-31 to 2020-04-30\n",
      "  Yearly: 40 | Analyst: 132 | Union/Intersection: 5 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00021 | Turnover: 1.8482 | TC: 0.001849 | Net: -0.00164\n",
      "  MV   - Gross: -0.03037 | Turnover: 2.2335 | TC: 0.002166 | Net: -0.03254\n",
      "  MSR  - Gross: -0.02938 | Turnover: 2.1649 | TC: 0.002101 | Net: -0.03148\n",
      "\n",
      "[66/112] Date: 2020-06-30 | Year: 2020\n",
      "  Window: 2005-06-30 to 2020-05-31\n",
      "  Yearly: 40 | Analyst: 115 | Union/Intersection: 9 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.05283 | Turnover: 1.9050 | TC: 0.002006 | Net:  0.05082\n",
      "  MV   - Gross:  0.06203 | Turnover: 2.3711 | TC: 0.002518 | Net:  0.05951\n",
      "  MSR  - Gross:  0.05890 | Turnover: 2.2011 | TC: 0.002331 | Net:  0.05657\n",
      "\n",
      "[67/112] Date: 2020-07-31 | Year: 2020\n",
      "  Window: 2005-07-31 to 2020-06-30\n",
      "  Yearly: 40 | Analyst: 147 | Union/Intersection: 11 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03627 | Turnover: 1.8845 | TC: 0.001953 | Net:  0.03432\n",
      "  MV   - Gross:  0.04822 | Turnover: 2.6024 | TC: 0.002728 | Net:  0.04549\n",
      "  MSR  - Gross:  0.05237 | Turnover: 2.7192 | TC: 0.002862 | Net:  0.04951\n",
      "\n",
      "[68/112] Date: 2020-08-31 | Year: 2020\n",
      "  Window: 2005-08-31 to 2020-07-31\n",
      "  Yearly: 40 | Analyst: 69 | Union/Intersection: 108 | Assets w/ data: 45\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00731 | Turnover: 2.1538 | TC: 0.002138 | Net: -0.00944\n",
      "  MV   - Gross: -0.00683 | Turnover: 2.5625 | TC: 0.002545 | Net: -0.00937\n",
      "  MSR  - Gross: -0.00546 | Turnover: 2.9834 | TC: 0.002967 | Net: -0.00843\n",
      "\n",
      "[69/112] Date: 2020-09-30 | Year: 2020\n",
      "  Window: 2005-09-30 to 2020-08-31\n",
      "  Yearly: 40 | Analyst: 121 | Union/Intersection: 10 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03148 | Turnover: 1.9231 | TC: 0.001984 | Net:  0.02950\n",
      "  MV   - Gross:  0.02448 | Turnover: 2.7680 | TC: 0.002836 | Net:  0.02164\n",
      "  MSR  - Gross:  0.02948 | Turnover: 2.3171 | TC: 0.002385 | Net:  0.02709\n",
      "\n",
      "[70/112] Date: 2020-10-31 | Year: 2020\n",
      "  Window: 2005-10-31 to 2020-09-30\n",
      "  Yearly: 40 | Analyst: 103 | Union/Intersection: 4 | Assets w/ data: 2\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00559 | Turnover: 2.0805 | TC: 0.002069 | Net: -0.00766\n",
      "  MV   - Gross: -0.01839 | Turnover: 2.9689 | TC: 0.002914 | Net: -0.02130\n",
      "  MSR  - Gross: -0.00990 | Turnover: 2.2254 | TC: 0.002203 | Net: -0.01210\n",
      "\n",
      "[71/112] Date: 2020-11-30 | Year: 2020\n",
      "  Window: 2005-11-30 to 2020-10-31\n",
      "  Yearly: 40 | Analyst: 118 | Union/Intersection: 12 | Assets w/ data: 8\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01483 | Turnover: 2.0196 | TC: 0.002050 | Net:  0.01278\n",
      "  MV   - Gross:  0.00508 | Turnover: 2.2315 | TC: 0.002243 | Net:  0.00284\n",
      "  MSR  - Gross: -0.00071 | Turnover: 2.2846 | TC: 0.002283 | Net: -0.00299\n",
      "\n",
      "[72/112] Date: 2020-12-31 | Year: 2020\n",
      "  Window: 2005-12-31 to 2020-11-30\n",
      "  Yearly: 40 | Analyst: 84 | Union/Intersection: 6 | Assets w/ data: 3\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03032 | Turnover: 1.9453 | TC: 0.002004 | Net:  0.02832\n",
      "  MV   - Gross:  0.01220 | Turnover: 3.0298 | TC: 0.003067 | Net:  0.00914\n",
      "  MSR  - Gross:  0.02598 | Turnover: 2.3483 | TC: 0.002409 | Net:  0.02357\n",
      "\n",
      "[73/112] Date: 2021-01-31 | Year: 2021\n",
      "  Window: 2006-01-31 to 2020-12-31\n",
      "  Yearly: 123 | Analyst: 123 | Union/Intersection: 32 | Assets w/ data: 21\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02365 | Turnover: 2.2635 | TC: 0.002317 | Net:  0.02133\n",
      "  MV   - Gross: -0.02460 | Turnover: 3.3793 | TC: 0.003296 | Net: -0.02790\n",
      "  MSR  - Gross: -0.04363 | Turnover: 2.7451 | TC: 0.002625 | Net: -0.04625\n",
      "\n",
      "[74/112] Date: 2021-02-28 | Year: 2021\n",
      "  Window: 2006-02-28 to 2021-01-31\n",
      "  Yearly: 123 | Analyst: 92 | Union/Intersection: 26 | Assets w/ data: 16\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.08523 | Turnover: 1.6875 | TC: 0.001831 | Net:  0.08340\n",
      "  MV   - Gross:  0.09076 | Turnover: 2.0337 | TC: 0.002218 | Net:  0.08854\n",
      "  MSR  - Gross:  0.09513 | Turnover: 2.4355 | TC: 0.002667 | Net:  0.09246\n",
      "\n",
      "[75/112] Date: 2021-03-31 | Year: 2021\n",
      "  Window: 2006-03-31 to 2021-02-28\n",
      "  Yearly: 123 | Analyst: 107 | Union/Intersection: 19 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07896 | Turnover: 1.6662 | TC: 0.001798 | Net:  0.07716\n",
      "  MV   - Gross:  0.07911 | Turnover: 1.7659 | TC: 0.001906 | Net:  0.07721\n",
      "  MSR  - Gross:  0.07922 | Turnover: 1.9422 | TC: 0.002096 | Net:  0.07713\n",
      "\n",
      "[76/112] Date: 2021-04-30 | Year: 2021\n",
      "  Window: 2006-04-30 to 2021-03-31\n",
      "  Yearly: 123 | Analyst: 115 | Union/Intersection: 22 | Assets w/ data: 15\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02741 | Turnover: 1.5266 | TC: 0.001568 | Net:  0.02584\n",
      "  MV   - Gross:  0.03063 | Turnover: 1.8626 | TC: 0.001920 | Net:  0.02871\n",
      "  MSR  - Gross:  0.01464 | Turnover: 2.3883 | TC: 0.002423 | Net:  0.01221\n",
      "\n",
      "[77/112] Date: 2021-05-31 | Year: 2021\n",
      "  Window: 2006-05-31 to 2021-04-30\n",
      "  Yearly: 123 | Analyst: 96 | Union/Intersection: 18 | Assets w/ data: 13\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01550 | Turnover: 2.1965 | TC: 0.002162 | Net: -0.01767\n",
      "  MV   - Gross: -0.01377 | Turnover: 2.2180 | TC: 0.002187 | Net: -0.01596\n",
      "  MSR  - Gross: -0.00804 | Turnover: 2.5708 | TC: 0.002550 | Net: -0.01059\n",
      "\n",
      "[78/112] Date: 2021-06-30 | Year: 2021\n",
      "  Window: 2006-06-30 to 2021-05-31\n",
      "  Yearly: 123 | Analyst: 108 | Union/Intersection: 22 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02836 | Turnover: 1.9196 | TC: 0.001974 | Net:  0.02639\n",
      "  MV   - Gross:  0.01026 | Turnover: 2.0332 | TC: 0.002054 | Net:  0.00821\n",
      "  MSR  - Gross:  0.05055 | Turnover: 2.2743 | TC: 0.002389 | Net:  0.04816\n",
      "\n",
      "[79/112] Date: 2021-07-31 | Year: 2021\n",
      "  Window: 2006-07-31 to 2021-06-30\n",
      "  Yearly: 123 | Analyst: 85 | Union/Intersection: 19 | Assets w/ data: 12\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00926 | Turnover: 1.3834 | TC: 0.001371 | Net: -0.01063\n",
      "  MV   - Gross: -0.00216 | Turnover: 1.5107 | TC: 0.001507 | Net: -0.00367\n",
      "  MSR  - Gross: -0.01567 | Turnover: 1.3551 | TC: 0.001334 | Net: -0.01701\n",
      "\n",
      "[80/112] Date: 2021-08-31 | Year: 2021\n",
      "  Window: 2006-08-31 to 2021-07-31\n",
      "  Yearly: 123 | Analyst: 68 | Union/Intersection: 15 | Assets w/ data: 14\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00637 | Turnover: 1.6447 | TC: 0.001634 | Net: -0.00800\n",
      "  MV   - Gross: -0.00779 | Turnover: 1.8485 | TC: 0.001834 | Net: -0.00963\n",
      "  MSR  - Gross: -0.00116 | Turnover: 1.5901 | TC: 0.001588 | Net: -0.00275\n",
      "\n",
      "[81/112] Date: 2021-09-30 | Year: 2021\n",
      "  Window: 2006-09-30 to 2021-08-31\n",
      "  Yearly: 123 | Analyst: 87 | Union/Intersection: 16 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03751 | Turnover: 1.3324 | TC: 0.001382 | Net:  0.03613\n",
      "  MV   - Gross:  0.03947 | Turnover: 1.3196 | TC: 0.001372 | Net:  0.03810\n",
      "  MSR  - Gross:  0.03225 | Turnover: 1.5431 | TC: 0.001593 | Net:  0.03066\n",
      "\n",
      "[82/112] Date: 2021-10-31 | Year: 2021\n",
      "  Window: 2006-10-31 to 2021-09-30\n",
      "  Yearly: 123 | Analyst: 150 | Union/Intersection: 33 | Assets w/ data: 21\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01338 | Turnover: 2.0978 | TC: 0.002070 | Net: -0.01545\n",
      "  MV   - Gross: -0.01429 | Turnover: 2.1084 | TC: 0.002078 | Net: -0.01637\n",
      "  MSR  - Gross:  0.00268 | Turnover: 2.4327 | TC: 0.002439 | Net:  0.00024\n",
      "\n",
      "[83/112] Date: 2021-11-30 | Year: 2021\n",
      "  Window: 2006-11-30 to 2021-10-31\n",
      "  Yearly: 123 | Analyst: 109 | Union/Intersection: 24 | Assets w/ data: 18\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.06113 | Turnover: 1.4096 | TC: 0.001496 | Net:  0.05963\n",
      "  MV   - Gross:  0.07243 | Turnover: 1.8025 | TC: 0.001933 | Net:  0.07050\n",
      "  MSR  - Gross:  0.07913 | Turnover: 2.2565 | TC: 0.002435 | Net:  0.07670\n",
      "\n",
      "[84/112] Date: 2021-12-31 | Year: 2021\n",
      "  Window: 2006-12-31 to 2021-11-30\n",
      "  Yearly: 123 | Analyst: 66 | Union/Intersection: 12 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01119 | Turnover: 2.0369 | TC: 0.002014 | Net: -0.01320\n",
      "  MV   - Gross:  0.01928 | Turnover: 2.2205 | TC: 0.002263 | Net:  0.01702\n",
      "  MSR  - Gross: -0.04295 | Turnover: 2.5119 | TC: 0.002404 | Net: -0.04536\n",
      "\n",
      "[85/112] Date: 2022-01-31 | Year: 2022\n",
      "  Window: 2007-01-31 to 2021-12-31\n",
      "  Yearly: 34 | Analyst: 117 | Union/Intersection: 9 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01231 | Turnover: 2.0000 | TC: 0.001975 | Net: -0.01428\n",
      "  MV   - Gross: -0.00678 | Turnover: 2.0630 | TC: 0.002049 | Net: -0.00883\n",
      "  MSR  - Gross: -0.03048 | Turnover: 2.0453 | TC: 0.001983 | Net: -0.03247\n",
      "\n",
      "[86/112] Date: 2022-02-28 | Year: 2022\n",
      "  Window: 2007-02-28 to 2022-01-31\n",
      "  Yearly: 34 | Analyst: 103 | Union/Intersection: 13 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.06231 | Turnover: 0.7822 | TC: 0.000831 | Net:  0.06148\n",
      "  MV   - Gross:  0.06419 | Turnover: 0.8458 | TC: 0.000900 | Net:  0.06329\n",
      "  MSR  - Gross:  0.03993 | Turnover: 0.6633 | TC: 0.000690 | Net:  0.03924\n",
      "\n",
      "[87/112] Date: 2022-03-31 | Year: 2022\n",
      "  Window: 2007-03-31 to 2022-02-28\n",
      "  Yearly: 34 | Analyst: 95 | Union/Intersection: 9 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.05834 | Turnover: 1.3944 | TC: 0.001313 | Net: -0.05966\n",
      "  MV   - Gross: -0.04759 | Turnover: 1.4599 | TC: 0.001390 | Net: -0.04898\n",
      "  MSR  - Gross: -0.07375 | Turnover: 1.4741 | TC: 0.001365 | Net: -0.07511\n",
      "\n",
      "[88/112] Date: 2022-04-30 | Year: 2022\n",
      "  Window: 2007-04-30 to 2022-03-31\n",
      "  Yearly: 34 | Analyst: 106 | Union/Intersection: 11 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.08998 | Turnover: 1.2509 | TC: 0.001363 | Net:  0.08862\n",
      "  MV   - Gross:  0.08314 | Turnover: 1.3201 | TC: 0.001430 | Net:  0.08171\n",
      "  MSR  - Gross:  0.07017 | Turnover: 0.9816 | TC: 0.001050 | Net:  0.06912\n",
      "\n",
      "[89/112] Date: 2022-05-31 | Year: 2022\n",
      "  Window: 2007-05-31 to 2022-04-30\n",
      "  Yearly: 34 | Analyst: 82 | Union/Intersection: 7 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02430 | Turnover: 0.8078 | TC: 0.000788 | Net: -0.02509\n",
      "  MV   - Gross: -0.02515 | Turnover: 0.8228 | TC: 0.000802 | Net: -0.02596\n",
      "  MSR  - Gross: -0.04761 | Turnover: 0.7585 | TC: 0.000722 | Net: -0.04833\n",
      "\n",
      "[90/112] Date: 2022-06-30 | Year: 2022\n",
      "  Window: 2007-06-30 to 2022-05-31\n",
      "  Yearly: 34 | Analyst: 98 | Union/Intersection: 7 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.09388 | Turnover: 2.0000 | TC: 0.002188 | Net:  0.09169\n",
      "  MV   - Gross:  0.09531 | Turnover: 2.0000 | TC: 0.002191 | Net:  0.09312\n",
      "  MSR  - Gross:  0.08924 | Turnover: 2.0000 | TC: 0.002178 | Net:  0.08706\n",
      "\n",
      "[91/112] Date: 2022-07-31 | Year: 2022\n",
      "  Window: 2007-07-31 to 2022-06-30\n",
      "  Yearly: 34 | Analyst: 104 | Union/Intersection: 10 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.03002 | Turnover: 1.3244 | TC: 0.001285 | Net: -0.03130\n",
      "  MV   - Gross: -0.04081 | Turnover: 1.1788 | TC: 0.001131 | Net: -0.04194\n",
      "  MSR  - Gross: -0.06977 | Turnover: 0.9135 | TC: 0.000850 | Net: -0.07062\n",
      "\n",
      "[92/112] Date: 2022-08-31 | Year: 2022\n",
      "  Window: 2007-08-31 to 2022-07-31\n",
      "  Yearly: 34 | Analyst: 82 | Union/Intersection: 5 | Assets w/ data: 3\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01809 | Turnover: 1.5559 | TC: 0.001528 | Net: -0.01962\n",
      "  MV   - Gross:  0.07907 | Turnover: 2.1959 | TC: 0.002369 | Net:  0.07670\n",
      "  MSR  - Gross: -0.03586 | Turnover: 1.4802 | TC: 0.001427 | Net: -0.03729\n",
      "\n",
      "[93/112] Date: 2022-09-30 | Year: 2022\n",
      "  Window: 2007-09-30 to 2022-08-31\n",
      "  Yearly: 34 | Analyst: 82 | Union/Intersection: 6 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07631 | Turnover: 1.3584 | TC: 0.001462 | Net:  0.07485\n",
      "  MV   - Gross:  0.12395 | Turnover: 2.7573 | TC: 0.003099 | Net:  0.12085\n",
      "  MSR  - Gross:  0.06710 | Turnover: 1.3404 | TC: 0.001430 | Net:  0.06567\n",
      "\n",
      "[94/112] Date: 2022-10-31 | Year: 2022\n",
      "  Window: 2007-10-31 to 2022-09-30\n",
      "  Yearly: 34 | Analyst: 96 | Union/Intersection: 6 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04668 | Turnover: 1.3790 | TC: 0.001443 | Net:  0.04524\n",
      "  MV   - Gross:  0.04520 | Turnover: 2.4923 | TC: 0.002605 | Net:  0.04259\n",
      "  MSR  - Gross:  0.02607 | Turnover: 0.8030 | TC: 0.000824 | Net:  0.02525\n",
      "\n",
      "[95/112] Date: 2022-11-30 | Year: 2022\n",
      "  Window: 2007-11-30 to 2022-10-31\n",
      "  Yearly: 34 | Analyst: 81 | Union/Intersection: 5 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.03839 | Turnover: 1.6866 | TC: 0.001622 | Net: -0.04001\n",
      "  MV   - Gross: -0.03592 | Turnover: 2.0336 | TC: 0.001961 | Net: -0.03788\n",
      "  MSR  - Gross: -0.03988 | Turnover: 1.3833 | TC: 0.001328 | Net: -0.04121\n",
      "\n",
      "[96/112] Date: 2022-12-31 | Year: 2022\n",
      "  Window: 2007-12-31 to 2022-11-30\n",
      "  Yearly: 34 | Analyst: 53 | Union/Intersection: 5 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04731 | Turnover: 1.7409 | TC: 0.001823 | Net:  0.04549\n",
      "  MV   - Gross:  0.05104 | Turnover: 1.8644 | TC: 0.001960 | Net:  0.04908\n",
      "  MSR  - Gross: -0.02812 | Turnover: 1.9798 | TC: 0.001924 | Net: -0.03004\n",
      "\n",
      "[97/112] Date: 2023-01-31 | Year: 2023\n",
      "  Window: 2008-01-31 to 2022-12-31\n",
      "  Yearly: 137 | Analyst: 102 | Union/Intersection: 23 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02951 | Turnover: 2.0644 | TC: 0.002003 | Net: -0.03151\n",
      "  MV   - Gross: -0.02603 | Turnover: 2.0688 | TC: 0.002015 | Net: -0.02804\n",
      "  MSR  - Gross: -0.06531 | Turnover: 2.7049 | TC: 0.002528 | Net: -0.06784\n",
      "\n",
      "[98/112] Date: 2023-02-28 | Year: 2023\n",
      "  Window: 2008-02-29 to 2023-01-31\n",
      "  Yearly: 137 | Analyst: 107 | Union/Intersection: 21 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.11140 | Turnover: 1.9423 | TC: 0.001726 | Net: -0.11313\n",
      "  MV   - Gross: -0.11272 | Turnover: 1.9366 | TC: 0.001718 | Net: -0.11444\n",
      "  MSR  - Gross: -0.01766 | Turnover: 2.4418 | TC: 0.002399 | Net: -0.02006\n",
      "\n",
      "[99/112] Date: 2023-03-31 | Year: 2023\n",
      "  Window: 2008-03-31 to 2023-02-28\n",
      "  Yearly: 137 | Analyst: 73 | Union/Intersection: 18 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01082 | Turnover: 1.9369 | TC: 0.001958 | Net:  0.00887\n",
      "  MV   - Gross:  0.01105 | Turnover: 1.9273 | TC: 0.001949 | Net:  0.00910\n",
      "  MSR  - Gross:  0.01792 | Turnover: 1.7501 | TC: 0.001781 | Net:  0.01613\n",
      "\n",
      "[100/112] Date: 2023-04-30 | Year: 2023\n",
      "  Window: 2008-04-30 to 2023-03-31\n",
      "  Yearly: 137 | Analyst: 93 | Union/Intersection: 22 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.07951 | Turnover: 2.0509 | TC: 0.001888 | Net: -0.08140\n",
      "  MV   - Gross: -0.04604 | Turnover: 2.0581 | TC: 0.001963 | Net: -0.04801\n",
      "  MSR  - Gross: -0.11527 | Turnover: 2.1986 | TC: 0.001945 | Net: -0.11722\n",
      "\n",
      "[101/112] Date: 2023-05-31 | Year: 2023\n",
      "  Window: 2008-05-31 to 2023-04-30\n",
      "  Yearly: 137 | Analyst: 73 | Union/Intersection: 16 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.08163 | Turnover: 2.1611 | TC: 0.002338 | Net:  0.07929\n",
      "  MV   - Gross:  0.08036 | Turnover: 2.1308 | TC: 0.002302 | Net:  0.07806\n",
      "  MSR  - Gross:  0.11003 | Turnover: 2.3877 | TC: 0.002650 | Net:  0.10738\n",
      "\n",
      "[102/112] Date: 2023-06-30 | Year: 2023\n",
      "  Window: 2008-06-30 to 2023-05-31\n",
      "  Yearly: 137 | Analyst: 70 | Union/Intersection: 17 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02190 | Turnover: 1.9145 | TC: 0.001956 | Net:  0.01994\n",
      "  MV   - Gross:  0.02183 | Turnover: 1.9358 | TC: 0.001978 | Net:  0.01985\n",
      "  MSR  - Gross:  0.02200 | Turnover: 1.9326 | TC: 0.001975 | Net:  0.02002\n",
      "\n",
      "[103/112] Date: 2023-07-31 | Year: 2023\n",
      "  Window: 2008-07-31 to 2023-06-30\n",
      "  Yearly: 137 | Analyst: 87 | Union/Intersection: 28 | Assets w/ data: 14\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.04091 | Turnover: 0.9390 | TC: 0.000901 | Net: -0.04181\n",
      "  MV   - Gross: -0.05024 | Turnover: 0.9958 | TC: 0.000946 | Net: -0.05119\n",
      "  MSR  - Gross: -0.02256 | Turnover: 1.0697 | TC: 0.001046 | Net: -0.02361\n",
      "\n",
      "[104/112] Date: 2023-08-31 | Year: 2023\n",
      "  Window: 2008-08-31 to 2023-07-31\n",
      "  Yearly: 137 | Analyst: 97 | Union/Intersection: 27 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.05095 | Turnover: 0.7160 | TC: 0.000680 | Net: -0.05163\n",
      "  MV   - Gross: -0.04474 | Turnover: 0.7141 | TC: 0.000682 | Net: -0.04542\n",
      "  MSR  - Gross: -0.06431 | Turnover: 0.9971 | TC: 0.000933 | Net: -0.06525\n",
      "\n",
      "[105/112] Date: 2023-09-30 | Year: 2023\n",
      "  Window: 2008-09-30 to 2023-08-31\n",
      "  Yearly: 137 | Analyst: 86 | Union/Intersection: 25 | Assets w/ data: 12\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00628 | Turnover: 1.8852 | TC: 0.001897 | Net:  0.00438\n",
      "  MV   - Gross:  0.01116 | Turnover: 2.0242 | TC: 0.002047 | Net:  0.00912\n",
      "  MSR  - Gross: -0.01208 | Turnover: 1.7177 | TC: 0.001697 | Net: -0.01377\n",
      "\n",
      "[106/112] Date: 2023-10-31 | Year: 2023\n",
      "  Window: 2008-10-31 to 2023-09-30\n",
      "  Yearly: 137 | Analyst: 118 | Union/Intersection: 34 | Assets w/ data: 19\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.06953 | Turnover: 1.7385 | TC: 0.001859 | Net:  0.06767\n",
      "  MV   - Gross:  0.06801 | Turnover: 1.8140 | TC: 0.001937 | Net:  0.06607\n",
      "  MSR  - Gross:  0.07245 | Turnover: 1.8070 | TC: 0.001938 | Net:  0.07051\n",
      "\n",
      "[107/112] Date: 2023-11-30 | Year: 2023\n",
      "  Window: 2008-11-30 to 2023-10-31\n",
      "  Yearly: 137 | Analyst: 92 | Union/Intersection: 23 | Assets w/ data: 10\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02549 | Turnover: 1.5915 | TC: 0.001632 | Net:  0.02386\n",
      "  MV   - Gross:  0.02090 | Turnover: 1.7131 | TC: 0.001749 | Net:  0.01915\n",
      "  MSR  - Gross:  0.03222 | Turnover: 1.6488 | TC: 0.001702 | Net:  0.03052\n",
      "\n",
      "[108/112] Date: 2023-12-31 | Year: 2023\n",
      "  Window: 2008-12-31 to 2023-11-30\n",
      "  Yearly: 137 | Analyst: 90 | Union/Intersection: 25 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02292 | Turnover: 2.0466 | TC: 0.002094 | Net:  0.02082\n",
      "  MV   - Gross: -0.00517 | Turnover: 2.2026 | TC: 0.002191 | Net: -0.00737\n",
      "  MSR  - Gross:  0.04714 | Turnover: 2.2047 | TC: 0.002309 | Net:  0.04483\n",
      "\n",
      "[109/112] Date: 2024-01-31 | Year: 2024\n",
      "  Window: 2009-01-31 to 2023-12-31\n",
      "  Yearly: 281 | Analyst: 110 | Union/Intersection: 50 | Assets w/ data: 34\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00311 | Turnover: 2.0807 | TC: 0.002087 | Net:  0.00103\n",
      "  MV   - Gross: -0.00353 | Turnover: 2.3800 | TC: 0.002372 | Net: -0.00590\n",
      "  MSR  - Gross:  0.04043 | Turnover: 2.8388 | TC: 0.002954 | Net:  0.03748\n",
      "\n",
      "[110/112] Date: 2024-02-29 | Year: 2024\n",
      "  Window: 2009-02-28 to 2024-01-31\n",
      "  Yearly: 281 | Analyst: 119 | Union/Intersection: 54 | Assets w/ data: 31\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04217 | Turnover: 1.5157 | TC: 0.001580 | Net:  0.04059\n",
      "  MV   - Gross:  0.04201 | Turnover: 1.4847 | TC: 0.001547 | Net:  0.04046\n",
      "  MSR  - Gross:  0.04314 | Turnover: 2.3262 | TC: 0.002427 | Net:  0.04071\n",
      "\n",
      "[111/112] Date: 2024-03-31 | Year: 2024\n",
      "  Window: 2009-03-31 to 2024-02-29\n",
      "  Yearly: 281 | Analyst: 73 | Union/Intersection: 39 | Assets w/ data: 31\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.03251 | Turnover: 1.2429 | TC: 0.001202 | Net: -0.03372\n",
      "  MV   - Gross: -0.03079 | Turnover: 1.2810 | TC: 0.001242 | Net: -0.03203\n",
      "  MSR  - Gross: -0.03675 | Turnover: 1.7161 | TC: 0.001653 | Net: -0.03840\n",
      "\n",
      "[112/112] Date: 2024-04-30 | Year: 2024\n",
      "  Window: 2009-04-30 to 2024-03-31\n",
      "  Yearly: 281 | Analyst: 99 | Union/Intersection: 49 | Assets w/ data: 26\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04544 | Turnover: 2.0542 | TC: 0.002148 | Net:  0.04330\n",
      "  MV   - Gross:  0.04036 | Turnover: 2.2312 | TC: 0.002321 | Net:  0.03804\n",
      "  MSR  - Gross:  0.05435 | Turnover: 2.4133 | TC: 0.002544 | Net:  0.05181\n",
      "\n",
      "============================================================\n",
      "BACKTEST COMPLETE\n",
      "============================================================\n",
      "\n",
      " GMV\n",
      "\n",
      "Sharpe Ratio: 0.1171\n",
      "Annualized Sharpe Ratio: 0.4055\n",
      "Total Return: 0.6443\n",
      "Average Turnover: 1.6111\n",
      "\n",
      " MV\n",
      "\n",
      "Sharpe Ratio: 0.0635\n",
      "Annualized Sharpe Ratio: 0.2200\n",
      "Total Return: 0.2416\n",
      "Average Turnover: 2.0215\n",
      "\n",
      " MSR\n",
      "\n",
      "Sharpe Ratio: 0.0588\n",
      "Annualized Sharpe Ratio: 0.2036\n",
      "Total Return: 0.2073\n",
      "Average Turnover: 1.7684\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../green cleaned.csv', dtype={'ncusip': 'string'})\n",
    "df['ret_fwd_1'] = df.groupby('permno')['ret_excess'].shift(-1)\n",
    "\n",
    "data_f=pd.read_csv('F-F_Research_Data_Factors.csv',sep=',')\n",
    "data_f['Date']=pd.to_datetime(data_f['Date'], format=\"%Y%m\")\n",
    "data_f['Date']=data_f['Date']+pd.offsets.MonthEnd(0)\n",
    "data_f = data_f.set_index('Date')\n",
    "data_f = data_f[['Mkt-RF', 'SMB', 'HML', 'RF']].astype(float)\n",
    "\n",
    "# Run backtest with yearly signals\n",
    "results_df, metrics, results_df_2, metrics_2, results_df_3, metrics_3= backtest_dnn_yearly(\n",
    "    df,\n",
    "    test_start_date='2015-01-31',\n",
    "    test_end_date='2024-04-30',\n",
    "    lookback_window=180,\n",
    "    transaction_cost=0.001,\n",
    "    buys_path_template='buys_{}.csv',\n",
    "    sells_path_template='sells_{}.csv',\n",
    "    analyst_rec_path='../examples/monthly_mean_recommendations_decay.csv',\n",
    "    data_factor=data_f,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n GMV\")\n",
    "print(f\"\\nSharpe Ratio: {metrics['sharpe_ratio']:.4f}\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Total Return: {metrics['total_return']:.4f}\")\n",
    "print(f\"Average Turnover: {metrics['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MV\")\n",
    "print(f\"\\nSharpe Ratio: {metrics_2['sharpe_ratio']:.4f}\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics_2['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Total Return: {metrics_2['total_return']:.4f}\")\n",
    "print(f\"Average Turnover: {metrics_2['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MSR\")\n",
    "print(f\"\\nSharpe Ratio: {metrics_3['sharpe_ratio']:.4f}\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics_3['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Total Return: {metrics_3['total_return']:.4f}\")\n",
    "print(f\"Average Turnover: {metrics_3['avg_turnover']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df58028-b81e-4987-92a9-52cb828f89f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GMV\n",
      "Annualized Sharpe Ratio: 0.4055\n",
      "Mean Return: 0.0674\n",
      "Variance: 0.0276\n",
      "Avg Turnover: 1.6111\n",
      "\n",
      " MV\n",
      "Annualized Sharpe Ratio: 0.2200\n",
      "Mean Return: 0.0413\n",
      "Variance: 0.0352\n",
      "Avg Turnover: 2.0215\n",
      "\n",
      " MSR\n",
      "Annualized Sharpe Ratio: 0.2036\n",
      "Mean Return: 0.0362\n",
      "Variance: 0.0316\n",
      "Avg Turnover: 1.7684\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n GMV\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {metrics['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {metrics['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {metrics['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MV\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics_2['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {metrics_2['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {metrics_2['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {metrics_2['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MSR\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics_3['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {metrics_3['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {metrics_3['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {metrics_3['avg_turnover']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d5e5c8-e09e-4e7f-b06c-2500ef309e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386d4f8-7bff-4a12-bc41-bd8853692468",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
