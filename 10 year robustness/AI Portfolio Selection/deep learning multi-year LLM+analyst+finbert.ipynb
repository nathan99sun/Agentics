{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84482766-9f65-4cb5-9309-e8bd125501f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 14:01:10.584035: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Lasso\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from multiprocessing import get_context\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "from scipy.optimize import brentq\n",
    "\n",
    "from DNNFM_functions import *\n",
    "from comp_m_functions import static_factor_obs, cov_e_poet\n",
    "\n",
    "def round(x):\n",
    "    return int(Decimal(x).to_integral_value(rounding=ROUND_HALF_UP))\n",
    "\n",
    "#---------------- Main ----------------\n",
    "\n",
    "def DNN_FM_main(data, data_factor, architecture=1, const_err_cov=2.5, use_CV_err=False, eval_type='frob'):\n",
    "\n",
    "    data_dm = data\n",
    "    data_factor_dm = data_factor\n",
    "    \n",
    "    # Obtain optimal tuning parameter based on cross-validation or pre-specified values\n",
    "    opt = opt_hyper_parameters(data=data, data_F=data_factor, architecture=architecture, const_err_cov=const_err_cov, \n",
    "                               use_CV_err=use_CV_err, eval_type=eval_type)\n",
    "    # Compute DNN-FM based on optimal hyper-parameters\n",
    "    res_DNN_FM = DNN_FM_core(data=data_dm, data_factor=data_factor_dm, architecture=architecture, opt=opt)\n",
    "\n",
    "    # c_err_min = DNN_FM_cov_e_cmin(data=data_dm, data_factor=data_factor_dm, DNN_model=res_DNN_FM['neural_net'])\n",
    "\n",
    "    print(opt['const_err_cov'])\n",
    "    res_DNN_FM_cov = DNN_FM_cov(data=data_dm, data_factor=data_factor_dm, DNN_model=res_DNN_FM['neural_net'], \n",
    "                                c_err_cov=opt['const_err_cov'], check_eig=False)\n",
    "    \n",
    "    res_DNN_FM.update(res_DNN_FM_cov)\n",
    "\n",
    "    return res_DNN_FM\n",
    "\n",
    "\n",
    "#---------------- Functions ----------------\n",
    "\n",
    "# Core function for creating Neural Network\n",
    "\n",
    "def DNN_FM_core(data, data_factor, architecture, opt):\n",
    "\n",
    "    num_n, num_s = data.shape\n",
    "    num_f = data_factor.shape[1]\n",
    "\n",
    "    # Create neural network specifications\n",
    "\n",
    "    if architecture == 1:\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 1\n",
    "        d_rate = 0.2\n",
    "\n",
    "        if inter_layer:\n",
    "            c_temp = 2\n",
    "        else:\n",
    "            c_temp = 1\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+c_temp)\n",
    "        activation_functions = [np.nan] * (n_layers+c_temp)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            hidden_layer_s[mm] = 512\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        if inter_layer:\n",
    "            dropout_rates_tr[len(dropout_rates_tr)-1] = d_rate\n",
    "            activation_functions[len(activation_functions)-2] = 'relu'\n",
    "            activation_functions[len(activation_functions)-1] = 'relu'\n",
    "        else:\n",
    "            activation_functions[len(activation_functions)-1] = None\n",
    "\n",
    "    elif architecture == 2:\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.1\n",
    "\n",
    "        if inter_layer:\n",
    "            c_temp = 2\n",
    "        else:\n",
    "            c_temp = 1\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+c_temp)\n",
    "        activation_functions = [np.nan] * (n_layers+c_temp)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            hidden_layer_s[mm] = 256\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        if inter_layer:\n",
    "            dropout_rates_tr[len(dropout_rates_tr)-1] = d_rate\n",
    "            activation_functions[len(activation_functions)-2] = 'relu'\n",
    "            activation_functions[len(activation_functions)-1] = 'relu'\n",
    "        else:\n",
    "            activation_functions[len(activation_functions)-1] = None\n",
    "        \n",
    "    elif architecture == 3:\n",
    "        \n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 1\n",
    "        d_rate = 0.0\n",
    "\n",
    "        if inter_layer:\n",
    "            c_temp = 2\n",
    "        else:\n",
    "            c_temp = 1\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+c_temp)\n",
    "        activation_functions = [np.nan] * (n_layers+c_temp)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            hidden_layer_s[mm] = 512\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        if inter_layer:\n",
    "            dropout_rates_tr[len(dropout_rates_tr)-1] = d_rate\n",
    "            activation_functions[len(activation_functions)-2] = 'relu'\n",
    "            activation_functions[len(activation_functions)-1] = 'relu'\n",
    "        else:\n",
    "            activation_functions[len(activation_functions)-1] = None\n",
    "    \n",
    "    elif architecture == 4:\n",
    "\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.0\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+1)\n",
    "        activation_functions = [np.nan] * (n_layers+1)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            if mm == 0:\n",
    "                hidden_layer_s[mm] = 256\n",
    "            elif mm == 1:\n",
    "                hidden_layer_s[mm] = 128\n",
    "            elif mm == 2:\n",
    "                hidden_layer_s[mm] = 64\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        activation_functions[len(activation_functions)-1] = None\n",
    "    \n",
    "    elif architecture == 5:\n",
    "\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.2\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+1)\n",
    "        activation_functions = [np.nan] * (n_layers+1)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            if mm == 0:\n",
    "                hidden_layer_s[mm] = 256\n",
    "            elif mm == 1:\n",
    "                hidden_layer_s[mm] = 128\n",
    "            elif mm == 2:\n",
    "                hidden_layer_s[mm] = 64\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        activation_functions[len(activation_functions)-1] = None\n",
    "\n",
    "\n",
    "    elif architecture == 6:\n",
    "\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.0\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+1)\n",
    "        activation_functions = [np.nan] * (n_layers+1)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            if mm == 0:\n",
    "                hidden_layer_s[mm] = 32\n",
    "            elif mm == 1:\n",
    "                hidden_layer_s[mm] = 16\n",
    "            elif mm == 2:\n",
    "                hidden_layer_s[mm] = 8\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        activation_functions[len(activation_functions)-1] = None\n",
    "\n",
    "    elif architecture == 7:\n",
    "\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.2\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+1)\n",
    "        activation_functions = [np.nan] * (n_layers+1)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            if mm == 0:\n",
    "                hidden_layer_s[mm] = 32\n",
    "            elif mm == 1:\n",
    "                hidden_layer_s[mm] = 16\n",
    "            elif mm == 2:\n",
    "                hidden_layer_s[mm] = 8\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        activation_functions[len(activation_functions)-1] = None\n",
    "\n",
    "    elif architecture == 8:\n",
    "\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.2\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+1)\n",
    "        activation_functions = [np.nan] * (n_layers+1)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            if mm == 0:\n",
    "                hidden_layer_s[mm] = 32\n",
    "            elif mm == 1:\n",
    "                hidden_layer_s[mm] = 16\n",
    "            elif mm == 2:\n",
    "                hidden_layer_s[mm] = 8\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        activation_functions[len(activation_functions)-1] = None\n",
    "\n",
    "    elif architecture == 9:\n",
    "\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.2\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+1)\n",
    "        activation_functions = [np.nan] * (n_layers+1)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            if mm == 0:\n",
    "                hidden_layer_s[mm] = 32\n",
    "            elif mm == 1:\n",
    "                hidden_layer_s[mm] = 16\n",
    "            elif mm == 2:\n",
    "                hidden_layer_s[mm] = 8\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        activation_functions[len(activation_functions)-1] = None\n",
    "\n",
    "    elif architecture == 10:\n",
    "\n",
    "        inter_layer = False\n",
    "\n",
    "        n_layers = 3\n",
    "        d_rate = 0.2\n",
    "\n",
    "        hidden_layer_s = [np.nan] * n_layers\n",
    "        dropout_rates_tr = [np.nan] * (n_layers+1)\n",
    "        activation_functions = [np.nan] * (n_layers+1)\n",
    "        dropout_rates_tr[0] = d_rate\n",
    "        for mm in range(0, n_layers):\n",
    "            if mm == 0:\n",
    "                hidden_layer_s[mm] = 256\n",
    "            elif mm == 1:\n",
    "                hidden_layer_s[mm] = 128\n",
    "            elif mm == 2:\n",
    "                hidden_layer_s[mm] = 64\n",
    "            dropout_rates_tr[mm+1] = d_rate\n",
    "            activation_functions[mm] = 'relu'\n",
    "        \n",
    "        activation_functions[len(activation_functions)-1] = None\n",
    "\n",
    "\n",
    "    # Optimization options\n",
    "    optimizer = 'Adam'\n",
    "    max_iter = 2000                 # maximum number of iterations\n",
    "    max_iter_nc = 50                # maximum number of iterations early stopping\n",
    "    \n",
    "    split_ratio = 0.3               # split ratio for training and validation set\n",
    "    batch_s = 256                   # batch size\n",
    "    use_bias = False                # include bias in neural net, if true\n",
    "\n",
    "    # Define early stopping criterion\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss', patience=max_iter_nc, mode='min')\n",
    "\n",
    "    learning_rate = opt['learning_rate']\n",
    "    reg_par_w = opt['reg_par_w']          # regularization parameter for weights\n",
    "    reg_par_b = opt['reg_par_b']          # regularization parameter for bias\n",
    "    el_r_pro = opt['el_r_pro']            # split between elastic net and lasso: 1 - only l1 norm\n",
    "\n",
    "    \"\"\"\n",
    "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "    learning_rate,\n",
    "    decay_steps=1,\n",
    "    decay_rate=1,\n",
    "    staircase=False)\n",
    "    \"\"\"\n",
    "\n",
    "    # Create sparse neural network and compile it\n",
    "    neural_net = sparse_nn(hidden_layer_s, activation_functions, dropout_rates_tr, num_s, num_f,\n",
    "                reg_par_w, reg_par_b, el_r_pro, max_iter_nc, max_iter, optimizer, learning_rate, use_bias, inter_layer)\n",
    "\n",
    "    neural_net.build_neural_network()\n",
    "    # Compile and fit model\n",
    "    neural_net.compile_nn()\n",
    "\n",
    "    fit_nn = neural_net.model.fit(data_factor, data, epochs=max_iter,\n",
    "                        validation_split=split_ratio, shuffle=True, batch_size=batch_s,\n",
    "                        callbacks=early_stopping, verbose=0)\n",
    "    \n",
    "    # Compute market sensitivity\n",
    "    with tf.GradientTape() as tape:\n",
    "        data_factor_ts = tf.convert_to_tensor(data_factor[-1,:].reshape(1,-1), dtype=tf.float32)\n",
    "        tape.watch(data_factor_ts)\n",
    "        y_pred = neural_net.model(data_factor_ts)\n",
    "\n",
    "    market_sens = tape.jacobian(y_pred, data_factor_ts)[-1,:,-1,:].numpy() \n",
    "\n",
    "    # Store for analysis\n",
    "    market_return_t = data_factor_ts.numpy()[-1, :].reshape(1,-1)\n",
    "    market_sensitivity = (market_sens, market_return_t)\n",
    "\n",
    "    res = {'neural_net': neural_net, 'opt': opt, 'market_sensitivity': market_sensitivity}\n",
    "    return res\n",
    "\n",
    "#-------------------------------------------\n",
    "\n",
    "def DNN_FM_cov(data, data_factor, DNN_model, c_err_cov, check_eig=False):\n",
    "\n",
    "    num_n, num_s = data.shape\n",
    "\n",
    "    y_hat_nn = DNN_model.model(data_factor).numpy()\n",
    "    resd_nn = data - y_hat_nn\n",
    "\n",
    "    sig_hat_e = thres_resd_new(resd_nn, c_err_cov, num_s, num_n)\n",
    "    cov_f_nnet = np.cov(y_hat_nn.T)\n",
    "\n",
    "    if not check_eig:\n",
    "                \n",
    "        sigma_y_nnet = cov_f_nnet + sig_hat_e\n",
    "    else:\n",
    "\n",
    "        cond = True\n",
    "        const_c = 0\n",
    "        while cond:\n",
    "\n",
    "            sig_hat_e = thres_resd_new(resd_nn, c_err_cov+const_c, num_s, num_n)\n",
    "\n",
    "            cond = (round(min(np.linalg.eig(sig_hat_e)[0]),2) < 0.01) or (np.linalg.cond(sig_hat_e) > num_s*10)\n",
    "            const_c+=0.01\n",
    "        \n",
    "        sigma_y_nnet = cov_f_nnet + sig_hat_e\n",
    "\n",
    "    inv_sigma_y_nnet = sig_inv_f_nnet(cov_f_nnet, sig_hat_e)\n",
    "\n",
    "    res = {'sigma_hat': sigma_y_nnet, 'sigma_f_hat': cov_f_nnet, 'sigma_e_hat': sig_hat_e, \n",
    "           'inv_sigma_hat': inv_sigma_y_nnet}\n",
    "\n",
    "    return res\n",
    "\n",
    "def DNN_FM_cov_e_cmin(data, data_factor, DNN_model):\n",
    "\n",
    "    num_n, num_s = data.shape\n",
    "\n",
    "    y_hat_nn = DNN_model.model(data_factor).numpy()\n",
    "    resd_nn = data - y_hat_nn\n",
    "\n",
    "    num_n, num_s = resd_nn.shape\n",
    "\n",
    "    f = lambda c: mineig_cov_e(resd=resd_nn, c_err_cov=c, num_s=num_s, num_n=num_n)\n",
    "\n",
    "    if (f(50) * f(-50) < 0):\n",
    "        r = brentq(f, -50, 50)\n",
    "        return max(0, r)\n",
    "    else:\n",
    "        c = 0\n",
    "        return c\n",
    "\n",
    "def mineig_cov_e(resd, c_err_cov, num_s, num_n):\n",
    "\n",
    "    return min(np.linalg.eig(thres_resd_new(resd, c_err_cov, num_s, num_n))[0])\n",
    "\n",
    "\n",
    "#-------------------------------------------\n",
    "\n",
    "# Function for determining optimal regularization and learning rate based on cross-validation or fixed\n",
    "def opt_hyper_parameters(data, data_F, architecture, const_err_cov, use_CV_err, eval_type):\n",
    "    \n",
    "    parallel = False\n",
    "\n",
    "    if architecture == 1 or architecture == 5 or architecture == 7:\n",
    "        reg_par_w = 0.0005           # regularization parameter for weights\n",
    "        reg_par_b = 0.0005           # regularization parameter for bias\n",
    "    elif architecture == 9 or architecture == 10:\n",
    "        reg_par_w = 0.005           # regularization parameter for weights\n",
    "        reg_par_b = 0.005           # regularization parameter for bias\n",
    "    else:\n",
    "        reg_par_w = 0.0             # regularization parameter for weights\n",
    "        reg_par_b = 0.0             # regularization parameter for bias\n",
    "    el_r_pro = 1                    # split between elastic net and lasso: 1 - only l1 norm\n",
    "    # Alternative specification for the learning rate\n",
    "    learning_rate = 0.0005\n",
    "\n",
    "    if use_CV_err:\n",
    "\n",
    "        range_cov_err = np.arange(0, const_err_cov+0.6, 0.1)\n",
    "\n",
    "        \"\"\"\n",
    "        opt = block_cv(data=data, data_F=data_F, architecture=architecture, \n",
    "                       reg_par=reg_par_w, lr=learning_rate, range_cov_err=range_cov_err, \n",
    "                       eval_type=eval_type, test_size=10, parallel=parallel)\n",
    "        \"\"\"\n",
    "        \n",
    "        opt = cv_split(data=data, data_F=data_F, architecture=architecture, \n",
    "                       reg_par=reg_par_w, lr=learning_rate, range_cov_err=range_cov_err, \n",
    "                       eval_type=eval_type)\n",
    "\n",
    "    else:\n",
    "\n",
    "        opt = {'learning_rate': learning_rate, 'reg_par_w': reg_par_w, \n",
    "            'reg_par_b': reg_par_b, 'el_r_pro': el_r_pro, 'const_err_cov': const_err_cov}\n",
    "    \n",
    "    return opt\n",
    "        \n",
    "#-------------------------------------------\n",
    "\n",
    "# Function that determines hyperparameters based on block cross-validation\n",
    "\n",
    "def block_cv(data, data_F, architecture, reg_par, lr, range_cov_err, eval_type, min_train_ratio=0.8, test_size=5, parallel=False):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    T, p = data.shape\n",
    "    train_size = int(np.floor(min_train_ratio * T)) # Get training size\n",
    "    numBlocks = int(np.floor((T - train_size) / test_size)) # Compute number of blocks\n",
    "    \n",
    "    # Show error message if test size is too large\n",
    "    assert numBlocks > 1, f\"Test size is too large\"\n",
    "\n",
    "    # Predefine dictionary for options\n",
    "    opt = {'learning_rate': lr, 'reg_par_w': reg_par, 'reg_par_b': reg_par, 'el_r_pro': 1}\n",
    "    \n",
    "    res_mat = np.empty((numBlocks,len(range_cov_err)))\n",
    "    res_mat[:] = np.nan\n",
    "\n",
    "    for bl in range(1, numBlocks+1):\n",
    "        idxTrainX = list(range((bl-1)*test_size,train_size+(bl-1)*test_size))\n",
    "\n",
    "        if bl == numBlocks:\n",
    "            idxTestX = list(range(train_size+(bl-1)*test_size,T))\n",
    "        else:\n",
    "            idxTestX = list(range(train_size+(bl-1)*test_size,train_size+bl*test_size))\n",
    "\n",
    "        \n",
    "        data_ntrain, data_mean, data_std = normalize_dat(data[idxTrainX,:])\n",
    "        data_F_ntrain, data_F_mean, data_F_std = normalize_dat(data_F[idxTrainX,:])    \n",
    "\n",
    "        test_res = np.empty((len(idxTestX),len(range_cov_err)))\n",
    "        test_res[:] = np.nan\n",
    "        \n",
    "        # if bl == 1:\n",
    "        res_DNN_FM = DNN_FM_core(data_ntrain, data_F_ntrain, architecture, opt)\n",
    "        neural_net = res_DNN_FM['neural_net']\n",
    "\n",
    "\n",
    "        for idx_t in range(1, len(idxTestX)+1):\n",
    "\n",
    "            ind_test_temp = idxTrainX[idx_t:]+idxTestX[:idx_t]\n",
    "\n",
    "            data_ntest, data_mean, data_std = normalize_dat(data[ind_test_temp,:])\n",
    "            data_F_ntest, data_F_mean, data_F_std = normalize_dat(data_F[ind_test_temp,:])\n",
    "\n",
    "            y_hat = neural_net.model(data_F_ntrain).numpy()\n",
    "            resd_nn = data_ntrain - y_hat\n",
    "\n",
    "            num_n, num_s = resd_nn.shape\n",
    "\n",
    "            sigma_test = cov_sfm(data_ntest - neural_net.model(data_F_ntest).numpy())\n",
    "\n",
    "            \"\"\"\n",
    "            # define the number of worker processes to use\n",
    "            num_processes = 2\n",
    "\n",
    "            combined_list = [(resd_nn, sigma_test, eval_type, const_err_item) for const_err_item in range_cov_err]\n",
    "\n",
    "            if parallel:\n",
    "                # create a pool of worker processes\n",
    "                with get_context(\"spawn\").Pool(processes=num_processes) as pool:\n",
    "                    ret = pool.imap(err_cv_core, combined_list)\n",
    "                    pool.close()\n",
    "                    pool.join()\n",
    "            else:\n",
    "                ret = map(err_cv_core, combined_list)\n",
    "\n",
    "            for indx, err_measure in enumerate(ret):\n",
    "                test_res[idx_t-1,indx] = err_measure\n",
    "            \"\"\"\n",
    "\n",
    "            # sigma_test = cov_sfm(data_ntest - neural_net.model(data_F_ntest).numpy())\n",
    "\n",
    "            rate_thres = np.sqrt((np.log(num_s))/num_n)\n",
    "            sig_e_samp = np.cov(resd_nn.T)\n",
    "            thet_par = np.empty((num_s, num_s))\n",
    "            thet_par[:] = np.nan\n",
    "\n",
    "            for ii in range(0, num_s):\n",
    "                for jj in range(0, num_s):\n",
    "                    thet_par[ii, jj] = np.mean(np.abs(resd_nn[:, ii] * resd_nn[:, jj] - sig_e_samp[ii, jj]))\n",
    "\n",
    "            sig_e_diag = np.diag(sig_e_samp)\n",
    "            \n",
    "            \"\"\"\n",
    "            sig_e_diag = np.diag(np.diag(sig_e_samp)**(0.5))\n",
    "            R = np.linalg.inv(sig_e_diag) @ sig_e_samp @ np.linalg.inv(sig_e_diag)\n",
    "            \"\"\"\n",
    "            \n",
    "            for c_idx in range(0,len(range_cov_err)):\n",
    "                lam = rate_thres * range_cov_err[c_idx] * thet_par\n",
    "                \n",
    "                \"\"\"\n",
    "                M = soft_t(R, lam)\n",
    "                M = M - np.diag(np.diag(M)) + np.eye(num_s)\n",
    "                sig_hat_e = sig_e_diag @ M @ sig_e_diag\n",
    "                \"\"\"\n",
    "                \n",
    "                sig_hat_e = soft_t(sig_e_samp, lam)\n",
    "                np.fill_diagonal(sig_hat_e, sig_e_diag)\n",
    "                \n",
    "                # sig_hat_e = thres_resd_new(resd_nn, range_cov_err[c_idx], num_s, num_n)\n",
    "\n",
    "                if min(np.linalg.eig(sig_hat_e)[0]) < 0:\n",
    "                    test_res[idx_t-1,c_idx] = np.inf\n",
    "                else:\n",
    "                    if eval_type == 'frob':\n",
    "                        test_res[idx_t-1,c_idx] = np.linalg.norm(sig_hat_e - sigma_test, ord='fro')**2\n",
    "                    elif eval_type == 'spec':\n",
    "                        test_res[idx_t-1,c_idx] = np.linalg.norm(sig_hat_e - sigma_test, ord=2)**2\n",
    "\n",
    "            \n",
    "        res_mat[bl-1,:] = np.mean(test_res, axis=0)\n",
    "\n",
    "\n",
    "     \n",
    "    idx_opt = np.where(res_mat.mean(axis=0) == np.nanmin(res_mat.mean(axis=0)))\n",
    "\n",
    "    opt.update({'const_err_cov': range_cov_err[idx_opt][0]})\n",
    "    end = time.time()\n",
    "\n",
    "    print(end - start)\n",
    "    return opt\n",
    "\n",
    "def err_cv_core(tuple_in):\n",
    "\n",
    "    resd_nn, sigma_test, eval_type, const_err_cov = tuple_in[0], tuple_in[1], tuple_in[2], tuple_in[3]\n",
    "\n",
    "    num_n, num_s = resd_nn.shape\n",
    "\n",
    "    st = time.time()\n",
    "    sig_hat_e = thres_resd_new(resd_nn, const_err_cov, num_s, num_n)\n",
    "    print(time.time()-st)\n",
    "\n",
    "    if min(np.linalg.eig(sig_hat_e)[0]) < 0:\n",
    "        test_res = np.inf\n",
    "    else:\n",
    "        if eval_type == 'frob':\n",
    "            test_res = np.linalg.norm(sig_hat_e - sigma_test, ord='fro')\n",
    "        elif eval_type == 'spec':\n",
    "            st1 = time.time()\n",
    "            test_res = np.linalg.norm(sig_hat_e - sigma_test, ord=2)\n",
    "            print(time.time()-st1)\n",
    "\n",
    "    return test_res\n",
    "\n",
    "def cv_split(data, data_F, architecture, reg_par, lr, range_cov_err, eval_type):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Predefine dictionary for options\n",
    "    opt = {'learning_rate': lr, 'reg_par_w': reg_par, 'reg_par_b': reg_par, 'el_r_pro': 1}\n",
    "\n",
    "    data_dm, _, _ = normalize_dat_sim(data)\n",
    "    data_F_dm, _, _ = normalize_dat_sim(data_F)    \n",
    "\n",
    "    res_DNN_FM = DNN_FM_core(data_dm, data_F_dm, architecture, opt)\n",
    "    neural_net = res_DNN_FM['neural_net']\n",
    "\n",
    "    y_hat = neural_net.model(data_F_dm).numpy()\n",
    "    resd_nn = data_dm - y_hat\n",
    "\n",
    "    n_folds = 10\n",
    "\n",
    "    res_mat = np.empty((n_folds,len(range_cov_err)))\n",
    "    res_mat[:] = np.nan\n",
    "\n",
    "    split_sample, _ = ts_train_test_split(resd_nn, n_folds, train_size=0.5)\n",
    "\n",
    "    for m_idx in range(0, n_folds):\n",
    "\n",
    "\n",
    "            resd_nn_s1 = split_sample[m_idx][0]\n",
    "            resd_nn_s2 = split_sample[m_idx][1]\n",
    "\n",
    "            num_n, num_s = resd_nn_s1.shape\n",
    "\n",
    "            sigma_test = cov_sfm(resd_nn_s2) # np.cov(resd_nn_s2.T) # \n",
    "\n",
    "            sig_e_samp, thet_par = thres_cov_resd_aux(resd_nn_s1, num_s)\n",
    "\n",
    "            for c_idx in range(0,len(range_cov_err)):\n",
    "                \n",
    "                sig_hat_e = thres_cov_resd(sig_e_samp, thet_par, range_cov_err[c_idx], num_s, num_n)\n",
    "\n",
    "                if min(np.linalg.eig(sig_hat_e)[0]) < 0:\n",
    "                    res_mat[m_idx,c_idx] = np.inf\n",
    "                else:\n",
    "                    if eval_type == 'frob':\n",
    "                        res_mat[m_idx,c_idx] = np.linalg.norm(sig_hat_e - sigma_test, ord='fro')**2\n",
    "                    elif eval_type == 'spec':\n",
    "                        res_mat[m_idx,c_idx] = np.linalg.norm(sig_hat_e - sigma_test, ord=2)**2\n",
    "\n",
    "    idx_opt = np.where(res_mat.mean(axis=0) == np.nanmin(res_mat.mean(axis=0)))\n",
    "\n",
    "    opt.update({'const_err_cov': range_cov_err[idx_opt][0]})\n",
    "    end = time.time()\n",
    "\n",
    "    print(end - start)\n",
    "\n",
    "    return opt\n",
    "\n",
    "def ts_train_test_split(X, n_folds = 5, train_size=0.5):\n",
    "\n",
    "    test_size = 1 - train_size\n",
    "    n_obs = X.shape[0]\n",
    "\n",
    "    size_split = n_obs - n_folds\n",
    "\n",
    "    n_train = round(size_split * train_size)\n",
    "    n_test = round(size_split * test_size)\n",
    "\n",
    "    split_t = (list(range(0, n_train)), list(range(n_train, n_train+n_test)))\n",
    "\n",
    "    split_sample = []\n",
    "    split_index = []\n",
    "\n",
    "    for jj in range(0, n_folds):\n",
    "        split_index.append(([el1 + jj for el1 in split_t[0]], [el2 + jj for el2 in split_t[1]]))\n",
    "        split_sample.append((X[split_index[jj][0],:], X[split_index[jj][1],:]))\n",
    "\n",
    "    return split_sample, split_index\n",
    "\n",
    "\n",
    "def gmv_weights(Theta_hat):\n",
    "    \"\"\"\n",
    "    Compute Global Minimum Variance (GMV) portfolio weights (Section 6.1).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # w* = (Θ 1_p) / (1_p' Θ 1_p)\n",
    "    numerator = Theta_hat @ ones_p\n",
    "    denominator = ones_p @ Theta_hat @ ones_p\n",
    "    \n",
    "    if np.abs(denominator) < 1e-10:\n",
    "        # Fallback to equal weights if precision matrix is near-singular\n",
    "        return ones_p / p\n",
    "    \n",
    "    w_star = numerator / denominator\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "def mv_weights(Theta_hat, mu, target_return=0.01):\n",
    "    \"\"\"\n",
    "    Compute Mean-Variance portfolio weights with target return.\n",
    "    \n",
    "    Solves the constrained optimization:\n",
    "    min w' Sigma w  subject to  w' mu = target_return  and  w' 1 = 1\n",
    "    \n",
    "    Solution uses Lagrange multipliers with two constraints.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix (Sigma^{-1})\n",
    "    mu : np.ndarray, shape (p,)\n",
    "        Expected returns\n",
    "    target_return : float\n",
    "        Target portfolio return (default: 0.01 = 1% monthly)\n",
    "    long_only : bool\n",
    "        If True, falls back to GMV if MV produces negative weights\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # Compute key quantities\n",
    "    A = ones_p @ Theta_hat @ ones_p  # 1' Theta 1\n",
    "    B = ones_p @ Theta_hat @ mu       # 1' Theta mu  \n",
    "    C = mu @ Theta_hat @ mu           # mu' Theta mu\n",
    "    D = A * C - B * B                  # Determinant\n",
    "    \n",
    "    # Check for singularity\n",
    "    if np.abs(D) < 1e-10:\n",
    "        print('SINGULARITY')\n",
    "        # System is singular, use GMV instead\n",
    "        if np.abs(A) > 1e-10:\n",
    "            w_star = (Theta_hat @ ones_p) / A\n",
    "            return w_star\n",
    "        else:\n",
    "            return ones_p / p\n",
    "    \n",
    "    \n",
    "    # Compute Lagrange multipliers\n",
    "    lambda1 = (C - B * target_return) / D\n",
    "    lambda2 = (A * target_return - B) / D\n",
    "    \n",
    "    # Compute weights: w = lambda1 * Theta^{-1} 1 + lambda2 * Theta^{-1} mu\n",
    "    w_star = lambda1 * (Theta_hat @ ones_p) + lambda2 * (Theta_hat @ mu)\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "def msr_weights(Theta_hat, mu):\n",
    "    \"\"\"\n",
    "    Compute Maximum Sharpe Ratio portfolio weights.\n",
    "    \n",
    "    The maximum Sharpe ratio portfolio solves:\n",
    "    max (w' mu) / sqrt(w' Sigma w)\n",
    "    \n",
    "    Solution (when mu represents excess returns):\n",
    "    w ∝ Sigma^{-1} mu = Theta mu\n",
    "    \n",
    "    Then normalize so that sum(w) = 1.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    Theta_hat : np.ndarray, shape (p, p)\n",
    "        Precision matrix (Sigma^{-1})\n",
    "    mu : np.ndarray, shape (p,)\n",
    "        Expected excess returns\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    w_star : np.ndarray, shape (p,)\n",
    "        Portfolio weights (sum to 1)\n",
    "    \"\"\"\n",
    "    p = Theta_hat.shape[0]\n",
    "    ones_p = np.ones(p)\n",
    "    \n",
    "    # Compute unnormalized weights: w ∝ Theta mu\n",
    "    w_unnorm = Theta_hat @ mu\n",
    "    \n",
    "    # Normalize to sum to 1\n",
    "    weight_sum = np.sum(w_unnorm)\n",
    "    \n",
    "    if np.abs(weight_sum) < 1e-10:\n",
    "        print('WARNING: Weight sum near zero, returning equal weights')\n",
    "        return ones_p / p\n",
    "    \n",
    "    w_star = w_unnorm / weight_sum\n",
    "    \n",
    "    return w_star\n",
    "\n",
    "\n",
    "def load_yearly_signals(year, buys_path_template='buys_{}.csv', sells_path_template='sells_{}.csv'):\n",
    "    \"\"\"\n",
    "    Load buy and sell signals for a specific year.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    year : int\n",
    "        Year to load signals for\n",
    "    buys_path_template : str\n",
    "        Template for buys file path (use {} for year placeholder)\n",
    "    sells_path_template : str\n",
    "        Template for sells file path (use {} for year placeholder)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    permno_set : set\n",
    "        Set of permnos in the buy and sell signals for this year\n",
    "    \"\"\"\n",
    "    try:\n",
    "        buys = pd.read_csv(buys_path_template.format(year), index_col=1)\n",
    "        sells = pd.read_csv(sells_path_template.format(year), index_col=1)\n",
    "        \n",
    "        buys.index.name = 'permno'\n",
    "        sells.index.name = 'permno'\n",
    "        \n",
    "        buys_index = buys.index.astype(int)\n",
    "        sells_index = sells.index.astype(int)\n",
    "        \n",
    "        return set(buys_index.union(sells_index))\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  ⚠ Warning: Could not load signals for year {year}: {e}\")\n",
    "        return set()\n",
    "\n",
    "def load_finbert_signals(signals_path):\n",
    "    \"\"\"\n",
    "    Load FinBERT monthly signals from CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signals_path : str\n",
    "        Path to monthly_signals.csv file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    signals_df : pd.DataFrame\n",
    "        DataFrame with columns: symbol, company, year_month, signal, avg_sentiment_score\n",
    "    \"\"\"\n",
    "    try:\n",
    "        signals_df = pd.read_csv(signals_path)\n",
    "        # Convert year_month to datetime (end of month)\n",
    "        signals_df['date'] = pd.to_datetime(signals_df['year_month']) + pd.offsets.MonthEnd(0)\n",
    "        return signals_df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  ⚠ Warning: Could not load FinBERT signals: {e}\")\n",
    "        return pd.DataFrame(columns=['symbol', 'company', 'year_month', 'signal', 'date'])\n",
    "\n",
    "def get_finbert_permnos_for_date(signals_df, ticker_to_permno, date):\n",
    "    \"\"\"\n",
    "    Get set of permnos with 'buy' or 'sell' signals for a specific date.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    signals_df : pd.DataFrame\n",
    "        FinBERT signals dataframe\n",
    "    ticker_to_permno : dict\n",
    "        Mapping from ticker symbol to permno\n",
    "    date : pd.Timestamp\n",
    "        Date to get signals for\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    permno_set : set\n",
    "        Set of permnos with buy or sell signals on this date\n",
    "    \"\"\"\n",
    "    # Get signals for this date\n",
    "    date_signals = signals_df[signals_df['date'] == date]\n",
    "    \n",
    "    # Filter for buy and sell signals (exclude hold)\n",
    "    buy_signals = date_signals[date_signals['signal'] == 'buy']\n",
    "    sell_signals = date_signals[date_signals['signal'] == 'sell']\n",
    "    \n",
    "    # Convert tickers to permnos\n",
    "    permnos = set()\n",
    "    for ticker in buy_signals['symbol'].values:\n",
    "        if ticker in ticker_to_permno:\n",
    "            permnos.add(ticker_to_permno[ticker])\n",
    "    for ticker in sell_signals['symbol'].values:\n",
    "        if ticker in ticker_to_permno:\n",
    "            permnos.add(ticker_to_permno[ticker])\n",
    "    \n",
    "    return permnos\n",
    "\n",
    "\n",
    "def create_ticker_to_permno_mapping(df):\n",
    "    \"\"\"\n",
    "    Create a mapping from ticker to permno from the returns dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Returns dataframe with 'ticker' and 'permno' columns\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    ticker_to_permno : dict\n",
    "        Mapping from ticker to permno (uses most recent permno for each ticker)\n",
    "    \"\"\"\n",
    "    if 'ticker' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have 'ticker' column for mapping\")\n",
    "    \n",
    "    # Drop NaN tickers\n",
    "    valid_df = df[df['ticker'].notna()].copy()\n",
    "    \n",
    "    # Get the most recent permno for each ticker\n",
    "    ticker_to_permno = valid_df.groupby('ticker')['permno'].last().to_dict()\n",
    "    \n",
    "    return ticker_to_permno\n",
    "\n",
    "def load_analyst_recommendations(rec_changes_path):\n",
    "    \"\"\"\n",
    "    Load significant recommendation changes from CSV file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rec_changes_path : str\n",
    "        Path to significant_recommendation_changes.csv file\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    rec_changes_df : pd.DataFrame\n",
    "        DataFrame with columns: permno, date, ticker, mean_recommendation, \n",
    "        recommendation_change, num_recommendations\n",
    "    \"\"\"\n",
    "    try:\n",
    "        rec_changes_df = pd.read_csv(rec_changes_path)\n",
    "        rec_changes_df['date'] = pd.to_datetime(rec_changes_df['date'])\n",
    "        rec_changes_df['permno'] = rec_changes_df['permno'].astype(int)\n",
    "        return rec_changes_df\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"  ⚠ Warning: Could not load recommendation changes: {e}\")\n",
    "        return pd.DataFrame(columns=['permno', 'date', 'ticker', 'mean_recommendation', \n",
    "                                    'recommendation_change', 'num_recommendations'])\n",
    "\n",
    "\n",
    "def get_signal_permnos_for_date(rec_changes_df, date, buy_threshold=-0.5, sell_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Get sets of permnos with buy/sell signals based on recommendation changes.\n",
    "    \n",
    "    Note: Negative change = upgrade (moving toward Strong Buy) = BUY signal\n",
    "          Positive change = downgrade (moving toward Sell) = SELL signal\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rec_changes_df : pd.DataFrame\n",
    "        Recommendation changes dataframe\n",
    "    date : pd.Timestamp\n",
    "        Date to get signals for\n",
    "    buy_threshold : float\n",
    "        Threshold for buy signals (default: -0.5)\n",
    "    sell_threshold : float\n",
    "        Threshold for sell signals (default: 0.5)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    buy_permnos : set\n",
    "        Set of permnos with buy signals\n",
    "    sell_permnos : set\n",
    "        Set of permnos with sell signals\n",
    "    \"\"\"\n",
    "    date_changes = rec_changes_df[rec_changes_df['date'] == date]\n",
    "    \n",
    "    # Buy signals: negative changes (recommendations getting better)\n",
    "    buys = date_changes[date_changes['recommendation_change'] <= buy_threshold]\n",
    "    buy_permnos = set(buys['permno'].values)\n",
    "    \n",
    "    # Sell signals: positive changes (recommendations getting worse)\n",
    "    sells = date_changes[date_changes['recommendation_change'] >= sell_threshold]\n",
    "    sell_permnos = set(sells['permno'].values)\n",
    "    \n",
    "    return buy_permnos | sell_permnos\n",
    "\n",
    "\n",
    "def calculate_exit_transaction_cost(prev_weights_dict, prev_oos_returns_dict, \n",
    "                                    prev_gross_return, transaction_cost, verbose=False):\n",
    "    \"\"\"Calculate transaction cost when exiting the market (liquidating all positions).\"\"\"\n",
    "    if len(prev_weights_dict) == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "    \n",
    "    adjusted_prev = {}\n",
    "    for asset, prev_w in prev_weights_dict.items():\n",
    "        if asset in prev_oos_returns_dict:\n",
    "            prev_r = prev_oos_returns_dict[asset]\n",
    "            if abs(1 + prev_gross_return) > 1e-6:\n",
    "                adjusted_prev[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return)\n",
    "            else:\n",
    "                adjusted_prev[asset] = 0.0\n",
    "        else:\n",
    "            if abs(1 + prev_gross_return) > 1e-6:\n",
    "                adjusted_prev[asset] = prev_w / (1 + prev_gross_return)\n",
    "            else:\n",
    "                adjusted_prev[asset] = 0.0\n",
    "    \n",
    "    turnover = sum(abs(w) for w in adjusted_prev.values())\n",
    "    tc = transaction_cost * 1.0 * turnover\n",
    "    net_return = -tc\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  Liquidating positions | Turnover: {turnover:>6.4f} | TC: {tc:>8.6f}\")\n",
    "    \n",
    "    return turnover, tc, net_return\n",
    "\n",
    "\n",
    "\n",
    "def backtest_dnn_yearly(df, \n",
    "                          test_start_date='2020-01-31', \n",
    "                          test_end_date='2024-11-30',\n",
    "                          lookback_window=180,\n",
    "                          transaction_cost=0.001,\n",
    "                          buys_path_template='buys_{}.csv',\n",
    "                          sells_path_template='sells_{}.csv',\n",
    "                          analyst_rec_path=None,\n",
    "                          finbert_signals_path=None,\n",
    "                          data_factor=None,\n",
    "                          verbose=True):\n",
    "    \"\"\"\n",
    "    Backtest DNN-FM with FinBERT + LLM signals using GMV/MV/MSR strategies.\n",
    "    \n",
    "    KEY CHANGES:\n",
    "    1. Added finbert_signals_path parameter\n",
    "    2. Added ticker to permno mapping creation\n",
    "    3. Added FinBERT signal loading and processing\n",
    "    4. Combined yearly and FinBERT signals using union/intersection logic\n",
    "    5. Added calculate_exit_transaction_cost for proper liquidation handling\n",
    "    \"\"\"\n",
    "    \n",
    "    # [Keep all existing setup code]\n",
    "    df = df.copy()\n",
    "    if 'datadate' not in df.columns or 'permno' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must have 'datadate' and 'permno' columns\")\n",
    "    df['datadate'] = pd.to_datetime(df['datadate'])\n",
    "\n",
    "    # Create ticker to permno mapping\n",
    "    if verbose:\n",
    "        print(\"Creating ticker to permno mapping...\")\n",
    "    ticker_to_permno = create_ticker_to_permno_mapping(df)\n",
    "    if verbose:\n",
    "        print(f\"Mapped {len(ticker_to_permno)} unique tickers to permnos\")\n",
    "    \n",
    "    # Load FinBERT signals if provided\n",
    "    finbert_df = None\n",
    "    if finbert_signals_path is not None:\n",
    "        finbert_df = load_finbert_signals(finbert_signals_path)\n",
    "        if verbose and len(finbert_df) > 0:\n",
    "            print(f\"Loaded FinBERT signals: {len(finbert_df)} monthly records\")\n",
    "            print(f\"FinBERT signal distribution:\")\n",
    "            print(finbert_df['signal'].value_counts())\n",
    "    \n",
    "    # Load analyst recommendations if provided\n",
    "    analyst_df = None\n",
    "    if analyst_rec_path is not None:\n",
    "        analyst_df = load_analyst_recommendations(analyst_rec_path)\n",
    "        if verbose and len(analyst_df) > 0:\n",
    "            print(f\"Loaded analyst recommendations: {len(analyst_df)} records\")\n",
    "    \n",
    "    \n",
    "    # [Keep all existing date and storage setup]\n",
    "    all_dates = sorted(df['datadate'].unique())\n",
    "    test_start_dt = pd.to_datetime(test_start_date)\n",
    "    test_end_dt = pd.to_datetime(test_end_date)\n",
    "    \n",
    "    try:\n",
    "        test_start_idx = all_dates.index(test_start_dt)\n",
    "        test_end_idx = all_dates.index(test_end_dt)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(f\"Date not found in DataFrame: {e}\")\n",
    "    \n",
    "    # Storage for results - GMV\n",
    "    portfolio_returns = []\n",
    "    portfolio_dates = []\n",
    "    portfolio_weights_list = []\n",
    "    portfolio_turnover_list = []\n",
    "    portfolio_gross_returns = []\n",
    "    \n",
    "    # Storage for results - MV\n",
    "    portfolio_returns_2 = []\n",
    "    portfolio_dates_2 = []\n",
    "    portfolio_weights_list_2 = []\n",
    "    portfolio_turnover_list_2 = []\n",
    "    portfolio_gross_returns_2 = []\n",
    "    \n",
    "    # Storage for results - MSR\n",
    "    portfolio_returns_3 = []\n",
    "    portfolio_dates_3 = []\n",
    "    portfolio_weights_list_3 = []\n",
    "    portfolio_turnover_list_3 = []\n",
    "    portfolio_gross_returns_3 = []\n",
    "    \n",
    "    # Track weights by permno - GMV\n",
    "    prev_weights_dict = {}\n",
    "    prev_oos_returns_dict = {}\n",
    "    prev_gross_return = 0.0\n",
    "    \n",
    "    # Track weights by permno - MV\n",
    "    prev_weights_dict_2 = {}\n",
    "    prev_oos_returns_dict_2 = {}\n",
    "    prev_gross_return_2 = 0.0\n",
    "    \n",
    "    # Track weights by permno - MSR\n",
    "    prev_weights_dict_3 = {}\n",
    "    prev_oos_returns_dict_3 = {}\n",
    "    prev_gross_return_3 = 0.0\n",
    "    \n",
    "    # Cache for yearly signals\n",
    "    yearly_signals_cache = {}\n",
    "    \n",
    "    # --- 2. Rolling Window Backtest ---\n",
    "    if verbose:\n",
    "        print(\"=\"*60)\n",
    "        print(\"STARTING BACKTEST WITH DNN-FM + YEARLY + ANALYST SIGNALS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "    for t in range(test_start_idx, test_end_idx + 1):\n",
    "        current_date = all_dates[t]\n",
    "        current_year = current_date.year\n",
    "        \n",
    "        # Load yearly signals\n",
    "        if current_year not in yearly_signals_cache:\n",
    "            yearly_signals_cache[current_year] = load_yearly_signals(\n",
    "                current_year, buys_path_template, sells_path_template\n",
    "            )\n",
    "        \n",
    "        yearly_permnos = yearly_signals_cache[current_year]\n",
    "        \n",
    "        # Get analyst recommendations for current date\n",
    "        analyst_permnos = set()\n",
    "        if analyst_df is not None and len(analyst_df) > 0:\n",
    "            analyst_permnos = get_signal_permnos_for_date(analyst_df, current_date)\n",
    "\n",
    "        # Get FinBERT signals for current date\n",
    "        finbert_permnos = set()\n",
    "        if finbert_df is not None and len(finbert_df) > 0:\n",
    "            finbert_permnos = get_finbert_permnos_for_date(finbert_df, ticker_to_permno, current_date)\n",
    "        \n",
    "        # keep only permnos that 2 strats agree on\n",
    "        allowed_permnos = (yearly_permnos & analyst_permnos) | \\\n",
    "                          (yearly_permnos & finbert_permnos) | \\\n",
    "                          (analyst_permnos & finbert_permnos)\n",
    "        \n",
    "        # NEW: Get OOS returns FIRST (critical for exit transaction cost calculation)\n",
    "        oos_data = df[(df['datadate'] == current_date) & (df['permno'].isin(allowed_permnos))]\n",
    "        oos_returns_series = oos_data.set_index('permno')['ret_fwd_1']\n",
    "        oos_returns_series = oos_returns_series.dropna()\n",
    "        oos_returns_dict = oos_returns_series.to_dict()\n",
    "        \n",
    "        # NEW: Handle no signals case with proper liquidation\n",
    "        if len(allowed_permnos) == 0:\n",
    "            if verbose:\n",
    "                print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                      f\"Date: {current_date.strftime('%Y-%m-%d')}\")\n",
    "                print(f\"  ⚠ No signals, recording zero return for all strategies\")\n",
    "            \n",
    "            # Liquidate all three strategies\n",
    "            for idx, (pw, po, pg) in enumerate([\n",
    "                (prev_weights_dict, prev_oos_returns_dict, prev_gross_return),\n",
    "                (prev_weights_dict_2, prev_oos_returns_dict_2, prev_gross_return_2),\n",
    "                (prev_weights_dict_3, prev_oos_returns_dict_3, prev_gross_return_3)\n",
    "            ]):\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    pw, po, pg, transaction_cost, verbose=verbose\n",
    "                )\n",
    "                \n",
    "                if idx == 0:  # GMV\n",
    "                    portfolio_returns.append(net_return)\n",
    "                    portfolio_dates.append(current_date)\n",
    "                    portfolio_weights_list.append({})\n",
    "                    portfolio_turnover_list.append(turnover)\n",
    "                    portfolio_gross_returns.append(0.0)\n",
    "                elif idx == 1:  # MV\n",
    "                    portfolio_returns_2.append(net_return)\n",
    "                    portfolio_dates_2.append(current_date)\n",
    "                    portfolio_weights_list_2.append({})\n",
    "                    portfolio_turnover_list_2.append(turnover)\n",
    "                    portfolio_gross_returns_2.append(0.0)\n",
    "                else:  # MSR\n",
    "                    portfolio_returns_3.append(net_return)\n",
    "                    portfolio_dates_3.append(current_date)\n",
    "                    portfolio_weights_list_3.append({})\n",
    "                    portfolio_turnover_list_3.append(turnover)\n",
    "                    portfolio_gross_returns_3.append(0.0)\n",
    "            \n",
    "            # Reset all state\n",
    "            prev_weights_dict = {}\n",
    "            prev_oos_returns_dict = {}\n",
    "            prev_gross_return = 0.0\n",
    "            prev_weights_dict_2 = {}\n",
    "            prev_oos_returns_dict_2 = {}\n",
    "            prev_gross_return_2 = 0.0\n",
    "            prev_weights_dict_3 = {}\n",
    "            prev_oos_returns_dict_3 = {}\n",
    "            prev_gross_return_3 = 0.0\n",
    "            continue\n",
    "        \n",
    "        # Define the lookback window\n",
    "        window_start_date = all_dates[t - lookback_window]\n",
    "        window_end_date = all_dates[t - 1]\n",
    "        \n",
    "        train_data = df[(df['datadate'] >= window_start_date) & \n",
    "                        (df['datadate'] <= window_end_date) &\n",
    "                        (df['permno'].isin(allowed_permnos))]\n",
    "        train_factor = data_factor.loc[window_start_date : window_end_date]\n",
    "        \n",
    "        returns_pivot = train_data.pivot(index='datadate', columns='permno', values='ret_fwd_1')\n",
    "        window_dates = all_dates[t - lookback_window : t]\n",
    "        returns_pivot = returns_pivot.reindex(index=window_dates)\n",
    "        \n",
    "        nan_assets = returns_pivot.columns[returns_pivot.isna().any()]\n",
    "        filtered_pivot = returns_pivot.drop(columns=nan_assets)\n",
    "        \n",
    "        current_assets = filtered_pivot.columns.tolist()\n",
    "        Y = filtered_pivot.values\n",
    "        n_train, p_current = Y.shape\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n[{t - test_start_idx + 1}/{test_end_idx - test_start_idx + 1}] \"\n",
    "                  f\"Date: {current_date.strftime('%Y-%m-%d')} | Year: {current_year}\")\n",
    "            print(f\"  Window: {window_start_date.strftime('%Y-%m-%d')} to \"\n",
    "                  f\"{window_end_date.strftime('%Y-%m-%d')}\")\n",
    "            # NEW: Show both signal types\n",
    "            print(f\"  Yearly: {len(yearly_permnos)} | Analyst: {len(analyst_permnos)} | FinBERT: {len(finbert_permnos)} | \"\n",
    "                  f\"Union/Intersection: {len(allowed_permnos)} | Assets w/ data: {p_current}\")\n",
    "\n",
    "        # Check for valid data\n",
    "        if n_train < lookback_window or p_current < 2:\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ Insufficient data (n={n_train}, p={p_current}), recording 0 return\")\n",
    "            # Liquidate all three strategies\n",
    "            for idx, (pw, po, pg) in enumerate([\n",
    "                (prev_weights_dict, prev_oos_returns_dict, prev_gross_return),\n",
    "                (prev_weights_dict_2, prev_oos_returns_dict_2, prev_gross_return_2),\n",
    "                (prev_weights_dict_3, prev_oos_returns_dict_3, prev_gross_return_3)\n",
    "            ]):\n",
    "                turnover, tc, net_return = calculate_exit_transaction_cost(\n",
    "                    pw, po, pg, transaction_cost, verbose=verbose\n",
    "                )\n",
    "                \n",
    "                if idx == 0:  # GMV\n",
    "                    portfolio_returns.append(net_return)\n",
    "                    portfolio_dates.append(current_date)\n",
    "                    portfolio_weights_list.append({})\n",
    "                    portfolio_turnover_list.append(turnover)\n",
    "                    portfolio_gross_returns.append(0.0)\n",
    "                elif idx == 1:  # MV\n",
    "                    portfolio_returns_2.append(net_return)\n",
    "                    portfolio_dates_2.append(current_date)\n",
    "                    portfolio_weights_list_2.append({})\n",
    "                    portfolio_turnover_list_2.append(turnover)\n",
    "                    portfolio_gross_returns_2.append(0.0)\n",
    "                else:  # MSR\n",
    "                    portfolio_returns_3.append(net_return)\n",
    "                    portfolio_dates_3.append(current_date)\n",
    "                    portfolio_weights_list_3.append({})\n",
    "                    portfolio_turnover_list_3.append(turnover)\n",
    "                    portfolio_gross_returns_3.append(0.0)\n",
    "            \n",
    "            # Reset all state\n",
    "            prev_weights_dict = {}\n",
    "            prev_oos_returns_dict = {}\n",
    "            prev_gross_return = 0.0\n",
    "            prev_weights_dict_2 = {}\n",
    "            prev_oos_returns_dict_2 = {}\n",
    "            prev_gross_return_2 = 0.0\n",
    "            prev_weights_dict_3 = {}\n",
    "            prev_oos_returns_dict_3 = {}\n",
    "            prev_gross_return_3 = 0.0\n",
    "            continue\n",
    "        else:\n",
    "            try:\n",
    "                # Demean the returns\n",
    "                Y_bar = Y.mean(axis=0)\n",
    "                Y_star = Y - Y_bar\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Running Deep Learning Regression...\")\n",
    "                F = train_factor.values.astype(float)\n",
    "                res_nnet_fm = DNN_FM_main(Y_star, F, architecture=5, const_err_cov=2.5, \n",
    "                                         use_CV_err=False, eval_type='frob')\n",
    "                Theta_hat = res_nnet_fm['inv_sigma_hat']\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Computing GMV weights...\")\n",
    "                w_star = gmv_weights(Theta_hat)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Computing MV weights...\")\n",
    "                w_star_2 = mv_weights(Theta_hat, Y_bar, target_return=0.01)\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"  Computing MSR weights...\")\n",
    "                w_star_3 = msr_weights(Theta_hat, Y_bar)\n",
    "                \n",
    "                # Create weights dictionaries\n",
    "                new_weights_dict = {asset: w_star[i] for i, asset in enumerate(current_assets)}\n",
    "                new_weights_dict_2 = {asset: w_star_2[i] for i, asset in enumerate(current_assets)}\n",
    "                new_weights_dict_3 = {asset: w_star_3[i] for i, asset in enumerate(current_assets)}\n",
    "                \n",
    "            except Exception as e:\n",
    "                if verbose:\n",
    "                    print(f\"  ✗ Error: {e}\")\n",
    "                    print(f\"  Using previous weights\")\n",
    "                new_weights_dict = prev_weights_dict.copy()\n",
    "                new_weights_dict_2 = prev_weights_dict_2.copy()\n",
    "                new_weights_dict_3 = prev_weights_dict_3.copy()\n",
    "\n",
    "        # Normalize weights to sum to 1 - GMV\n",
    "        weight_sum = sum(new_weights_dict.values())\n",
    "        if weight_sum > 1e-10:\n",
    "            new_weights_dict = {k: v/weight_sum for k, v in new_weights_dict.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ GMV: Zero weight sum, using previous weights\")\n",
    "            new_weights_dict = prev_weights_dict.copy()\n",
    "            weight_sum = sum(new_weights_dict.values())\n",
    "            if weight_sum > 1e-10:\n",
    "                new_weights_dict = {k: v/weight_sum for k, v in new_weights_dict.items()}\n",
    "        \n",
    "        # Normalize weights to sum to 1 - MV\n",
    "        weight_sum_2 = sum(new_weights_dict_2.values())\n",
    "        if weight_sum_2 > 1e-10:\n",
    "            new_weights_dict_2 = {k: v/weight_sum_2 for k, v in new_weights_dict_2.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ MV: Zero weight sum, using previous weights\")\n",
    "            new_weights_dict_2 = prev_weights_dict_2.copy()\n",
    "            weight_sum_2 = sum(new_weights_dict_2.values())\n",
    "            if weight_sum_2 > 1e-10:\n",
    "                new_weights_dict_2 = {k: v/weight_sum_2 for k, v in new_weights_dict_2.items()}\n",
    "        \n",
    "        # Normalize weights to sum to 1 - MSR\n",
    "        weight_sum_3 = sum(new_weights_dict_3.values())\n",
    "        if weight_sum_3 > 1e-10:\n",
    "            new_weights_dict_3 = {k: v/weight_sum_3 for k, v in new_weights_dict_3.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ MSR: Zero weight sum, using previous weights\")\n",
    "            new_weights_dict_3 = prev_weights_dict_3.copy()\n",
    "            weight_sum_3 = sum(new_weights_dict_3.values())\n",
    "            if weight_sum_3 > 1e-10:\n",
    "                new_weights_dict_3 = {k: v/weight_sum_3 for k, v in new_weights_dict_3.items()}\n",
    "        \n",
    "        # --- 3. OOS Returns & Transaction Costs ---\n",
    "        \n",
    "        # Get out-of-sample returns for current month (only for allowed permnos)\n",
    "        oos_data = df[(df['datadate'] == current_date) & (df['permno'].isin(allowed_permnos))]\n",
    "        oos_returns_series = oos_data.set_index('permno')['ret_fwd_1']\n",
    "        \n",
    "        # Filter out NaN returns\n",
    "        oos_returns_series = oos_returns_series.dropna()\n",
    "        oos_returns_dict = oos_returns_series.to_dict()\n",
    "        \n",
    "        # Find common assets between weights and returns\n",
    "        common_assets = set(new_weights_dict.keys()) & set(oos_returns_dict.keys())\n",
    "        common_assets_2 = set(new_weights_dict_2.keys()) & set(oos_returns_dict.keys())\n",
    "        common_assets_3 = set(new_weights_dict_3.keys()) & set(oos_returns_dict.keys())\n",
    "        \n",
    "        if len(common_assets) == 0 or len(common_assets_2) == 0 or len(common_assets_3) == 0:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ No common assets with valid returns, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Filter to common assets and renormalize - GMV\n",
    "        common_weights = {a: new_weights_dict[a] for a in common_assets}\n",
    "        common_weight_sum = sum(common_weights.values())\n",
    "        if common_weight_sum > 1e-10:\n",
    "            common_weights = {k: v/common_weight_sum for k, v in common_weights.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ GMV: Zero weight sum after filtering, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Filter to common assets and renormalize - MV\n",
    "        common_weights_2 = {a: new_weights_dict_2[a] for a in common_assets_2}\n",
    "        common_weight_sum_2 = sum(common_weights_2.values())\n",
    "        if common_weight_sum_2 > 1e-10:\n",
    "            common_weights_2 = {k: v/common_weight_sum_2 for k, v in common_weights_2.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ MV: Zero weight sum after filtering, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Filter to common assets and renormalize - MSR\n",
    "        common_weights_3 = {a: new_weights_dict_3[a] for a in common_assets_3}\n",
    "        common_weight_sum_3 = sum(common_weights_3.values())\n",
    "        if common_weight_sum_3 > 1e-10:\n",
    "            common_weights_3 = {k: v/common_weight_sum_3 for k, v in common_weights_3.items()}\n",
    "        else:\n",
    "            if verbose:\n",
    "                print(\"  ⚠ MSR: Zero weight sum after filtering, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # Compute gross portfolio returns\n",
    "        gross_return = sum(common_weights[a] * oos_returns_dict[a] for a in common_assets)\n",
    "        gross_return_2 = sum(common_weights_2[a] * oos_returns_dict[a] for a in common_assets_2)\n",
    "        gross_return_3 = sum(common_weights_3[a] * oos_returns_dict[a] for a in common_assets_3)\n",
    "        \n",
    "        # Sanity checks\n",
    "        if np.isnan(gross_return) or np.isinf(gross_return):\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ GMV: Invalid gross return: {gross_return}, skipping period\")\n",
    "            continue\n",
    "        if np.isnan(gross_return_2) or np.isinf(gross_return_2):\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ MV: Invalid gross return: {gross_return_2}, skipping period\")\n",
    "            continue\n",
    "        if np.isnan(gross_return_3) or np.isinf(gross_return_3):\n",
    "            if verbose:\n",
    "                print(f\"  ⚠ MSR: Invalid gross return: {gross_return_3}, skipping period\")\n",
    "            continue\n",
    "        \n",
    "        # === IMPROVED TRANSACTION COST CALCULATION - GMV ===\n",
    "        if len(prev_weights_dict) > 0:\n",
    "            # Step 1: Adjust ALL previous weights for their returns\n",
    "            adjusted_prev = {}\n",
    "            \n",
    "            for asset, prev_w in prev_weights_dict.items():\n",
    "                if asset in prev_oos_returns_dict:\n",
    "                    prev_r = prev_oos_returns_dict[asset]\n",
    "                    if abs(1 + prev_gross_return) > 1e-6:\n",
    "                        adjusted_prev[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return)\n",
    "                    else:\n",
    "                        adjusted_prev[asset] = 0.0\n",
    "                else:\n",
    "                    # Asset had weight but no return data (exited)\n",
    "                    if abs(1 + prev_gross_return) > 1e-6:\n",
    "                        adjusted_prev[asset] = prev_w / (1 + prev_gross_return)\n",
    "                    else:\n",
    "                        adjusted_prev[asset] = 0.0\n",
    "            \n",
    "            # Step 2: Calculate turnover across all assets (old and new)\n",
    "            all_assets = set(adjusted_prev.keys()) | set(common_weights.keys())\n",
    "            \n",
    "            turnover = 0.0\n",
    "            for asset in all_assets:\n",
    "                old_w = adjusted_prev.get(asset, 0.0)\n",
    "                new_w = common_weights.get(asset, 0.0)\n",
    "                turnover += abs(new_w - old_w)\n",
    "            \n",
    "            # Transaction cost on end-of-period portfolio value\n",
    "            tc = transaction_cost * (1 + gross_return) * turnover\n",
    "        else:\n",
    "            # First period: buying into everything\n",
    "            turnover = sum(abs(w) for w in common_weights.values())\n",
    "            tc = transaction_cost * (1 + gross_return) * turnover\n",
    "        \n",
    "        # === IMPROVED TRANSACTION COST CALCULATION - MV ===\n",
    "        if len(prev_weights_dict_2) > 0:\n",
    "            adjusted_prev_2 = {}\n",
    "            \n",
    "            for asset, prev_w in prev_weights_dict_2.items():\n",
    "                if asset in prev_oos_returns_dict_2:\n",
    "                    prev_r = prev_oos_returns_dict_2[asset]\n",
    "                    if abs(1 + prev_gross_return_2) > 1e-6:\n",
    "                        adjusted_prev_2[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return_2)\n",
    "                    else:\n",
    "                        adjusted_prev_2[asset] = 0.0\n",
    "                else:\n",
    "                    if abs(1 + prev_gross_return_2) > 1e-6:\n",
    "                        adjusted_prev_2[asset] = prev_w / (1 + prev_gross_return_2)\n",
    "                    else:\n",
    "                        adjusted_prev_2[asset] = 0.0\n",
    "            \n",
    "            all_assets_2 = set(adjusted_prev_2.keys()) | set(common_weights_2.keys())\n",
    "            \n",
    "            turnover_2 = 0.0\n",
    "            for asset in all_assets_2:\n",
    "                old_w = adjusted_prev_2.get(asset, 0.0)\n",
    "                new_w = common_weights_2.get(asset, 0.0)\n",
    "                turnover_2 += abs(new_w - old_w)\n",
    "            \n",
    "            tc_2 = transaction_cost * (1 + gross_return_2) * turnover_2\n",
    "        else:\n",
    "            turnover_2 = sum(abs(w) for w in common_weights_2.values())\n",
    "            tc_2 = transaction_cost * (1 + gross_return_2) * turnover_2\n",
    "        \n",
    "        # === IMPROVED TRANSACTION COST CALCULATION - MSR ===\n",
    "        if len(prev_weights_dict_3) > 0:\n",
    "            adjusted_prev_3 = {}\n",
    "            \n",
    "            for asset, prev_w in prev_weights_dict_3.items():\n",
    "                if asset in prev_oos_returns_dict_3:\n",
    "                    prev_r = prev_oos_returns_dict_3[asset]\n",
    "                    if abs(1 + prev_gross_return_3) > 1e-6:\n",
    "                        adjusted_prev_3[asset] = prev_w * (1 + prev_r) / (1 + prev_gross_return_3)\n",
    "                    else:\n",
    "                        adjusted_prev_3[asset] = 0.0\n",
    "                else:\n",
    "                    if abs(1 + prev_gross_return_3) > 1e-6:\n",
    "                        adjusted_prev_3[asset] = prev_w / (1 + prev_gross_return_3)\n",
    "                    else:\n",
    "                        adjusted_prev_3[asset] = 0.0\n",
    "            \n",
    "            all_assets_3 = set(adjusted_prev_3.keys()) | set(common_weights_3.keys())\n",
    "            \n",
    "            turnover_3 = 0.0\n",
    "            for asset in all_assets_3:\n",
    "                old_w = adjusted_prev_3.get(asset, 0.0)\n",
    "                new_w = common_weights_3.get(asset, 0.0)\n",
    "                turnover_3 += abs(new_w - old_w)\n",
    "            \n",
    "            tc_3 = transaction_cost * (1 + gross_return_3) * turnover_3\n",
    "        else:\n",
    "            turnover_3 = sum(abs(w) for w in common_weights_3.values())\n",
    "            tc_3 = transaction_cost * (1 + gross_return_3) * turnover_3\n",
    "        \n",
    "        # Net returns\n",
    "        net_return = gross_return - tc\n",
    "        net_return_2 = gross_return_2 - tc_2\n",
    "        net_return_3 = gross_return_3 - tc_3\n",
    "        \n",
    "        # Store results - GMV\n",
    "        portfolio_returns.append(net_return)\n",
    "        portfolio_dates.append(current_date)\n",
    "        portfolio_weights_list.append(common_weights.copy())\n",
    "        portfolio_turnover_list.append(turnover)\n",
    "        portfolio_gross_returns.append(gross_return)\n",
    "        \n",
    "        # Store results - MV\n",
    "        portfolio_returns_2.append(net_return_2)\n",
    "        portfolio_dates_2.append(current_date)\n",
    "        portfolio_weights_list_2.append(common_weights_2.copy())\n",
    "        portfolio_turnover_list_2.append(turnover_2)\n",
    "        portfolio_gross_returns_2.append(gross_return_2)\n",
    "        \n",
    "        # Store results - MSR\n",
    "        portfolio_returns_3.append(net_return_3)\n",
    "        portfolio_dates_3.append(current_date)\n",
    "        portfolio_weights_list_3.append(common_weights_3.copy())\n",
    "        portfolio_turnover_list_3.append(turnover_3)\n",
    "        portfolio_gross_returns_3.append(gross_return_3)\n",
    "        \n",
    "        # Update previous values for next iteration\n",
    "        prev_weights_dict = common_weights.copy()\n",
    "        prev_oos_returns_dict = {a: oos_returns_dict[a] for a in common_assets}\n",
    "        prev_gross_return = gross_return\n",
    "        \n",
    "        prev_weights_dict_2 = common_weights_2.copy()\n",
    "        prev_oos_returns_dict_2 = {a: oos_returns_dict[a] for a in common_assets_2}\n",
    "        prev_gross_return_2 = gross_return_2\n",
    "        \n",
    "        prev_weights_dict_3 = common_weights_3.copy()\n",
    "        prev_oos_returns_dict_3 = {a: oos_returns_dict[a] for a in common_assets_3}\n",
    "        prev_gross_return_3 = gross_return_3\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  GMV  - Gross: {gross_return:>8.5f} | Turnover: {turnover:>6.4f} | \"\n",
    "                  f\"TC: {tc:>8.6f} | Net: {net_return:>8.5f}\")\n",
    "            print(f\"  MV   - Gross: {gross_return_2:>8.5f} | Turnover: {turnover_2:>6.4f} | \"\n",
    "                  f\"TC: {tc_2:>8.6f} | Net: {net_return_2:>8.5f}\")\n",
    "            print(f\"  MSR  - Gross: {gross_return_3:>8.5f} | Turnover: {turnover_3:>6.4f} | \"\n",
    "                  f\"TC: {tc_3:>8.6f} | Net: {net_return_3:>8.5f}\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"BACKTEST COMPLETE\")\n",
    "        print(\"=\"*60)\n",
    "    \n",
    "    # --- 4. Compile Results ---\n",
    "    results_df = pd.DataFrame({\n",
    "        'date': portfolio_dates,\n",
    "        'portfolio_return': portfolio_returns,\n",
    "        'portfolio_gross_return': portfolio_gross_returns,\n",
    "        'portfolio_weights': portfolio_weights_list,\n",
    "        'portfolio_turnover': portfolio_turnover_list\n",
    "    })\n",
    "    results_df['cumulative_return'] = (1 + results_df['portfolio_return']).cumprod() - 1\n",
    "    \n",
    "    results_df_2 = pd.DataFrame({\n",
    "        'date': portfolio_dates_2,\n",
    "        'portfolio_return': portfolio_returns_2,\n",
    "        'portfolio_gross_return': portfolio_gross_returns_2,\n",
    "        'portfolio_weights': portfolio_weights_list_2,\n",
    "        'portfolio_turnover': portfolio_turnover_list_2\n",
    "    })\n",
    "    results_df_2['cumulative_return'] = (1 + results_df_2['portfolio_return']).cumprod() - 1\n",
    "    \n",
    "    results_df_3 = pd.DataFrame({\n",
    "        'date': portfolio_dates_3,\n",
    "        'portfolio_return': portfolio_returns_3,\n",
    "        'portfolio_gross_return': portfolio_gross_returns_3,\n",
    "        'portfolio_weights': portfolio_weights_list_3,\n",
    "        'portfolio_turnover': portfolio_turnover_list_3\n",
    "    })\n",
    "    results_df_3['cumulative_return'] = (1 + results_df_3['portfolio_return']).cumprod() - 1\n",
    "    \n",
    "    # Helper function to compute metrics\n",
    "    def compute_metrics(returns_list, turnover_list, results_df):\n",
    "        if len(returns_list) > 0:\n",
    "            mean_return = np.mean(returns_list)\n",
    "            variance = np.var(returns_list, ddof=1)\n",
    "            sharpe_ratio = mean_return / np.sqrt(variance) if variance > 0 else 0\n",
    "            \n",
    "            # Annualized metrics (monthly data)\n",
    "            annual_return = mean_return * 12\n",
    "            annual_volatility = np.sqrt(variance * 12)\n",
    "            annual_sharpe = annual_return / annual_volatility if annual_volatility > 0 else 0\n",
    "            \n",
    "            return {\n",
    "                'mean_return': mean_return,\n",
    "                'variance': variance,\n",
    "                'sharpe_ratio': sharpe_ratio,\n",
    "                'annual_return': annual_return,\n",
    "                'annual_volatility': annual_volatility,\n",
    "                'annual_sharpe_ratio': annual_sharpe,\n",
    "                'total_return': results_df['cumulative_return'].iloc[-1],\n",
    "                'avg_turnover': np.mean(turnover_list),\n",
    "                'n_periods': len(returns_list)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'mean_return': 0, 'variance': 0, 'sharpe_ratio': 0,\n",
    "                'annual_return': 0, 'annual_volatility': 0, 'annual_sharpe_ratio': 0,\n",
    "                'total_return': 0, 'avg_turnover': 0, 'n_periods': 0\n",
    "            }\n",
    "    \n",
    "    # Compute metrics for all three strategies\n",
    "    metrics = compute_metrics(portfolio_returns, portfolio_turnover_list, results_df)\n",
    "    metrics_2 = compute_metrics(portfolio_returns_2, portfolio_turnover_list_2, results_df_2)\n",
    "    metrics_3 = compute_metrics(portfolio_returns_3, portfolio_turnover_list_3, results_df_3)\n",
    "    \n",
    "    return results_df, metrics, results_df_2, metrics_2, results_df_3, metrics_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f77cbae-5233-4cbe-8d95-7d8e0a1a7e1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ticker to permno mapping...\n",
      "Mapped 1664 unique tickers to permnos\n",
      "Loaded FinBERT signals: 54240 monthly records\n",
      "FinBERT signal distribution:\n",
      "signal\n",
      "hold    52823\n",
      "sell      859\n",
      "buy       558\n",
      "Name: count, dtype: int64\n",
      "Loaded analyst recommendations: 37527 records\n",
      "============================================================\n",
      "STARTING BACKTEST WITH DNN-FM + YEARLY + ANALYST SIGNALS\n",
      "============================================================\n",
      "\n",
      "[1/112] Date: 2015-01-31 | Year: 2015\n",
      "  Window: 2000-01-31 to 2014-12-31\n",
      "  Yearly: 54 | Analyst: 69 | FinBERT: 10 | Union/Intersection: 10 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04100 | Turnover: 1.0000 | TC: 0.001041 | Net:  0.03996\n",
      "  MV   - Gross:  0.05005 | Turnover: 1.0428 | TC: 0.001095 | Net:  0.04895\n",
      "  MSR  - Gross:  0.04839 | Turnover: 1.0208 | TC: 0.001070 | Net:  0.04732\n",
      "\n",
      "[2/112] Date: 2015-02-28 | Year: 2015\n",
      "  Window: 2000-02-29 to 2015-01-31\n",
      "  Yearly: 54 | Analyst: 91 | FinBERT: 4 | Union/Intersection: 7 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00617 | Turnover: 1.8906 | TC: 0.001879 | Net: -0.00805\n",
      "  MV   - Gross: -0.05585 | Turnover: 1.9105 | TC: 0.001804 | Net: -0.05765\n",
      "  MSR  - Gross:  0.02396 | Turnover: 1.9737 | TC: 0.002021 | Net:  0.02193\n",
      "\n",
      "[3/112] Date: 2015-03-31 | Year: 2015\n",
      "  Window: 2000-03-31 to 2015-02-28\n",
      "  Yearly: 54 | Analyst: 101 | FinBERT: 4 | Union/Intersection: 9 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01898 | Turnover: 2.0143 | TC: 0.002053 | Net:  0.01693\n",
      "  MV   - Gross:  0.02162 | Turnover: 2.0000 | TC: 0.002043 | Net:  0.01958\n",
      "  MSR  - Gross:  0.01335 | Turnover: 2.1197 | TC: 0.002148 | Net:  0.01120\n",
      "\n",
      "[4/112] Date: 2015-04-30 | Year: 2015\n",
      "  Window: 2000-04-30 to 2015-03-31\n",
      "  Yearly: 54 | Analyst: 143 | FinBERT: 5 | Union/Intersection: 16 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00016 | Turnover: 1.4544 | TC: 0.001454 | Net: -0.00162\n",
      "  MV   - Gross: -0.00154 | Turnover: 1.5252 | TC: 0.001523 | Net: -0.00306\n",
      "  MSR  - Gross: -0.00220 | Turnover: 1.6138 | TC: 0.001610 | Net: -0.00381\n",
      "\n",
      "[5/112] Date: 2015-05-31 | Year: 2015\n",
      "  Window: 2000-05-31 to 2015-04-30\n",
      "  Yearly: 54 | Analyst: 121 | FinBERT: 5 | Union/Intersection: 9 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function pfor.<locals>.f at 0x13eaf3240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.07079 | Turnover: 1.8144 | TC: 0.001686 | Net: -0.07248\n",
      "  MV   - Gross: -0.04372 | Turnover: 1.9325 | TC: 0.001848 | Net: -0.04556\n",
      "  MSR  - Gross: -0.04230 | Turnover: 2.0082 | TC: 0.001923 | Net: -0.04422\n",
      "\n",
      "[6/112] Date: 2015-06-30 | Year: 2015\n",
      "  Window: 2000-06-30 to 2015-05-31\n",
      "  Yearly: 54 | Analyst: 105 | FinBERT: 4 | Union/Intersection: 18 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function pfor.<locals>.f at 0x10ca5d300> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00715 | Turnover: 1.0067 | TC: 0.001000 | Net: -0.00815\n",
      "  MV   - Gross: -0.01278 | Turnover: 1.0769 | TC: 0.001063 | Net: -0.01384\n",
      "  MSR  - Gross: -0.01690 | Turnover: 1.0342 | TC: 0.001017 | Net: -0.01791\n",
      "\n",
      "[7/112] Date: 2015-07-31 | Year: 2015\n",
      "  Window: 2000-07-31 to 2015-06-30\n",
      "  Yearly: 54 | Analyst: 135 | FinBERT: 3 | Union/Intersection: 11 | Assets w/ data: 8\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.05699 | Turnover: 1.3987 | TC: 0.001319 | Net: -0.05831\n",
      "  MV   - Gross: -0.05083 | Turnover: 1.6836 | TC: 0.001598 | Net: -0.05242\n",
      "  MSR  - Gross: -0.04902 | Turnover: 1.8751 | TC: 0.001783 | Net: -0.05080\n",
      "\n",
      "[8/112] Date: 2015-08-31 | Year: 2015\n",
      "  Window: 2000-08-31 to 2015-07-31\n",
      "  Yearly: 54 | Analyst: 122 | FinBERT: 4 | Union/Intersection: 15 | Assets w/ data: 12\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01591 | Turnover: 1.4372 | TC: 0.001414 | Net: -0.01732\n",
      "  MV   - Gross: -0.00833 | Turnover: 1.6234 | TC: 0.001610 | Net: -0.00994\n",
      "  MSR  - Gross: -0.00133 | Turnover: 1.8869 | TC: 0.001884 | Net: -0.00321\n",
      "\n",
      "[9/112] Date: 2015-09-30 | Year: 2015\n",
      "  Window: 2000-09-30 to 2015-08-31\n",
      "  Yearly: 54 | Analyst: 139 | FinBERT: 1 | Union/Intersection: 16 | Assets w/ data: 12\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03477 | Turnover: 1.0171 | TC: 0.001052 | Net:  0.03371\n",
      "  MV   - Gross:  0.04880 | Turnover: 1.1340 | TC: 0.001189 | Net:  0.04761\n",
      "  MSR  - Gross:  0.07239 | Turnover: 1.3447 | TC: 0.001442 | Net:  0.07095\n",
      "\n",
      "[10/112] Date: 2015-10-31 | Year: 2015\n",
      "  Window: 2000-10-31 to 2015-09-30\n",
      "  Yearly: 54 | Analyst: 143 | FinBERT: 6 | Union/Intersection: 16 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01913 | Turnover: 1.3862 | TC: 0.001360 | Net: -0.02049\n",
      "  MV   - Gross: -0.01938 | Turnover: 1.4691 | TC: 0.001441 | Net: -0.02082\n",
      "  MSR  - Gross: -0.02117 | Turnover: 1.6028 | TC: 0.001569 | Net: -0.02274\n",
      "\n",
      "[11/112] Date: 2015-11-30 | Year: 2015\n",
      "  Window: 2000-11-30 to 2015-10-31\n",
      "  Yearly: 54 | Analyst: 121 | FinBERT: 4 | Union/Intersection: 10 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01552 | Turnover: 1.6836 | TC: 0.001658 | Net: -0.01717\n",
      "  MV   - Gross: -0.02523 | Turnover: 1.6995 | TC: 0.001657 | Net: -0.02688\n",
      "  MSR  - Gross: -0.03032 | Turnover: 2.1541 | TC: 0.002089 | Net: -0.03241\n",
      "\n",
      "[12/112] Date: 2015-12-31 | Year: 2015\n",
      "  Window: 2000-12-31 to 2015-11-30\n",
      "  Yearly: 54 | Analyst: 74 | FinBERT: 5 | Union/Intersection: 4 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.07766 | Turnover: 1.7771 | TC: 0.001639 | Net: -0.07930\n",
      "  MV   - Gross: -0.11000 | Turnover: 4.3118 | TC: 0.003838 | Net: -0.11384\n",
      "  MSR  - Gross: -0.07980 | Turnover: 2.1232 | TC: 0.001954 | Net: -0.08175\n",
      "\n",
      "[13/112] Date: 2016-01-31 | Year: 2016\n",
      "  Window: 2001-01-31 to 2015-12-31\n",
      "  Yearly: 81 | Analyst: 111 | FinBERT: 1 | Union/Intersection: 13 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04692 | Turnover: 1.9197 | TC: 0.002010 | Net:  0.04491\n",
      "  MV   - Gross:  0.07609 | Turnover: 4.6544 | TC: 0.005009 | Net:  0.07108\n",
      "  MSR  - Gross:  0.07385 | Turnover: 2.0236 | TC: 0.002173 | Net:  0.07167\n",
      "\n",
      "[14/112] Date: 2016-02-29 | Year: 2016\n",
      "  Window: 2001-02-28 to 2016-01-31\n",
      "  Yearly: 81 | Analyst: 117 | FinBERT: 8 | Union/Intersection: 17 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07956 | Turnover: 1.7787 | TC: 0.001920 | Net:  0.07764\n",
      "  MV   - Gross:  0.06202 | Turnover: 2.2638 | TC: 0.002404 | Net:  0.05961\n",
      "  MSR  - Gross:  0.07058 | Turnover: 1.8936 | TC: 0.002027 | Net:  0.06855\n",
      "\n",
      "[15/112] Date: 2016-03-31 | Year: 2016\n",
      "  Window: 2001-03-31 to 2016-02-29\n",
      "  Yearly: 81 | Analyst: 113 | FinBERT: 4 | Union/Intersection: 15 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02476 | Turnover: 1.0398 | TC: 0.001014 | Net: -0.02577\n",
      "  MV   - Gross: -0.09720 | Turnover: 7.2747 | TC: 0.006568 | Net: -0.10377\n",
      "  MSR  - Gross: -0.02873 | Turnover: 1.7111 | TC: 0.001662 | Net: -0.03039\n",
      "\n",
      "[16/112] Date: 2016-04-30 | Year: 2016\n",
      "  Window: 2001-04-30 to 2016-03-31\n",
      "  Yearly: 81 | Analyst: 115 | FinBERT: 5 | Union/Intersection: 22 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02845 | Turnover: 1.9590 | TC: 0.002015 | Net:  0.02644\n",
      "  MV   - Gross:  0.02144 | Turnover: 7.2334 | TC: 0.007389 | Net:  0.01406\n",
      "  MSR  - Gross:  0.01743 | Turnover: 2.0331 | TC: 0.002069 | Net:  0.01537\n",
      "\n",
      "[17/112] Date: 2016-05-31 | Year: 2016\n",
      "  Window: 2001-05-31 to 2016-04-30\n",
      "  Yearly: 81 | Analyst: 99 | FinBERT: 5 | Union/Intersection: 17 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00616 | Turnover: 1.4475 | TC: 0.001456 | Net:  0.00471\n",
      "  MV   - Gross:  0.01294 | Turnover: 1.3255 | TC: 0.001343 | Net:  0.01160\n",
      "  MSR  - Gross:  0.01920 | Turnover: 1.2809 | TC: 0.001305 | Net:  0.01789\n",
      "\n",
      "[18/112] Date: 2016-06-30 | Year: 2016\n",
      "  Window: 2001-06-30 to 2016-05-31\n",
      "  Yearly: 81 | Analyst: 114 | FinBERT: 4 | Union/Intersection: 14 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03132 | Turnover: 2.0392 | TC: 0.002103 | Net:  0.02922\n",
      "  MV   - Gross: -0.00044 | Turnover: 2.4227 | TC: 0.002422 | Net: -0.00286\n",
      "  MSR  - Gross:  0.00724 | Turnover: 2.2423 | TC: 0.002259 | Net:  0.00498\n",
      "\n",
      "[19/112] Date: 2016-07-31 | Year: 2016\n",
      "  Window: 2001-07-31 to 2016-06-30\n",
      "  Yearly: 81 | Analyst: 101 | FinBERT: 9 | Union/Intersection: 24 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00235 | Turnover: 1.6063 | TC: 0.001603 | Net: -0.00395\n",
      "  MV   - Gross: -0.14923 | Turnover: 4.8619 | TC: 0.004136 | Net: -0.15336\n",
      "  MSR  - Gross: -0.03153 | Turnover: 2.3942 | TC: 0.002319 | Net: -0.03385\n",
      "\n",
      "[20/112] Date: 2016-08-31 | Year: 2016\n",
      "  Window: 2001-08-31 to 2016-07-31\n",
      "  Yearly: 81 | Analyst: 98 | FinBERT: 10 | Union/Intersection: 18 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01172 | Turnover: 1.3256 | TC: 0.001310 | Net: -0.01303\n",
      "  MV   - Gross: -0.00667 | Turnover: 4.9500 | TC: 0.004917 | Net: -0.01158\n",
      "  MSR  - Gross: -0.00731 | Turnover: 1.8997 | TC: 0.001886 | Net: -0.00920\n",
      "\n",
      "[21/112] Date: 2016-09-30 | Year: 2016\n",
      "  Window: 2001-09-30 to 2016-08-31\n",
      "  Yearly: 81 | Analyst: 137 | FinBERT: 3 | Union/Intersection: 17 | Assets w/ data: 8\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00621 | Turnover: 1.0457 | TC: 0.001039 | Net: -0.00725\n",
      "  MV   - Gross: -0.00059 | Turnover: 0.9751 | TC: 0.000974 | Net: -0.00156\n",
      "  MSR  - Gross:  0.00109 | Turnover: 0.9308 | TC: 0.000932 | Net:  0.00016\n",
      "\n",
      "[22/112] Date: 2016-10-31 | Year: 2016\n",
      "  Window: 2001-10-31 to 2016-09-30\n",
      "  Yearly: 81 | Analyst: 178 | FinBERT: 10 | Union/Intersection: 28 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04188 | Turnover: 1.3554 | TC: 0.001412 | Net:  0.04046\n",
      "  MV   - Gross:  0.06580 | Turnover: 1.8408 | TC: 0.001962 | Net:  0.06384\n",
      "  MSR  - Gross:  0.05561 | Turnover: 1.6637 | TC: 0.001756 | Net:  0.05385\n",
      "\n",
      "[23/112] Date: 2016-11-30 | Year: 2016\n",
      "  Window: 2001-11-30 to 2016-10-31\n",
      "  Yearly: 81 | Analyst: 151 | FinBERT: 4 | Union/Intersection: 24 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01889 | Turnover: 1.7818 | TC: 0.001815 | Net:  0.01707\n",
      "  MV   - Gross: -0.00811 | Turnover: 1.6577 | TC: 0.001644 | Net: -0.00975\n",
      "  MSR  - Gross: -0.01066 | Turnover: 1.6316 | TC: 0.001614 | Net: -0.01228\n",
      "\n",
      "[24/112] Date: 2016-12-31 | Year: 2016\n",
      "  Window: 2001-12-31 to 2016-11-30\n",
      "  Yearly: 81 | Analyst: 88 | FinBERT: 5 | Union/Intersection: 12 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00578 | Turnover: 1.3427 | TC: 0.001335 | Net: -0.00711\n",
      "  MV   - Gross: -0.00292 | Turnover: 1.7896 | TC: 0.001784 | Net: -0.00470\n",
      "  MSR  - Gross: -0.00463 | Turnover: 1.4082 | TC: 0.001402 | Net: -0.00603\n",
      "\n",
      "[25/112] Date: 2017-01-31 | Year: 2017\n",
      "  Window: 2002-01-31 to 2016-12-31\n",
      "  Yearly: 35 | Analyst: 109 | FinBERT: 13 | Union/Intersection: 11 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02908 | Turnover: 1.8581 | TC: 0.001912 | Net:  0.02716\n",
      "  MV   - Gross:  0.01692 | Turnover: 2.2722 | TC: 0.002311 | Net:  0.01460\n",
      "  MSR  - Gross:  0.02063 | Turnover: 1.9366 | TC: 0.001977 | Net:  0.01865\n",
      "\n",
      "[26/112] Date: 2017-02-28 | Year: 2017\n",
      "  Window: 2002-02-28 to 2017-01-31\n",
      "  Yearly: 35 | Analyst: 105 | FinBERT: 10 | Union/Intersection: 7 | Assets w/ data: 2\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02778 | Turnover: 1.8297 | TC: 0.001779 | Net: -0.02956\n",
      "  MV   - Gross: -0.02790 | Turnover: 1.7837 | TC: 0.001734 | Net: -0.02963\n",
      "  MSR  - Gross: -0.01512 | Turnover: 1.7978 | TC: 0.001771 | Net: -0.01689\n",
      "\n",
      "[27/112] Date: 2017-03-31 | Year: 2017\n",
      "  Window: 2002-03-31 to 2017-02-28\n",
      "  Yearly: 35 | Analyst: 136 | FinBERT: 12 | Union/Intersection: 8 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00864 | Turnover: 1.8830 | TC: 0.001867 | Net: -0.01051\n",
      "  MV   - Gross: -0.02428 | Turnover: 1.9836 | TC: 0.001935 | Net: -0.02621\n",
      "  MSR  - Gross: -0.01201 | Turnover: 1.9047 | TC: 0.001882 | Net: -0.01390\n",
      "\n",
      "[28/112] Date: 2017-04-30 | Year: 2017\n",
      "  Window: 2002-04-30 to 2017-03-31\n",
      "  Yearly: 35 | Analyst: 106 | FinBERT: 5 | Union/Intersection: 5 | Assets w/ data: 1\n",
      "  ⚠ Insufficient data (n=180, p=1), recording 0 return\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "  Liquidating positions | Turnover: 1.0000 | TC: 0.001000\n",
      "\n",
      "[29/112] Date: 2017-05-31 | Year: 2017\n",
      "  Window: 2002-05-31 to 2017-04-30\n",
      "  Yearly: 35 | Analyst: 89 | FinBERT: 9 | Union/Intersection: 5 | Assets w/ data: 1\n",
      "  ⚠ Insufficient data (n=180, p=1), recording 0 return\n",
      "\n",
      "[30/112] Date: 2017-06-30 | Year: 2017\n",
      "  Window: 2002-06-30 to 2017-05-31\n",
      "  Yearly: 35 | Analyst: 129 | FinBERT: 4 | Union/Intersection: 12 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02990 | Turnover: 1.0000 | TC: 0.001030 | Net:  0.02887\n",
      "  MV   - Gross:  0.03301 | Turnover: 1.3699 | TC: 0.001415 | Net:  0.03159\n",
      "  MSR  - Gross:  0.03156 | Turnover: 1.1104 | TC: 0.001145 | Net:  0.03041\n",
      "\n",
      "[31/112] Date: 2017-07-31 | Year: 2017\n",
      "  Window: 2002-07-31 to 2017-06-30\n",
      "  Yearly: 35 | Analyst: 110 | FinBERT: 9 | Union/Intersection: 7 | Assets w/ data: 3\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00195 | Turnover: 2.0000 | TC: 0.002004 | Net: -0.00006\n",
      "  MV   - Gross:  0.00384 | Turnover: 2.3637 | TC: 0.002373 | Net:  0.00147\n",
      "  MSR  - Gross:  0.00292 | Turnover: 2.1087 | TC: 0.002115 | Net:  0.00081\n",
      "\n",
      "[32/112] Date: 2017-08-31 | Year: 2017\n",
      "  Window: 2002-08-31 to 2017-07-31\n",
      "  Yearly: 35 | Analyst: 89 | FinBERT: 9 | Union/Intersection: 10 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.05213 | Turnover: 1.5573 | TC: 0.001638 | Net:  0.05050\n",
      "  MV   - Gross:  0.05348 | Turnover: 1.6180 | TC: 0.001705 | Net:  0.05177\n",
      "  MSR  - Gross:  0.07342 | Turnover: 1.3710 | TC: 0.001472 | Net:  0.07195\n",
      "\n",
      "[33/112] Date: 2017-09-30 | Year: 2017\n",
      "  Window: 2002-09-30 to 2017-08-31\n",
      "  Yearly: 35 | Analyst: 111 | FinBERT: 10 | Union/Intersection: 9 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02364 | Turnover: 1.7754 | TC: 0.001733 | Net: -0.02538\n",
      "  MV   - Gross:  0.01000 | Turnover: 2.0909 | TC: 0.002112 | Net:  0.00789\n",
      "  MSR  - Gross: -0.05013 | Turnover: 1.7207 | TC: 0.001634 | Net: -0.05176\n",
      "\n",
      "[34/112] Date: 2017-10-31 | Year: 2017\n",
      "  Window: 2002-10-31 to 2017-09-30\n",
      "  Yearly: 35 | Analyst: 137 | FinBERT: 10 | Union/Intersection: 14 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.05361 | Turnover: 1.6441 | TC: 0.001732 | Net:  0.05188\n",
      "  MV   - Gross:  0.05664 | Turnover: 1.8444 | TC: 0.001949 | Net:  0.05469\n",
      "  MSR  - Gross:  0.06706 | Turnover: 1.5911 | TC: 0.001698 | Net:  0.06536\n",
      "\n",
      "[35/112] Date: 2017-11-30 | Year: 2017\n",
      "  Window: 2002-11-30 to 2017-10-31\n",
      "  Yearly: 35 | Analyst: 92 | FinBERT: 6 | Union/Intersection: 5 | Assets w/ data: 2\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03880 | Turnover: 2.0000 | TC: 0.002078 | Net:  0.03673\n",
      "  MV   - Gross:  0.04689 | Turnover: 2.0000 | TC: 0.002094 | Net:  0.04479\n",
      "  MSR  - Gross:  0.04835 | Turnover: 2.0000 | TC: 0.002097 | Net:  0.04626\n",
      "\n",
      "[36/112] Date: 2017-12-31 | Year: 2017\n",
      "  Window: 2002-12-31 to 2017-11-30\n",
      "  Yearly: 35 | Analyst: 96 | FinBERT: 7 | Union/Intersection: 10 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00058 | Turnover: 1.7039 | TC: 0.001703 | Net: -0.00228\n",
      "  MV   - Gross:  0.00162 | Turnover: 1.6640 | TC: 0.001667 | Net: -0.00005\n",
      "  MSR  - Gross:  0.00537 | Turnover: 1.6696 | TC: 0.001679 | Net:  0.00369\n",
      "\n",
      "[37/112] Date: 2018-01-31 | Year: 2018\n",
      "  Window: 2003-01-31 to 2017-12-31\n",
      "  Yearly: 75 | Analyst: 161 | FinBERT: 7 | Union/Intersection: 26 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.06054 | Turnover: 2.0000 | TC: 0.001879 | Net: -0.06241\n",
      "  MV   - Gross: -0.06149 | Turnover: 2.0000 | TC: 0.001877 | Net: -0.06336\n",
      "  MSR  - Gross: -0.04752 | Turnover: 2.0716 | TC: 0.001973 | Net: -0.04949\n",
      "\n",
      "[38/112] Date: 2018-02-28 | Year: 2018\n",
      "  Window: 2003-02-28 to 2018-01-31\n",
      "  Yearly: 75 | Analyst: 160 | FinBERT: 11 | Union/Intersection: 23 | Assets w/ data: 10\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01056 | Turnover: 1.1743 | TC: 0.001162 | Net: -0.01172\n",
      "  MV   - Gross: -0.00856 | Turnover: 1.2469 | TC: 0.001236 | Net: -0.00979\n",
      "  MSR  - Gross: -0.01815 | Turnover: 0.9163 | TC: 0.000900 | Net: -0.01905\n",
      "\n",
      "[39/112] Date: 2018-03-31 | Year: 2018\n",
      "  Window: 2003-03-31 to 2018-02-28\n",
      "  Yearly: 75 | Analyst: 100 | FinBERT: 7 | Union/Intersection: 14 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07032 | Turnover: 1.6141 | TC: 0.001728 | Net:  0.06859\n",
      "  MV   - Gross:  0.07213 | Turnover: 1.6067 | TC: 0.001723 | Net:  0.07040\n",
      "  MSR  - Gross:  0.03510 | Turnover: 1.7263 | TC: 0.001787 | Net:  0.03331\n",
      "\n",
      "[40/112] Date: 2018-04-30 | Year: 2018\n",
      "  Window: 2003-04-30 to 2018-03-31\n",
      "  Yearly: 75 | Analyst: 106 | FinBERT: 13 | Union/Intersection: 19 | Assets w/ data: 12\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00131 | Turnover: 1.9488 | TC: 0.001946 | Net: -0.00326\n",
      "  MV   - Gross: -0.01371 | Turnover: 1.9541 | TC: 0.001927 | Net: -0.01564\n",
      "  MSR  - Gross:  0.03175 | Turnover: 2.0473 | TC: 0.002112 | Net:  0.02964\n",
      "\n",
      "[41/112] Date: 2018-05-31 | Year: 2018\n",
      "  Window: 2003-05-31 to 2018-04-30\n",
      "  Yearly: 75 | Analyst: 85 | FinBERT: 11 | Union/Intersection: 14 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00362 | Turnover: 1.4313 | TC: 0.001426 | Net: -0.00505\n",
      "  MV   - Gross: -0.00619 | Turnover: 1.6795 | TC: 0.001669 | Net: -0.00786\n",
      "  MSR  - Gross:  0.00014 | Turnover: 1.2047 | TC: 0.001205 | Net: -0.00106\n",
      "\n",
      "[42/112] Date: 2018-06-30 | Year: 2018\n",
      "  Window: 2003-06-30 to 2018-05-31\n",
      "  Yearly: 75 | Analyst: 133 | FinBERT: 7 | Union/Intersection: 19 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03836 | Turnover: 1.6641 | TC: 0.001728 | Net:  0.03663\n",
      "  MV   - Gross:  0.03704 | Turnover: 1.7398 | TC: 0.001804 | Net:  0.03524\n",
      "  MSR  - Gross:  0.02750 | Turnover: 1.4297 | TC: 0.001469 | Net:  0.02603\n",
      "\n",
      "[43/112] Date: 2018-07-31 | Year: 2018\n",
      "  Window: 2003-07-31 to 2018-06-30\n",
      "  Yearly: 75 | Analyst: 125 | FinBERT: 10 | Union/Intersection: 17 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01666 | Turnover: 1.6487 | TC: 0.001676 | Net:  0.01498\n",
      "  MV   - Gross:  0.01743 | Turnover: 1.6632 | TC: 0.001692 | Net:  0.01574\n",
      "  MSR  - Gross:  0.01339 | Turnover: 1.7696 | TC: 0.001793 | Net:  0.01160\n",
      "\n",
      "[44/112] Date: 2018-08-31 | Year: 2018\n",
      "  Window: 2003-08-31 to 2018-07-31\n",
      "  Yearly: 75 | Analyst: 73 | FinBERT: 8 | Union/Intersection: 9 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.03382 | Turnover: 1.6542 | TC: 0.001598 | Net: -0.03542\n",
      "  MV   - Gross: -0.03437 | Turnover: 1.6432 | TC: 0.001587 | Net: -0.03596\n",
      "  MSR  - Gross: -0.02297 | Turnover: 1.8689 | TC: 0.001826 | Net: -0.02479\n",
      "\n",
      "[45/112] Date: 2018-09-30 | Year: 2018\n",
      "  Window: 2003-09-30 to 2018-08-31\n",
      "  Yearly: 75 | Analyst: 116 | FinBERT: 9 | Union/Intersection: 24 | Assets w/ data: 10\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01014 | Turnover: 1.1110 | TC: 0.001100 | Net: -0.01124\n",
      "  MV   - Gross: -0.01494 | Turnover: 1.1078 | TC: 0.001091 | Net: -0.01604\n",
      "  MSR  - Gross: -0.05121 | Turnover: 1.1040 | TC: 0.001047 | Net: -0.05226\n",
      "\n",
      "[46/112] Date: 2018-10-31 | Year: 2018\n",
      "  Window: 2003-10-31 to 2018-09-30\n",
      "  Yearly: 75 | Analyst: 172 | FinBERT: 12 | Union/Intersection: 30 | Assets w/ data: 14\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.10335 | Turnover: 1.2911 | TC: 0.001158 | Net: -0.10451\n",
      "  MV   - Gross: -0.10334 | Turnover: 1.2395 | TC: 0.001111 | Net: -0.10445\n",
      "  MSR  - Gross: -0.10312 | Turnover: 0.9698 | TC: 0.000870 | Net: -0.10399\n",
      "\n",
      "[47/112] Date: 2018-11-30 | Year: 2018\n",
      "  Window: 2003-11-30 to 2018-10-31\n",
      "  Yearly: 75 | Analyst: 99 | FinBERT: 8 | Union/Intersection: 16 | Assets w/ data: 8\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.07482 | Turnover: 2.0274 | TC: 0.001876 | Net: -0.07670\n",
      "  MV   - Gross: -0.07973 | Turnover: 2.2375 | TC: 0.002059 | Net: -0.08179\n",
      "  MSR  - Gross: -0.06822 | Turnover: 1.7237 | TC: 0.001606 | Net: -0.06982\n",
      "\n",
      "[48/112] Date: 2018-12-31 | Year: 2018\n",
      "  Window: 2003-12-31 to 2018-11-30\n",
      "  Yearly: 75 | Analyst: 89 | FinBERT: 9 | Union/Intersection: 14 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.05713 | Turnover: 1.7906 | TC: 0.001893 | Net:  0.05524\n",
      "  MV   - Gross:  0.05198 | Turnover: 1.8961 | TC: 0.001995 | Net:  0.04998\n",
      "  MSR  - Gross:  0.06214 | Turnover: 1.9523 | TC: 0.002074 | Net:  0.06007\n",
      "\n",
      "[49/112] Date: 2019-01-31 | Year: 2019\n",
      "  Window: 2004-01-31 to 2018-12-31\n",
      "  Yearly: 269 | Analyst: 137 | FinBERT: 10 | Union/Intersection: 67 | Assets w/ data: 32\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04313 | Turnover: 1.9605 | TC: 0.002045 | Net:  0.04109\n",
      "  MV   - Gross:  0.04437 | Turnover: 2.0466 | TC: 0.002137 | Net:  0.04223\n",
      "  MSR  - Gross:  0.04714 | Turnover: 2.1465 | TC: 0.002248 | Net:  0.04489\n",
      "\n",
      "[50/112] Date: 2019-02-28 | Year: 2019\n",
      "  Window: 2004-02-29 to 2019-01-31\n",
      "  Yearly: 269 | Analyst: 103 | FinBERT: 17 | Union/Intersection: 49 | Assets w/ data: 20\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00029 | Turnover: 1.7521 | TC: 0.001752 | Net: -0.00204\n",
      "  MV   - Gross: -0.00366 | Turnover: 1.8129 | TC: 0.001806 | Net: -0.00547\n",
      "  MSR  - Gross:  0.01586 | Turnover: 1.7859 | TC: 0.001814 | Net:  0.01404\n",
      "\n",
      "[51/112] Date: 2019-03-31 | Year: 2019\n",
      "  Window: 2004-03-31 to 2019-02-28\n",
      "  Yearly: 269 | Analyst: 255 | FinBERT: 11 | Union/Intersection: 115 | Assets w/ data: 56\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02309 | Turnover: 2.1411 | TC: 0.002191 | Net:  0.02090\n",
      "  MV   - Gross:  0.02303 | Turnover: 2.1951 | TC: 0.002246 | Net:  0.02079\n",
      "  MSR  - Gross:  0.02572 | Turnover: 2.4762 | TC: 0.002540 | Net:  0.02318\n",
      "\n",
      "[52/112] Date: 2019-04-30 | Year: 2019\n",
      "  Window: 2004-04-30 to 2019-03-31\n",
      "  Yearly: 269 | Analyst: 160 | FinBERT: 11 | Union/Intersection: 62 | Assets w/ data: 31\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.03076 | Turnover: 1.8916 | TC: 0.001833 | Net: -0.03259\n",
      "  MV   - Gross: -0.03343 | Turnover: 1.9178 | TC: 0.001854 | Net: -0.03528\n",
      "  MSR  - Gross: -0.04228 | Turnover: 2.1824 | TC: 0.002090 | Net: -0.04437\n",
      "\n",
      "[53/112] Date: 2019-05-31 | Year: 2019\n",
      "  Window: 2004-05-31 to 2019-04-30\n",
      "  Yearly: 269 | Analyst: 99 | FinBERT: 12 | Union/Intersection: 44 | Assets w/ data: 15\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.05444 | Turnover: 2.0090 | TC: 0.002118 | Net:  0.05232\n",
      "  MV   - Gross:  0.05802 | Turnover: 1.9833 | TC: 0.002098 | Net:  0.05592\n",
      "  MSR  - Gross:  0.06773 | Turnover: 2.0532 | TC: 0.002192 | Net:  0.06554\n",
      "\n",
      "[54/112] Date: 2019-06-30 | Year: 2019\n",
      "  Window: 2004-06-30 to 2019-05-31\n",
      "  Yearly: 269 | Analyst: 104 | FinBERT: 7 | Union/Intersection: 41 | Assets w/ data: 21\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03118 | Turnover: 1.4416 | TC: 0.001487 | Net:  0.02970\n",
      "  MV   - Gross:  0.03547 | Turnover: 1.4264 | TC: 0.001477 | Net:  0.03399\n",
      "  MSR  - Gross:  0.04438 | Turnover: 1.4699 | TC: 0.001535 | Net:  0.04285\n",
      "\n",
      "[55/112] Date: 2019-07-31 | Year: 2019\n",
      "  Window: 2004-07-31 to 2019-06-30\n",
      "  Yearly: 269 | Analyst: 101 | FinBERT: 16 | Union/Intersection: 55 | Assets w/ data: 31\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00946 | Turnover: 1.8196 | TC: 0.001837 | Net:  0.00763\n",
      "  MV   - Gross:  0.00980 | Turnover: 1.8488 | TC: 0.001867 | Net:  0.00793\n",
      "  MSR  - Gross:  0.02454 | Turnover: 1.9440 | TC: 0.001992 | Net:  0.02255\n",
      "\n",
      "[56/112] Date: 2019-08-31 | Year: 2019\n",
      "  Window: 2004-08-31 to 2019-07-31\n",
      "  Yearly: 269 | Analyst: 86 | FinBERT: 14 | Union/Intersection: 38 | Assets w/ data: 18\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02519 | Turnover: 1.7663 | TC: 0.001811 | Net:  0.02338\n",
      "  MV   - Gross:  0.02825 | Turnover: 1.7596 | TC: 0.001809 | Net:  0.02644\n",
      "  MSR  - Gross:  0.01694 | Turnover: 2.0724 | TC: 0.002108 | Net:  0.01484\n",
      "\n",
      "[57/112] Date: 2019-09-30 | Year: 2019\n",
      "  Window: 2004-09-30 to 2019-08-31\n",
      "  Yearly: 269 | Analyst: 104 | FinBERT: 8 | Union/Intersection: 49 | Assets w/ data: 20\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00570 | Turnover: 2.0955 | TC: 0.002084 | Net: -0.00778\n",
      "  MV   - Gross: -0.00624 | Turnover: 2.0934 | TC: 0.002080 | Net: -0.00832\n",
      "  MSR  - Gross:  0.02742 | Turnover: 2.4613 | TC: 0.002529 | Net:  0.02489\n",
      "\n",
      "[58/112] Date: 2019-10-31 | Year: 2019\n",
      "  Window: 2004-10-31 to 2019-09-30\n",
      "  Yearly: 269 | Analyst: 90 | FinBERT: 14 | Union/Intersection: 44 | Assets w/ data: 24\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01530 | Turnover: 1.6389 | TC: 0.001664 | Net:  0.01363\n",
      "  MV   - Gross:  0.01419 | Turnover: 1.6427 | TC: 0.001666 | Net:  0.01252\n",
      "  MSR  - Gross:  0.01244 | Turnover: 1.6793 | TC: 0.001700 | Net:  0.01074\n",
      "\n",
      "[59/112] Date: 2019-11-30 | Year: 2019\n",
      "  Window: 2004-11-30 to 2019-10-31\n",
      "  Yearly: 269 | Analyst: 81 | FinBERT: 8 | Union/Intersection: 44 | Assets w/ data: 21\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02997 | Turnover: 2.0478 | TC: 0.002109 | Net:  0.02786\n",
      "  MV   - Gross:  0.02824 | Turnover: 2.0834 | TC: 0.002142 | Net:  0.02610\n",
      "  MSR  - Gross:  0.03767 | Turnover: 2.0001 | TC: 0.002075 | Net:  0.03560\n",
      "\n",
      "[60/112] Date: 2019-12-31 | Year: 2019\n",
      "  Window: 2004-12-31 to 2019-11-30\n",
      "  Yearly: 269 | Analyst: 97 | FinBERT: 10 | Union/Intersection: 48 | Assets w/ data: 26\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00457 | Turnover: 1.9447 | TC: 0.001954 | Net:  0.00262\n",
      "  MV   - Gross:  0.00872 | Turnover: 1.9917 | TC: 0.002009 | Net:  0.00671\n",
      "  MSR  - Gross:  0.03050 | Turnover: 2.1460 | TC: 0.002211 | Net:  0.02829\n",
      "\n",
      "[61/112] Date: 2020-01-31 | Year: 2020\n",
      "  Window: 2005-01-31 to 2019-12-31\n",
      "  Yearly: 40 | Analyst: 94 | FinBERT: 8 | Union/Intersection: 14 | Assets w/ data: 12\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.10750 | Turnover: 2.1920 | TC: 0.001956 | Net: -0.10946\n",
      "  MV   - Gross: -0.10996 | Turnover: 2.3289 | TC: 0.002073 | Net: -0.11203\n",
      "  MSR  - Gross: -0.11229 | Turnover: 2.6411 | TC: 0.002345 | Net: -0.11463\n",
      "\n",
      "[62/112] Date: 2020-02-29 | Year: 2020\n",
      "  Window: 2005-02-28 to 2020-01-31\n",
      "  Yearly: 40 | Analyst: 81 | FinBERT: 10 | Union/Intersection: 5 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.19806 | Turnover: 1.8590 | TC: 0.001491 | Net: -0.19955\n",
      "  MV   - Gross: -0.22405 | Turnover: 2.2292 | TC: 0.001730 | Net: -0.22578\n",
      "  MSR  - Gross: -0.20062 | Turnover: 2.0625 | TC: 0.001649 | Net: -0.20227\n",
      "\n",
      "[63/112] Date: 2020-03-31 | Year: 2020\n",
      "  Window: 2005-03-31 to 2020-02-29\n",
      "  Yearly: 40 | Analyst: 202 | FinBERT: 14 | Union/Intersection: 23 | Assets w/ data: 16\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.09613 | Turnover: 1.4115 | TC: 0.001547 | Net:  0.09458\n",
      "  MV   - Gross: -0.00084 | Turnover: 2.2526 | TC: 0.002251 | Net: -0.00309\n",
      "  MSR  - Gross:  0.06358 | Turnover: 1.4274 | TC: 0.001518 | Net:  0.06206\n",
      "\n",
      "[64/112] Date: 2020-04-30 | Year: 2020\n",
      "  Window: 2005-04-30 to 2020-03-31\n",
      "  Yearly: 40 | Analyst: 220 | FinBERT: 10 | Union/Intersection: 22 | Assets w/ data: 17\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01733 | Turnover: 1.1240 | TC: 0.001143 | Net:  0.01619\n",
      "  MV   - Gross:  0.01996 | Turnover: 2.0609 | TC: 0.002102 | Net:  0.01786\n",
      "  MSR  - Gross:  0.01878 | Turnover: 1.2747 | TC: 0.001299 | Net:  0.01748\n",
      "\n",
      "[65/112] Date: 2020-05-31 | Year: 2020\n",
      "  Window: 2005-05-31 to 2020-04-30\n",
      "  Yearly: 40 | Analyst: 132 | FinBERT: 8 | Union/Intersection: 6 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00023 | Turnover: 1.8803 | TC: 0.001881 | Net: -0.00165\n",
      "  MV   - Gross: -0.03037 | Turnover: 2.3242 | TC: 0.002254 | Net: -0.03263\n",
      "  MSR  - Gross: -0.02937 | Turnover: 2.2123 | TC: 0.002147 | Net: -0.03152\n",
      "\n",
      "[66/112] Date: 2020-06-30 | Year: 2020\n",
      "  Window: 2005-06-30 to 2020-05-31\n",
      "  Yearly: 40 | Analyst: 115 | FinBERT: 7 | Union/Intersection: 9 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.05283 | Turnover: 1.9050 | TC: 0.002006 | Net:  0.05082\n",
      "  MV   - Gross:  0.06203 | Turnover: 2.3710 | TC: 0.002518 | Net:  0.05951\n",
      "  MSR  - Gross:  0.05890 | Turnover: 2.2005 | TC: 0.002330 | Net:  0.05657\n",
      "\n",
      "[67/112] Date: 2020-07-31 | Year: 2020\n",
      "  Window: 2005-07-31 to 2020-06-30\n",
      "  Yearly: 40 | Analyst: 147 | FinBERT: 4 | Union/Intersection: 13 | Assets w/ data: 10\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04428 | Turnover: 1.8831 | TC: 0.001967 | Net:  0.04231\n",
      "  MV   - Gross:  0.04865 | Turnover: 2.5942 | TC: 0.002720 | Net:  0.04593\n",
      "  MSR  - Gross:  0.05010 | Turnover: 2.7428 | TC: 0.002880 | Net:  0.04721\n",
      "\n",
      "[68/112] Date: 2020-08-31 | Year: 2020\n",
      "  Window: 2005-08-31 to 2020-07-31\n",
      "  Yearly: 40 | Analyst: 69 | FinBERT: 12 | Union/Intersection: 5 | Assets w/ data: 2\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07751 | Turnover: 2.0676 | TC: 0.002228 | Net:  0.07528\n",
      "  MV   - Gross:  0.03183 | Turnover: 2.8200 | TC: 0.002910 | Net:  0.02892\n",
      "  MSR  - Gross:  0.07288 | Turnover: 2.7218 | TC: 0.002920 | Net:  0.06996\n",
      "\n",
      "[69/112] Date: 2020-09-30 | Year: 2020\n",
      "  Window: 2005-09-30 to 2020-08-31\n",
      "  Yearly: 40 | Analyst: 121 | FinBERT: 17 | Union/Intersection: 18 | Assets w/ data: 8\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00763 | Turnover: 2.0436 | TC: 0.002059 | Net:  0.00557\n",
      "  MV   - Gross: -0.02966 | Turnover: 2.4496 | TC: 0.002377 | Net: -0.03204\n",
      "  MSR  - Gross: -0.03191 | Turnover: 2.0713 | TC: 0.002005 | Net: -0.03392\n",
      "\n",
      "[70/112] Date: 2020-10-31 | Year: 2020\n",
      "  Window: 2005-10-31 to 2020-09-30\n",
      "  Yearly: 40 | Analyst: 103 | FinBERT: 7 | Union/Intersection: 4 | Assets w/ data: 2\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00648 | Turnover: 2.0477 | TC: 0.002034 | Net: -0.00852\n",
      "  MV   - Gross: -0.01839 | Turnover: 2.1011 | TC: 0.002063 | Net: -0.02045\n",
      "  MSR  - Gross: -0.01075 | Turnover: 2.0919 | TC: 0.002069 | Net: -0.01282\n",
      "\n",
      "[71/112] Date: 2020-11-30 | Year: 2020\n",
      "  Window: 2005-11-30 to 2020-10-31\n",
      "  Yearly: 40 | Analyst: 118 | FinBERT: 7 | Union/Intersection: 14 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01738 | Turnover: 2.0237 | TC: 0.002059 | Net:  0.01532\n",
      "  MV   - Gross:  0.00616 | Turnover: 2.2418 | TC: 0.002256 | Net:  0.00390\n",
      "  MSR  - Gross:  0.00072 | Turnover: 2.2816 | TC: 0.002283 | Net: -0.00156\n",
      "\n",
      "[72/112] Date: 2020-12-31 | Year: 2020\n",
      "  Window: 2005-12-31 to 2020-11-30\n",
      "  Yearly: 40 | Analyst: 84 | FinBERT: 7 | Union/Intersection: 8 | Assets w/ data: 4\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04673 | Turnover: 1.9678 | TC: 0.002060 | Net:  0.04467\n",
      "  MV   - Gross:  0.01986 | Turnover: 3.2158 | TC: 0.003280 | Net:  0.01658\n",
      "  MSR  - Gross:  0.04151 | Turnover: 2.3441 | TC: 0.002441 | Net:  0.03907\n",
      "\n",
      "[73/112] Date: 2021-01-31 | Year: 2021\n",
      "  Window: 2006-01-31 to 2020-12-31\n",
      "  Yearly: 123 | Analyst: 123 | FinBERT: 8 | Union/Intersection: 34 | Assets w/ data: 22\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02475 | Turnover: 2.2625 | TC: 0.002319 | Net:  0.02243\n",
      "  MV   - Gross: -0.02313 | Turnover: 3.5845 | TC: 0.003502 | Net: -0.02663\n",
      "  MSR  - Gross: -0.04573 | Turnover: 2.8142 | TC: 0.002685 | Net: -0.04842\n",
      "\n",
      "[74/112] Date: 2021-02-28 | Year: 2021\n",
      "  Window: 2006-02-28 to 2021-01-31\n",
      "  Yearly: 123 | Analyst: 92 | FinBERT: 15 | Union/Intersection: 34 | Assets w/ data: 21\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.08171 | Turnover: 1.6257 | TC: 0.001759 | Net:  0.07995\n",
      "  MV   - Gross:  0.08120 | Turnover: 1.9525 | TC: 0.002111 | Net:  0.07909\n",
      "  MSR  - Gross:  0.07739 | Turnover: 2.7118 | TC: 0.002922 | Net:  0.07447\n",
      "\n",
      "[75/112] Date: 2021-03-31 | Year: 2021\n",
      "  Window: 2006-03-31 to 2021-02-28\n",
      "  Yearly: 123 | Analyst: 107 | FinBERT: 11 | Union/Intersection: 22 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07414 | Turnover: 1.6029 | TC: 0.001722 | Net:  0.07241\n",
      "  MV   - Gross:  0.06761 | Turnover: 1.7254 | TC: 0.001842 | Net:  0.06577\n",
      "  MSR  - Gross:  0.05843 | Turnover: 2.0882 | TC: 0.002210 | Net:  0.05622\n",
      "\n",
      "[76/112] Date: 2021-04-30 | Year: 2021\n",
      "  Window: 2006-04-30 to 2021-03-31\n",
      "  Yearly: 123 | Analyst: 115 | FinBERT: 15 | Union/Intersection: 28 | Assets w/ data: 18\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.02381 | Turnover: 1.6975 | TC: 0.001738 | Net:  0.02207\n",
      "  MV   - Gross:  0.03011 | Turnover: 1.7950 | TC: 0.001849 | Net:  0.02827\n",
      "  MSR  - Gross:  0.00889 | Turnover: 2.5791 | TC: 0.002602 | Net:  0.00629\n",
      "\n",
      "[77/112] Date: 2021-05-31 | Year: 2021\n",
      "  Window: 2006-05-31 to 2021-04-30\n",
      "  Yearly: 123 | Analyst: 96 | FinBERT: 9 | Union/Intersection: 19 | Assets w/ data: 13\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01550 | Turnover: 2.2495 | TC: 0.002215 | Net: -0.01772\n",
      "  MV   - Gross: -0.01377 | Turnover: 2.2424 | TC: 0.002212 | Net: -0.01598\n",
      "  MSR  - Gross: -0.00804 | Turnover: 2.6269 | TC: 0.002606 | Net: -0.01065\n",
      "\n",
      "[78/112] Date: 2021-06-30 | Year: 2021\n",
      "  Window: 2006-06-30 to 2021-05-31\n",
      "  Yearly: 123 | Analyst: 108 | FinBERT: 13 | Union/Intersection: 28 | Assets w/ data: 14\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04026 | Turnover: 1.9986 | TC: 0.002079 | Net:  0.03818\n",
      "  MV   - Gross:  0.03254 | Turnover: 2.0777 | TC: 0.002145 | Net:  0.03039\n",
      "  MSR  - Gross:  0.06066 | Turnover: 2.3532 | TC: 0.002496 | Net:  0.05816\n",
      "\n",
      "[79/112] Date: 2021-07-31 | Year: 2021\n",
      "  Window: 2006-07-31 to 2021-06-30\n",
      "  Yearly: 123 | Analyst: 85 | FinBERT: 11 | Union/Intersection: 20 | Assets w/ data: 13\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00871 | Turnover: 1.4739 | TC: 0.001461 | Net: -0.01017\n",
      "  MV   - Gross: -0.00155 | Turnover: 1.5748 | TC: 0.001572 | Net: -0.00312\n",
      "  MSR  - Gross: -0.01478 | Turnover: 1.4714 | TC: 0.001450 | Net: -0.01623\n",
      "\n",
      "[80/112] Date: 2021-08-31 | Year: 2021\n",
      "  Window: 2006-08-31 to 2021-07-31\n",
      "  Yearly: 123 | Analyst: 68 | FinBERT: 11 | Union/Intersection: 19 | Assets w/ data: 16\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00549 | Turnover: 1.7263 | TC: 0.001717 | Net: -0.00721\n",
      "  MV   - Gross: -0.00726 | Turnover: 1.9386 | TC: 0.001924 | Net: -0.00918\n",
      "  MSR  - Gross: -0.00083 | Turnover: 1.6857 | TC: 0.001684 | Net: -0.00251\n",
      "\n",
      "[81/112] Date: 2021-09-30 | Year: 2021\n",
      "  Window: 2006-09-30 to 2021-08-31\n",
      "  Yearly: 123 | Analyst: 87 | FinBERT: 12 | Union/Intersection: 19 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03454 | Turnover: 1.2501 | TC: 0.001293 | Net:  0.03324\n",
      "  MV   - Gross:  0.03878 | Turnover: 1.2685 | TC: 0.001318 | Net:  0.03746\n",
      "  MSR  - Gross:  0.02620 | Turnover: 1.4520 | TC: 0.001490 | Net:  0.02471\n",
      "\n",
      "[82/112] Date: 2021-10-31 | Year: 2021\n",
      "  Window: 2006-10-31 to 2021-09-30\n",
      "  Yearly: 123 | Analyst: 150 | FinBERT: 12 | Union/Intersection: 35 | Assets w/ data: 22\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01692 | Turnover: 2.1221 | TC: 0.002086 | Net: -0.01900\n",
      "  MV   - Gross: -0.01823 | Turnover: 2.1665 | TC: 0.002127 | Net: -0.02035\n",
      "  MSR  - Gross: -0.00343 | Turnover: 2.5034 | TC: 0.002495 | Net: -0.00592\n",
      "\n",
      "[83/112] Date: 2021-11-30 | Year: 2021\n",
      "  Window: 2006-11-30 to 2021-10-31\n",
      "  Yearly: 123 | Analyst: 109 | FinBERT: 9 | Union/Intersection: 27 | Assets w/ data: 19\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.06199 | Turnover: 1.4542 | TC: 0.001544 | Net:  0.06045\n",
      "  MV   - Gross:  0.07250 | Turnover: 1.7806 | TC: 0.001910 | Net:  0.07059\n",
      "  MSR  - Gross:  0.07944 | Turnover: 2.2340 | TC: 0.002411 | Net:  0.07703\n",
      "\n",
      "[84/112] Date: 2021-12-31 | Year: 2021\n",
      "  Window: 2006-12-31 to 2021-11-30\n",
      "  Yearly: 123 | Analyst: 66 | FinBERT: 8 | Union/Intersection: 15 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01913 | Turnover: 2.0464 | TC: 0.002007 | Net: -0.02113\n",
      "  MV   - Gross:  0.02051 | Turnover: 2.2020 | TC: 0.002247 | Net:  0.01826\n",
      "  MSR  - Gross: -0.05741 | Turnover: 2.5202 | TC: 0.002376 | Net: -0.05979\n",
      "\n",
      "[85/112] Date: 2022-01-31 | Year: 2022\n",
      "  Window: 2007-01-31 to 2021-12-31\n",
      "  Yearly: 34 | Analyst: 117 | FinBERT: 29 | Union/Intersection: 18 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01890 | Turnover: 1.9812 | TC: 0.001944 | Net: -0.02085\n",
      "  MV   - Gross: -0.01481 | Turnover: 2.0883 | TC: 0.002057 | Net: -0.01686\n",
      "  MSR  - Gross: -0.03368 | Turnover: 2.0270 | TC: 0.001959 | Net: -0.03564\n",
      "\n",
      "[86/112] Date: 2022-02-28 | Year: 2022\n",
      "  Window: 2007-02-28 to 2022-01-31\n",
      "  Yearly: 34 | Analyst: 103 | FinBERT: 15 | Union/Intersection: 16 | Assets w/ data: 10\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.05971 | Turnover: 1.0240 | TC: 0.001085 | Net:  0.05862\n",
      "  MV   - Gross:  0.06034 | Turnover: 1.0345 | TC: 0.001097 | Net:  0.05924\n",
      "  MSR  - Gross:  0.03989 | Turnover: 0.9817 | TC: 0.001021 | Net:  0.03887\n",
      "\n",
      "[87/112] Date: 2022-03-31 | Year: 2022\n",
      "  Window: 2007-03-31 to 2022-02-28\n",
      "  Yearly: 34 | Analyst: 95 | FinBERT: 16 | Union/Intersection: 12 | Assets w/ data: 8\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.05161 | Turnover: 1.4838 | TC: 0.001407 | Net: -0.05302\n",
      "  MV   - Gross: -0.04285 | Turnover: 1.4869 | TC: 0.001423 | Net: -0.04427\n",
      "  MSR  - Gross: -0.07089 | Turnover: 1.5023 | TC: 0.001396 | Net: -0.07229\n",
      "\n",
      "[88/112] Date: 2022-04-30 | Year: 2022\n",
      "  Window: 2007-04-30 to 2022-03-31\n",
      "  Yearly: 34 | Analyst: 106 | FinBERT: 19 | Union/Intersection: 14 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07311 | Turnover: 1.5181 | TC: 0.001629 | Net:  0.07148\n",
      "  MV   - Gross:  0.06831 | Turnover: 1.5776 | TC: 0.001685 | Net:  0.06662\n",
      "  MSR  - Gross:  0.05452 | Turnover: 1.3060 | TC: 0.001377 | Net:  0.05314\n",
      "\n",
      "[89/112] Date: 2022-05-31 | Year: 2022\n",
      "  Window: 2007-05-31 to 2022-04-30\n",
      "  Yearly: 34 | Analyst: 82 | FinBERT: 10 | Union/Intersection: 8 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02430 | Turnover: 1.2809 | TC: 0.001250 | Net: -0.02555\n",
      "  MV   - Gross: -0.02515 | Turnover: 1.2899 | TC: 0.001257 | Net: -0.02641\n",
      "  MSR  - Gross: -0.04761 | Turnover: 1.3161 | TC: 0.001253 | Net: -0.04886\n",
      "\n",
      "[90/112] Date: 2022-06-30 | Year: 2022\n",
      "  Window: 2007-06-30 to 2022-05-31\n",
      "  Yearly: 34 | Analyst: 98 | FinBERT: 11 | Union/Intersection: 12 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.06366 | Turnover: 2.0000 | TC: 0.002127 | Net:  0.06154\n",
      "  MV   - Gross:  0.06361 | Turnover: 2.0000 | TC: 0.002127 | Net:  0.06148\n",
      "  MSR  - Gross:  0.06468 | Turnover: 2.0000 | TC: 0.002129 | Net:  0.06255\n",
      "\n",
      "[91/112] Date: 2022-07-31 | Year: 2022\n",
      "  Window: 2007-07-31 to 2022-06-30\n",
      "  Yearly: 34 | Analyst: 104 | FinBERT: 24 | Union/Intersection: 16 | Assets w/ data: 9\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.06584 | Turnover: 1.7477 | TC: 0.001633 | Net: -0.06747\n",
      "  MV   - Gross: -0.07080 | Turnover: 1.5728 | TC: 0.001461 | Net: -0.07226\n",
      "  MSR  - Gross: -0.07913 | Turnover: 1.7302 | TC: 0.001593 | Net: -0.08073\n",
      "\n",
      "[92/112] Date: 2022-08-31 | Year: 2022\n",
      "  Window: 2007-08-31 to 2022-07-31\n",
      "  Yearly: 34 | Analyst: 82 | FinBERT: 12 | Union/Intersection: 7 | Assets w/ data: 5\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01777 | Turnover: 1.8410 | TC: 0.001808 | Net: -0.01957\n",
      "  MV   - Gross:  0.07123 | Turnover: 2.4998 | TC: 0.002678 | Net:  0.06856\n",
      "  MSR  - Gross: -0.03348 | Turnover: 1.7877 | TC: 0.001728 | Net: -0.03521\n",
      "\n",
      "[93/112] Date: 2022-09-30 | Year: 2022\n",
      "  Window: 2007-09-30 to 2022-08-31\n",
      "  Yearly: 34 | Analyst: 82 | FinBERT: 19 | Union/Intersection: 10 | Assets w/ data: 7\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.06147 | Turnover: 1.4155 | TC: 0.001503 | Net:  0.05997\n",
      "  MV   - Gross:  0.05941 | Turnover: 2.4406 | TC: 0.002586 | Net:  0.05683\n",
      "  MSR  - Gross:  0.06232 | Turnover: 1.3320 | TC: 0.001415 | Net:  0.06091\n",
      "\n",
      "[94/112] Date: 2022-10-31 | Year: 2022\n",
      "  Window: 2007-10-31 to 2022-09-30\n",
      "  Yearly: 34 | Analyst: 96 | FinBERT: 25 | Union/Intersection: 17 | Assets w/ data: 10\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03957 | Turnover: 1.6467 | TC: 0.001712 | Net:  0.03785\n",
      "  MV   - Gross:  0.04041 | Turnover: 2.0008 | TC: 0.002082 | Net:  0.03833\n",
      "  MSR  - Gross:  0.02617 | Turnover: 1.4240 | TC: 0.001461 | Net:  0.02471\n",
      "\n",
      "[95/112] Date: 2022-11-30 | Year: 2022\n",
      "  Window: 2007-11-30 to 2022-10-31\n",
      "  Yearly: 34 | Analyst: 81 | FinBERT: 25 | Union/Intersection: 11 | Assets w/ data: 8\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.04736 | Turnover: 1.7802 | TC: 0.001696 | Net: -0.04905\n",
      "  MV   - Gross: -0.04408 | Turnover: 2.0333 | TC: 0.001944 | Net: -0.04602\n",
      "  MSR  - Gross: -0.04996 | Turnover: 1.6491 | TC: 0.001567 | Net: -0.05153\n",
      "\n",
      "[96/112] Date: 2022-12-31 | Year: 2022\n",
      "  Window: 2007-12-31 to 2022-11-30\n",
      "  Yearly: 34 | Analyst: 53 | FinBERT: 9 | Union/Intersection: 7 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.06986 | Turnover: 1.8596 | TC: 0.001990 | Net:  0.06787\n",
      "  MV   - Gross:  0.07654 | Turnover: 1.9931 | TC: 0.002146 | Net:  0.07440\n",
      "  MSR  - Gross:  0.02188 | Turnover: 1.9872 | TC: 0.002031 | Net:  0.01985\n",
      "\n",
      "[97/112] Date: 2023-01-31 | Year: 2023\n",
      "  Window: 2008-01-31 to 2022-12-31\n",
      "  Yearly: 137 | Analyst: 102 | FinBERT: 23 | Union/Intersection: 32 | Assets w/ data: 15\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.02442 | Turnover: 2.1011 | TC: 0.002050 | Net: -0.02647\n",
      "  MV   - Gross: -0.03702 | Turnover: 2.0988 | TC: 0.002021 | Net: -0.03904\n",
      "  MSR  - Gross: -0.05674 | Turnover: 2.5819 | TC: 0.002435 | Net: -0.05918\n",
      "\n",
      "[98/112] Date: 2023-02-28 | Year: 2023\n",
      "  Window: 2008-02-29 to 2023-01-31\n",
      "  Yearly: 137 | Analyst: 107 | FinBERT: 23 | Union/Intersection: 30 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.01419 | Turnover: 2.0280 | TC: 0.001999 | Net: -0.01619\n",
      "  MV   - Gross: -0.01058 | Turnover: 2.0693 | TC: 0.002047 | Net: -0.01263\n",
      "  MSR  - Gross:  0.00674 | Turnover: 2.6290 | TC: 0.002647 | Net:  0.00409\n",
      "\n",
      "[99/112] Date: 2023-03-31 | Year: 2023\n",
      "  Window: 2008-03-31 to 2023-02-28\n",
      "  Yearly: 137 | Analyst: 73 | FinBERT: 20 | Union/Intersection: 24 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.00475 | Turnover: 1.7197 | TC: 0.001728 | Net:  0.00302\n",
      "  MV   - Gross:  0.00365 | Turnover: 1.7835 | TC: 0.001790 | Net:  0.00186\n",
      "  MSR  - Gross:  0.01286 | Turnover: 1.6122 | TC: 0.001633 | Net:  0.01123\n",
      "\n",
      "[100/112] Date: 2023-04-30 | Year: 2023\n",
      "  Window: 2008-04-30 to 2023-03-31\n",
      "  Yearly: 137 | Analyst: 93 | FinBERT: 23 | Union/Intersection: 25 | Assets w/ data: 6\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.07951 | Turnover: 2.0583 | TC: 0.001895 | Net: -0.08140\n",
      "  MV   - Gross: -0.04604 | Turnover: 2.0637 | TC: 0.001969 | Net: -0.04801\n",
      "  MSR  - Gross: -0.11527 | Turnover: 2.2582 | TC: 0.001998 | Net: -0.11727\n",
      "\n",
      "[101/112] Date: 2023-05-31 | Year: 2023\n",
      "  Window: 2008-05-31 to 2023-04-30\n",
      "  Yearly: 137 | Analyst: 73 | FinBERT: 20 | Union/Intersection: 22 | Assets w/ data: 11\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07112 | Turnover: 2.1350 | TC: 0.002287 | Net:  0.06883\n",
      "  MV   - Gross:  0.09524 | Turnover: 2.0462 | TC: 0.002241 | Net:  0.09300\n",
      "  MSR  - Gross: -0.01095 | Turnover: 2.4605 | TC: 0.002434 | Net: -0.01338\n",
      "\n",
      "[102/112] Date: 2023-06-30 | Year: 2023\n",
      "  Window: 2008-06-30 to 2023-05-31\n",
      "  Yearly: 137 | Analyst: 70 | FinBERT: 25 | Union/Intersection: 28 | Assets w/ data: 16\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03353 | Turnover: 2.0232 | TC: 0.002091 | Net:  0.03144\n",
      "  MV   - Gross:  0.03371 | Turnover: 2.0310 | TC: 0.002099 | Net:  0.03161\n",
      "  MSR  - Gross:  0.03333 | Turnover: 2.4797 | TC: 0.002562 | Net:  0.03077\n",
      "\n",
      "[103/112] Date: 2023-07-31 | Year: 2023\n",
      "  Window: 2008-07-31 to 2023-06-30\n",
      "  Yearly: 137 | Analyst: 87 | FinBERT: 32 | Union/Intersection: 33 | Assets w/ data: 17\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.04219 | Turnover: 1.0156 | TC: 0.000973 | Net: -0.04316\n",
      "  MV   - Gross: -0.05198 | Turnover: 1.1279 | TC: 0.001069 | Net: -0.05305\n",
      "  MSR  - Gross: -0.02375 | Turnover: 1.2401 | TC: 0.001211 | Net: -0.02496\n",
      "\n",
      "[104/112] Date: 2023-08-31 | Year: 2023\n",
      "  Window: 2008-08-31 to 2023-07-31\n",
      "  Yearly: 137 | Analyst: 97 | FinBERT: 29 | Union/Intersection: 38 | Assets w/ data: 17\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.03860 | Turnover: 0.9780 | TC: 0.000940 | Net: -0.03954\n",
      "  MV   - Gross: -0.03420 | Turnover: 1.0550 | TC: 0.001019 | Net: -0.03522\n",
      "  MSR  - Gross: -0.06127 | Turnover: 1.1631 | TC: 0.001092 | Net: -0.06236\n",
      "\n",
      "[105/112] Date: 2023-09-30 | Year: 2023\n",
      "  Window: 2008-09-30 to 2023-08-31\n",
      "  Yearly: 137 | Analyst: 86 | FinBERT: 27 | Union/Intersection: 34 | Assets w/ data: 16\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00428 | Turnover: 2.0122 | TC: 0.002004 | Net: -0.00628\n",
      "  MV   - Gross: -0.00276 | Turnover: 2.0940 | TC: 0.002088 | Net: -0.00485\n",
      "  MSR  - Gross: -0.01516 | Turnover: 1.8908 | TC: 0.001862 | Net: -0.01702\n",
      "\n",
      "[106/112] Date: 2023-10-31 | Year: 2023\n",
      "  Window: 2008-10-31 to 2023-09-30\n",
      "  Yearly: 137 | Analyst: 118 | FinBERT: 31 | Union/Intersection: 41 | Assets w/ data: 21\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07396 | Turnover: 1.8538 | TC: 0.001991 | Net:  0.07197\n",
      "  MV   - Gross:  0.06873 | Turnover: 1.8856 | TC: 0.002015 | Net:  0.06671\n",
      "  MSR  - Gross:  0.08233 | Turnover: 2.0002 | TC: 0.002165 | Net:  0.08017\n",
      "\n",
      "[107/112] Date: 2023-11-30 | Year: 2023\n",
      "  Window: 2008-11-30 to 2023-10-31\n",
      "  Yearly: 137 | Analyst: 92 | FinBERT: 35 | Union/Intersection: 39 | Assets w/ data: 20\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.03449 | Turnover: 1.3087 | TC: 0.001354 | Net:  0.03314\n",
      "  MV   - Gross:  0.03892 | Turnover: 1.5294 | TC: 0.001589 | Net:  0.03733\n",
      "  MSR  - Gross:  0.02937 | Turnover: 1.2972 | TC: 0.001335 | Net:  0.02804\n",
      "\n",
      "[108/112] Date: 2023-12-31 | Year: 2023\n",
      "  Window: 2008-12-31 to 2023-11-30\n",
      "  Yearly: 137 | Analyst: 90 | FinBERT: 36 | Union/Intersection: 32 | Assets w/ data: 16\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.00463 | Turnover: 1.6347 | TC: 0.001627 | Net: -0.00625\n",
      "  MV   - Gross: -0.03237 | Turnover: 1.8094 | TC: 0.001751 | Net: -0.03412\n",
      "  MSR  - Gross:  0.02263 | Turnover: 1.7661 | TC: 0.001806 | Net:  0.02082\n",
      "\n",
      "[109/112] Date: 2024-01-31 | Year: 2024\n",
      "  Window: 2009-01-31 to 2023-12-31\n",
      "  Yearly: 281 | Analyst: 110 | FinBERT: 49 | Union/Intersection: 71 | Assets w/ data: 46\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.01156 | Turnover: 2.0284 | TC: 0.002052 | Net:  0.00951\n",
      "  MV   - Gross:  0.00471 | Turnover: 2.3430 | TC: 0.002354 | Net:  0.00235\n",
      "  MSR  - Gross:  0.03901 | Turnover: 2.6222 | TC: 0.002725 | Net:  0.03628\n",
      "\n",
      "[110/112] Date: 2024-02-29 | Year: 2024\n",
      "  Window: 2009-02-28 to 2024-01-31\n",
      "  Yearly: 281 | Analyst: 119 | FinBERT: 28 | Union/Intersection: 72 | Assets w/ data: 44\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.04389 | Turnover: 1.5813 | TC: 0.001651 | Net:  0.04224\n",
      "  MV   - Gross:  0.04330 | Turnover: 1.5597 | TC: 0.001627 | Net:  0.04167\n",
      "  MSR  - Gross:  0.04757 | Turnover: 2.2754 | TC: 0.002384 | Net:  0.04519\n",
      "\n",
      "[111/112] Date: 2024-03-31 | Year: 2024\n",
      "  Window: 2009-03-31 to 2024-02-29\n",
      "  Yearly: 281 | Analyst: 73 | FinBERT: 32 | Union/Intersection: 54 | Assets w/ data: 38\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross: -0.04219 | Turnover: 1.2905 | TC: 0.001236 | Net: -0.04342\n",
      "  MV   - Gross: -0.04531 | Turnover: 1.3346 | TC: 0.001274 | Net: -0.04659\n",
      "  MSR  - Gross: -0.03519 | Turnover: 1.9138 | TC: 0.001846 | Net: -0.03703\n",
      "\n",
      "[112/112] Date: 2024-04-30 | Year: 2024\n",
      "  Window: 2009-04-30 to 2024-03-31\n",
      "  Yearly: 281 | Analyst: 99 | FinBERT: 42 | Union/Intersection: 64 | Assets w/ data: 36\n",
      "  Running Deep Learning Regression...\n",
      "2.5\n",
      "  Computing GMV weights...\n",
      "  Computing MV weights...\n",
      "  Computing MSR weights...\n",
      "  GMV  - Gross:  0.07089 | Turnover: 1.8804 | TC: 0.002014 | Net:  0.06887\n",
      "  MV   - Gross:  0.06842 | Turnover: 2.0853 | TC: 0.002228 | Net:  0.06620\n",
      "  MSR  - Gross:  0.07558 | Turnover: 2.2107 | TC: 0.002378 | Net:  0.07320\n",
      "\n",
      "============================================================\n",
      "BACKTEST COMPLETE\n",
      "============================================================\n",
      "\n",
      " GMV\n",
      "\n",
      "Sharpe Ratio: 0.1212\n",
      "Annualized Sharpe Ratio: 0.4200\n",
      "Total Return: 0.6548\n",
      "Average Turnover: 1.6766\n",
      "\n",
      " MV\n",
      "\n",
      "Sharpe Ratio: 0.0284\n",
      "Annualized Sharpe Ratio: 0.0983\n",
      "Total Return: 0.0107\n",
      "Average Turnover: 2.0509\n",
      "\n",
      " MSR\n",
      "\n",
      "Sharpe Ratio: 0.0540\n",
      "Annualized Sharpe Ratio: 0.1869\n",
      "Total Return: 0.1717\n",
      "Average Turnover: 1.8557\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../green cleaned.csv', dtype={'ncusip': 'string'})\n",
    "df['ret_fwd_1'] = df.groupby('permno')['ret_excess'].shift(-1)\n",
    "\n",
    "data_f=pd.read_csv('F-F_Research_Data_Factors.csv',sep=',')\n",
    "data_f['Date']=pd.to_datetime(data_f['Date'], format=\"%Y%m\")\n",
    "data_f['Date']=data_f['Date']+pd.offsets.MonthEnd(0)\n",
    "data_f = data_f.set_index('Date')\n",
    "data_f = data_f[['Mkt-RF', 'SMB', 'HML', 'RF']].astype(float)\n",
    "\n",
    "# Run backtest with yearly signals\n",
    "results_df, metrics, results_df_2, metrics_2, results_df_3, metrics_3= backtest_dnn_yearly(\n",
    "    df,\n",
    "    test_start_date='2015-01-31',\n",
    "    test_end_date='2024-04-30',\n",
    "    lookback_window=180,\n",
    "    transaction_cost=0.001,\n",
    "    buys_path_template='buys_{}.csv',\n",
    "    sells_path_template='sells_{}.csv',\n",
    "    analyst_rec_path='../examples/monthly_mean_recommendations_decay.csv',\n",
    "    finbert_signals_path='../examples/monthly_signals_decay.csv',  # Your FinBERT signals\n",
    "    data_factor=data_f,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\n GMV\")\n",
    "print(f\"\\nSharpe Ratio: {metrics['sharpe_ratio']:.4f}\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Total Return: {metrics['total_return']:.4f}\")\n",
    "print(f\"Average Turnover: {metrics['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MV\")\n",
    "print(f\"\\nSharpe Ratio: {metrics_2['sharpe_ratio']:.4f}\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics_2['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Total Return: {metrics_2['total_return']:.4f}\")\n",
    "print(f\"Average Turnover: {metrics_2['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MSR\")\n",
    "print(f\"\\nSharpe Ratio: {metrics_3['sharpe_ratio']:.4f}\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics_3['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Total Return: {metrics_3['total_return']:.4f}\")\n",
    "print(f\"Average Turnover: {metrics_3['avg_turnover']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df58028-b81e-4987-92a9-52cb828f89f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " GMV\n",
      "Annualized Sharpe Ratio: 0.4200\n",
      "Mean Return: 0.0671\n",
      "Variance: 0.0255\n",
      "Avg Turnover: 1.6766\n",
      "\n",
      " MV\n",
      "Annualized Sharpe Ratio: 0.0983\n",
      "Mean Return: 0.0174\n",
      "Variance: 0.0315\n",
      "Avg Turnover: 2.0509\n",
      "\n",
      " MSR\n",
      "Annualized Sharpe Ratio: 0.1869\n",
      "Mean Return: 0.0317\n",
      "Variance: 0.0287\n",
      "Avg Turnover: 1.8557\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n GMV\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {metrics['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {metrics['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {metrics['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MV\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics_2['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {metrics_2['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {metrics_2['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {metrics_2['avg_turnover']:.4f}\")\n",
    "\n",
    "print(f\"\\n MSR\")\n",
    "print(f\"Annualized Sharpe Ratio: {metrics_3['annual_sharpe_ratio']:.4f}\")\n",
    "print(f\"Mean Return: {metrics_3['mean_return']*12:.4f}\")\n",
    "print(f\"Variance: {metrics_3['variance']*12:.4f}\")\n",
    "print(f\"Avg Turnover: {metrics_3['avg_turnover']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d5e5c8-e09e-4e7f-b06c-2500ef309e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cdcee9-7980-4c93-aaa8-c7f6a28b7ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
